<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Yuma Uchiumi</title>
    <link>https://yumaloop.github.io/</link>
      <atom:link href="https://yumaloop.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Yuma Uchiumi</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© Yuma Uchiumi 2018-2021</copyright><lastBuildDate>Sun, 20 Dec 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://yumaloop.github.io/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_2.png</url>
      <title>Yuma Uchiumi</title>
      <link>https://yumaloop.github.io/</link>
    </image>
    
    <item>
      <title>StackOverflow - 2020 Developer Survey</title>
      <link>https://yumaloop.github.io/post/2020-12-20-stackoverflow-developer-survey-2020/</link>
      <pubDate>Sun, 20 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/post/2020-12-20-stackoverflow-developer-survey-2020/</guid>
      <description>&lt;p&gt;StackOverflow published its &lt;strong&gt;Developer Survey 2020&lt;/strong&gt;. Click &lt;a href=&#34;https://insights.stackoverflow.com/survey/2020&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt; for details.&lt;/p&gt;
&lt;p&gt;In 2020,
&lt;strong&gt;Python&lt;/strong&gt;, &lt;strong&gt;Go&lt;/strong&gt;, &lt;strong&gt;TypeScript&lt;/strong&gt;, &lt;strong&gt;Rust&lt;/strong&gt; are the programming language most loved by developers in the world.
It means that these languages are in vogue and new learners are on the rise.
While &lt;strong&gt;JavaScript&lt;/strong&gt; swallows everything, &lt;strong&gt;Perl&lt;/strong&gt;, &lt;strong&gt;PHP&lt;/strong&gt;, and &lt;strong&gt;Ruby&lt;/strong&gt; seem to be still in high demand.&lt;/p&gt;
&lt;p&gt;Frameworks packaging frontends, backends and database into one, such as Rails, are already not preferred.
Today, dividing frontends with &lt;strong&gt;JavaScript&lt;/strong&gt; (&lt;strong&gt;Node.js&lt;/strong&gt;, &lt;strong&gt;Vue.js&lt;/strong&gt;, &lt;strong&gt;React.js&lt;/strong&gt;)
and backends/database with scalable cloud services (&lt;strong&gt;AWS&lt;/strong&gt;, &lt;strong&gt;GCP&lt;/strong&gt;)
is major approach for adaptive web applications.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Python&lt;/strong&gt; and &lt;strong&gt;Java&lt;/strong&gt; have always been very popular
and in demand as general languages that can be used for many purposes.
In the future, it will be interesting to see if &lt;strong&gt;Go&lt;/strong&gt; and &lt;strong&gt;Rust&lt;/strong&gt; can take their place.&lt;/p&gt;
&lt;p&gt;Finally, I would like to introduce the cluster map of major development technologies found by the StackOverflow Developer Survey 2020.
With the penetration of new technologies such as &lt;strong&gt;mobile&lt;/strong&gt;, &lt;strong&gt;container&lt;/strong&gt; and &lt;strong&gt;cloud computing&lt;/strong&gt;,
it will be more difficult to become a full-stack engineer in the near future.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Assembly, C, C++&lt;/li&gt;
&lt;li&gt;Raspberry Pi, Arduino&lt;/li&gt;
&lt;li&gt;Unity, UnrealEngine&lt;/li&gt;
&lt;li&gt;Hadoop, Scala, Apache Spark&lt;/li&gt;
&lt;li&gt;Python, Pandas, Torch/PyTorch&lt;/li&gt;
&lt;li&gt;Linux, Docker, Kubernetes, Bash/Shell&lt;/li&gt;
&lt;li&gt;AWS, Redis, Ansible, DynamoDB, PostgreSQL&lt;/li&gt;
&lt;li&gt;JavaScript, Node.js, React.js, Angular, TypeScript, MongoDB,&lt;/li&gt;
&lt;li&gt;PHP, MySQL, jQuery, WordPress&lt;/li&gt;
&lt;li&gt;Java, Swift, Android, iOS, Kotlin, SQLite, Firebase&lt;/li&gt;
&lt;li&gt;C#, .NET, Windows, Azure&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;./so_ds_2020_cluster.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Maximize the cell size of Jupyter notebook</title>
      <link>https://yumaloop.github.io/post/2020-11-29-maximize-jupyter-notebook-cell-height/</link>
      <pubDate>Sun, 29 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/post/2020-11-29-maximize-jupyter-notebook-cell-height/</guid>
      <description>&lt;h3 id=&#34;tldr&#34;&gt;TL;DR&lt;/h3&gt;
&lt;p&gt;Put the following magic command (cell magic) in a cell and execute it.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%%javascript
IPython.OutputArea.auto_scroll_threshold = 9999;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note: This is not &lt;code&gt;line magic&lt;/code&gt; like &lt;code&gt;% matplotlib inline&lt;/code&gt; and some errors will occur unless the executed cell is independent.
See &lt;a href=&#34;https://ipython.readthedocs.io/en/stable/interactive/magics.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IPython Official Documentation&lt;/a&gt; for details.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;%&lt;/code&gt; - All available &lt;em&gt;line magic&lt;/em&gt; commands - &lt;a href=&#34;https://ipython.readthedocs.io/en/stable/interactive/magics.html#line-magics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;check here&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;%%&lt;/code&gt; - All available &lt;em&gt;cell magic&lt;/em&gt; commands - &lt;a href=&#34;https://ipython.readthedocs.io/en/stable/interactive/magics.html#cell-magics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;check here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cf&#34;&gt;Cf.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://ipython.readthedocs.io/en/stable/interactive/tutorial.html#magic-functions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Magic functions - IPython公式ドキュメント&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ipython/ipython/issues/2172#issuecomment-53708976&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;comment:53708976 issue:2172 ipython github.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://qastack.jp/programming/18770504/resize-ipython-notebook-output-window&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ipythonノートブックの出力ウィンドウのサイズを変更する&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://qiita.com/daifuku_mochi2/items/30258e58750ff8e85d37&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jupyter notebookで列をすべて表示したい - Qitta&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Monte Carlo Simulation of Black-Scholes Option Pricing Model</title>
      <link>https://yumaloop.github.io/post/2020-11-25-monte-carlo-sim-bsoption-r/</link>
      <pubDate>Wed, 25 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/post/2020-11-25-monte-carlo-sim-bsoption-r/</guid>
      <description>&lt;p&gt;幾何ブラウン運動のサンプルパスを生成することにより，株価が幾何ブラウン運動にしたがう場合のコールオプション価格をモンテカルロシミュレーションにより導出し，サンプルパスの生成回数を増やすことで理論値に収束することをプロットにより確認する．&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;1-コールオプションの価格理論&#34;&gt;1. コールオプションの価格理論&lt;/h2&gt;
&lt;h4 id=&#34;ブラックショールズ式によるオプション価格の導出&#34;&gt;ブラックショールズ式によるオプション価格の導出&lt;/h4&gt;
&lt;p&gt;満期$T$で原資産価格(株式価格)が連続時間確率過程$S = {(S_t)}_{t \in [0,T]}$に従うオプションの時刻$t \in [0, T]$における価格$C(t, S_t)$について考える．$S$が確率微分方程式:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
d S_t = \sigma S_t dt + \mu S_t d W_t
\end{align}
$$&lt;/p&gt;
&lt;p&gt;の解で与えられているとする($S$は幾何ブラウン運動に従う)．時刻$t \in [0, T]$において，オプションの原資産価格$S_t$とオプションの行使価格$K$が与えられたとき，ブラック・ショールズ式によってオプションの理論価格$C(t, S_t)$は&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
C(t, S_t) &amp;amp;= S_t \Phi(d_1) - K e^{-r(T-t)} \Phi(d_2) \\&lt;br&gt;
where ~~
d_1 &amp;amp;= \frac{\log \left( \frac{S_t}{K} \right) + \left( r + \frac{\sigma^2}{2}  \right) T}{\sigma \sqrt{T}} \\&lt;br&gt;
d_2 &amp;amp;= \frac{\log \left( \frac{S_t}{K} \right) + \left( r - \frac{\sigma^2}{2}  \right) T}{\sigma \sqrt{T}}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;となる．ただし，$r$は無リスク資産の利率，$\Phi$は標準正規分布$\mathcal{N}(0,1)の累積分布関数とする．ここで，簡単のために満期$T$を$1$とすると，現在($t=0$)のオプション価格の理論値は，&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
C(0, S_0) &amp;amp;= S_0 \Phi(d_1) - K e^{-r} \Phi(d_2) \\&lt;br&gt;
where ~~
d_1 &amp;amp;= \frac{\log \left( \frac{S_0}{K} \right) + \left( r + \frac{\sigma^2}{2}  \right)}{\sigma } \\&lt;br&gt;
d_2 &amp;amp;= \frac{\log \left( \frac{S_0}{K} \right) + \left( r - \frac{\sigma^2}{2}  \right)}{\sigma}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;となる．&lt;/p&gt;
&lt;h4 id=&#34;モンテカルロ法によるオプション価格の導出&#34;&gt;モンテカルロ法によるオプション価格の導出&lt;/h4&gt;
&lt;p&gt;ブラックショールズ式に含まれる$S_T$の期待値計算をモンテカルロ法によって近似することを考える．すなわち，幾何ブラウン運動に従うサンプルパス$S = {(S_t)}_{t \in [0,T]}$を大量に生成することで，$S_T$の期待値を求める．&lt;/p&gt;
&lt;p&gt;モンテカルロシミュレーションによって生成された，満期$T$における原資産価格$S_T$の$n$個のサンプルを$(s^{(1)}&lt;em&gt;{T}, \cdots, s^{(n)}&lt;/em&gt;{T})$とすると，時刻$t \in [0, T]$におけるオプションの価格の推定値$\hat{C}(t, S_t)$は&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\hat{C}(t, S_t) &amp;amp;= \frac{1}{n} \sum_{i=1}^{n} e^{-r(T-t)} \cdot max(s^{(i)}_{T} - K, 0)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;と求められる．ここで，簡単のために満期$T$を$1$とすると，現在($t=0$)のオプション価格の推定値は，&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\hat{C}(0, S_0) &amp;amp;= \frac{1}{n} \sum_{i=1}^{n} e^{-r} \cdot max(s^{(i)}_{1} - K, 0)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;となる．&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;2-rでモンテカルロシミュレーション&#34;&gt;2. Rでモンテカルロシミュレーション&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://yuimaproject.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;YUIMA&lt;/a&gt;ライブラリをインストール（or 読み込み）する．&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;install.packages(&amp;quot;yuima&amp;quot;) # インストール (初回のみ)
library(yuima) # ライブラリの読み込み
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;モンテカルロシミュレーションを実行するコード．&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Calculation of call-option prices by Black-Sholes eq.
BlackScholesCallPrice = function(S, K, r, sigma, T=1)
{
    d1 &amp;lt;- ( log(S/K) + (r + sigma^2/2) * T)/( sigma * sqrt(T))
    d2 &amp;lt;- ( log(S/K) + (r - sigma^2/2) * T)/( sigma * sqrt(T))
    C0 &amp;lt;- S * pnorm(d1) - K * exp(-r * T) * pnorm(d2)
    return(C0)
}

# Calculation of call-option prices by Monte Carlo method
MonteCarloCallPrice = function(S, K, r, sigma, n, T=1)
{
    n_sample &amp;lt;- 1000
    c0_list &amp;lt;- list()
    c0 &amp;lt;- 0
    for (i in 1:n) {
        resultGBM &amp;lt;- GBM_sample(S, r, sigma, n_sample)
        sT &amp;lt;- resultGBM@data@original.data[n_sample]
        c0 &amp;lt;- (1/i) * exp(-1*r*T) * max(sT - K, 0) + ((i-1)/i) * c0
        c0_list &amp;lt;- append(c0_list, list(c0))
    }
    return(c0_list)
}

# A function which generates sample paths that follows a Geometric Brownian motion
GBM_sample = function(x0, alpha, beta, n_sample, T=1)
{
    # Step1: Define SDE
    # dS_t = alpha * S_t * dt + beta * S_t * dW_t
    mod &amp;lt;-setModel(drift=&amp;quot;alpha*x&amp;quot;, diffusion=&amp;quot;beta*x&amp;quot;)
    
    # Step2: Define samples
    samp &amp;lt;-setSampling(Initial=0, Terminal=T, n=n_sample)
    
    # Step3: define the statistical model
    smod &amp;lt;-setYuima(model=mod, sampling=samp)
    
    # Step4: Generate sample paths
    xinit &amp;lt;- x0
    param &amp;lt;- list(alpha=alpha, beta=beta)
    resultGBM &amp;lt;- simulate(smod, xinit=xinit, true.parameter=param)
    return(resultGBM)
}

# Params for call-option pricing
n &amp;lt;- 10000 # Num. of MonteCalro simulation
K &amp;lt;- 900 # Option exercise price (at t=T)
S &amp;lt;- 1000 # Curent asset price (at t=0)
r &amp;lt;- 0.005 # Drift for Geometric Brownian motion
sigma &amp;lt;- 0.3 # Diffusion for Geometric Brownian motion
T &amp;lt;- 1 # Optional term

# Main procedure: Run simulation
bs_price &amp;lt;- BlackScholesCallPrice(S, K, r, sigma, T=1)
mc_price &amp;lt;- MonteCarloCallPrice(S, K, r, sigma, n, T=1)
print(bs_price)
plot(1:n, mc_price, main=&amp;quot;Monte Carlo Simulation:\nBlack-Scholes Option Pricing Model&amp;quot;, xlab=&amp;quot;Number of sample paths: # of ST&amp;quot;, ylab=&amp;quot;Option Price: C0&amp;quot;, cex=0.5)
abline(h=bs_price, col=&#39;red&#39;, lwd=1, lty=2)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Case 1.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./r_mcbs1.png&#34; alt=&#34;img1&#34;&gt;&lt;/p&gt;
&lt;p&gt;モンテカルロ法によるコールオプションの推定価格が，
BS式による理論価格172.7457に漸近している．&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;パラメータ設定
&lt;ul&gt;
&lt;li&gt;n: 10000 # モンテカルロシミュレーションの回数&lt;/li&gt;
&lt;li&gt;K: 900 # コールオプションの権利行使価格 (t=T)&lt;/li&gt;
&lt;li&gt;S: 1000 # 株式の現在価格 (t=0)&lt;/li&gt;
&lt;li&gt;r: 0.005 # 幾何ブラウン運動のdrift&lt;/li&gt;
&lt;li&gt;sigma: 0.3 # 幾何ブラウン運動のdiffusion&lt;/li&gt;
&lt;li&gt;T: 1 # オプションの満期&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Case 2.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./r_mcbs2.png&#34; alt=&#34;img2&#34;&gt;&lt;/p&gt;
&lt;p&gt;モンテカルロ法によるコールオプションの推定価格が，
BS式による理論価格83.1821に漸近している．&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;パラメータ設定
&lt;ul&gt;
&lt;li&gt;n: 10000 # モンテカルロシミュレーションの回数&lt;/li&gt;
&lt;li&gt;K: 1100 # コールオプションの権利行使価格 (t=T)&lt;/li&gt;
&lt;li&gt;S: 1000 # 株式の現在価格 (t=0)&lt;/li&gt;
&lt;li&gt;r: 0.005 # 幾何ブラウン運動のdrift&lt;/li&gt;
&lt;li&gt;sigma: 0.3 # 幾何ブラウン運動のdiffusion&lt;/li&gt;
&lt;li&gt;T: 1 # オプションの満期&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Basic Portfolio Optimization with Python: Markowitz&#39;s Mean-Variance Model</title>
      <link>https://yumaloop.github.io/post/2020-11-12-portfolio-optimization-by-python/</link>
      <pubDate>Thu, 12 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/post/2020-11-12-portfolio-optimization-by-python/</guid>
      <description>&lt;p&gt;Pythonでbacktestする際のTipsをまとめたものです．面倒な前処理をさくっと終わらせてモデル作りに専念しましょう！という主旨です．記事では紹介していませんが，&lt;code&gt;pandas-datareader&lt;/code&gt;でマクロデータもだいたい取れるので，複数因子モデルなど，さまざまなポートフォリオ選択モデルを試すことができます．&lt;/p&gt;
&lt;font color=&#34;gray&#34;&gt;
&lt;p&gt;&lt;strong&gt;Overview:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;PythonでBacktestする環境を整える．&lt;/li&gt;
&lt;li&gt;東証TOPIX構成銘柄から対象資産を選び最小分散ポートフォリオを組む．&lt;/li&gt;
&lt;/ol&gt;
&lt;/font&gt;
&lt;br&gt;
&lt;h2 id=&#34;1-株価データの取得&#34;&gt;1. 株価データの取得&lt;/h2&gt;
&lt;br&gt;
&lt;p&gt;まず，&lt;code&gt;pandas-datareader&lt;/code&gt;を環境にインストールします．&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pandas-datareader&lt;/code&gt;は，株価などの市場データをWeb API経由でダウンロードできる（pandas.Dataframe friendlyで）便利なPythonパッケージです．IEX, World Bank, OECD, &lt;a href=&#34;https://finance.yahoo.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yahoo! Finance&lt;/a&gt;，&lt;a href=&#34;https://fred.stlouisfed.org/docs/api/fred/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;FRED&lt;/a&gt;，&lt;a href=&#34;https://stooq.com/q/?s=usdkrw&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stooq&lt;/a&gt;などのAPIを内部で叩き、pythonコード上に取得したデータを読み込みことができます．詳しい使い方は&lt;a href=&#34;https://pandas-datareader.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;公式ドキュメント&lt;/a&gt;を参照してください．&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Install pandas-datareader (latest version)
pip install git+https://github.com/pydata/pandas-datareader.git
# Or install pandas-datareader (stable version)
pip install pandas-datareader
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;今回は，東京証券取引所（東証）に上場している株式銘柄を対象商品とします．
Web上で公開されているデータは圧倒的に米国市場のものが多いですが，ポーランドの最強サイト&lt;a href=&#34;https://stooq.com/q/?s=usdkrw&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;stooq.com&lt;/a&gt;は東京証券取引所の過去データを公開しています．&lt;code&gt;pandas-datareader&lt;/code&gt;を使ってstooqから個別銘柄のデータを取得しましょう．&lt;/p&gt;
&lt;p&gt;基本的には，&lt;code&gt;pandas_datareader.stooq.StooqDailyReader()&lt;/code&gt;を実行すればOKです．引数には，各市場に登録してある証券コード(or ティッカーシンボル)と、データ公開元のサイト(Yahoo!, Stooq, &amp;hellip;)を指定します．&lt;/p&gt;
&lt;p&gt;東京証券取引所で取り扱いされている株式銘柄には，4桁の証券コードが割り当てられているので、今回はこれを使います．（例：&lt;a href=&#34;https://stocks.finance.yahoo.co.jp/stocks/detail/?code=7203&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;トヨタ自動車&lt;/a&gt;の株式は、東証では証券コードが&lt;strong&gt;7203&lt;/strong&gt;である銘柄として，NYSEではティッカーシンボルが&lt;strong&gt;TM&lt;/strong&gt;である銘柄として取引されています．）&lt;/p&gt;
&lt;p&gt;試しに，トヨタ自動車(東証:7203)の株価データを取得してプロットしてみましょう，&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import datetime
import pandas_datareader

start = datetime.datetime(2015, 1, 1)
end = datetime.datetime(2020, 11, 30)
stockcode = &amp;quot;7203.jp&amp;quot; # Toyota Motor Corporation (TM)

df = pandas_datareader.stooq.StooqDailyReader(stockcode, start, end).read()
df = df.sort_values(by=&#39;Date&#39;,ascending=True)
display(df) # Show dataframe
-----
            Open	High	Low	    Close	Volume
Date					
2015-01-05	6756.50	6765.42	6623.43	6704.69	10653925
2015-01-06	6539.48	6601.09	6519.83	6519.83	13870266
2015-01-07	6480.52	6685.05	6479.64	6615.40	12837377
2015-01-08	6698.46	6748.46	6693.98	6746.69	11257646
2015-01-09	6814.56	6846.70	6752.92	6795.80	11672928
...	...	...	...	...	...
2020-11-04	7024.00	7054.00	6976.00	6976.00	6278100
2020-11-05	6955.00	7032.00	6923.00	6984.00	5643400
2020-11-06	7070.00	7152.00	7015.00	7019.00	11092900
2020-11-09	7159.00	7242.00	7119.00	7173.00	7838600
2020-11-10	7320.00	7360.00	7212.00	7267.00	8825700
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;日別の株価推移データがpandas.Dataframeとして取得できました！
いま作成した&lt;code&gt;df&lt;/code&gt;の中身をプロットしてみます．（基本的に終値をつかいます）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Plot timeseries (2015/1/1 - 2020/11/30)
plt.figure(figsize=(12,8))
plt.plot(df.index, df[&amp;quot;Close&amp;quot;].values)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;下図のように，終値(Close)の推移が簡単にプロットできました．
&lt;img src=&#34;https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/295228/ef4c8a3e-7e1b-4a6e-d1e2-40f12c91691c.png&#34; alt=&#34;hoge.png&#34;&gt;&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;2-対象資産のパネルデータを作る&#34;&gt;2. 対象資産のパネルデータを作る&lt;/h2&gt;
&lt;br&gt;
&lt;p&gt;ポートフォリオ最適化問題を解くための準備として，複数の資産(株式銘柄)に対するパネルデータを作り，pandas.Dataframeオブジェクトとして整理します．&lt;/p&gt;
&lt;p&gt;今回は&lt;a href=&#34;https://www.jpx.co.jp/markets/indices/topix/index.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TOPIX 500&lt;/a&gt;に掲載されている銘柄から5つ選び，投資対象資産とします．また，前処理として「終値」を「終値ベースの収益率」へ変換しています．この部分のコードは状況に合わせて変えてください．&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import datetime
import numpy as np
import pandas as pd
import pandas_datareader.data as web
import pandas_datareader.stooq as stooq


def get_stockvalues_tokyo(stockcode, start, end, use_ratio=False):
    &amp;quot;&amp;quot;&amp;quot;
    stockcode: market code of each target stock (ex. &amp;quot;NNNN&amp;quot;) defined by the Tokyo stock market.
    start, end: datetime object
    &amp;quot;&amp;quot;&amp;quot;
    # Get index data from https://stooq.com/
    df = stooq.StooqDailyReader(f&amp;quot;{stockcode}.jp&amp;quot;, start, end).read()
    df = df.sort_values(by=&#39;Date&#39;,ascending=True)
    
    if use_ratio:
        df = df.apply(lambda x: (x - x[0]) / x[0] )
    return df

def get_paneldata_tokyo(stockcodes, start, end, use_ratio=False):
    # Use &amp;quot;Close&amp;quot; value only 
    dfs = []
    for sc in stockcodes:
        df = get_stockvalues_tokyo(sc, start, end, use_ratio)[[&#39;Close&#39;]]
        df = df.rename(columns={&#39;Close&#39;: sc})
        dfs.append(df)
    df_concat = pd.concat(dfs, axis=1)
    return df_concat
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;get_paneldata_tokyo()&lt;/code&gt;を使ってパネルデータを作成します．&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;start = datetime.datetime(2015, 1, 1)
end = datetime.datetime(2020, 11, 30)
stockcodes=[&amp;quot;1301&amp;quot;, &amp;quot;1762&amp;quot;, &amp;quot;1820&amp;quot;, &amp;quot;1967&amp;quot;, &amp;quot;2127&amp;quot;]

df = get_paneldata_tokyo(stockcodes, start, end, use_ratio=True)
display(df) # return ratio daily
-----
            1301	    1762    	1820    	1967	    2127
Date					
2015-01-05	0.000000	0.000000	0.000000	0.000000	0.000000
2015-01-06	-0.010929	-0.018385	-0.033937	-0.002265	-0.038448
2015-01-07	-0.014564	-0.020433	-0.059863	-0.013823	-0.059680
2015-01-08	-0.007302	-0.016338	-0.057883	-0.013823	-0.039787
2015-01-09	0.000000	-0.004490	-0.031938	-0.025407	-0.043770
...	...	...	...	...	...
2020-10-29	0.096138	-0.032923	-0.030777	0.858573	5.682321
2020-10-30	0.093336	-0.039657	-0.041199	0.832831	5.704266
2020-11-02	0.107748	-0.026188	-0.032198	0.845702	5.418978
2020-11-04	0.099341	-0.024392	-0.020829	0.858573	5.704266
2020-11-05	0.069315	-0.014964	-0.042147	0.904909	6.055390
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;これで，評価対象となる各資産のパネルデータを取得できました．&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;3-マーコビッツの平均分散モデルとその解法&#34;&gt;3. マーコビッツの平均分散モデルとその解法&lt;/h2&gt;
&lt;br&gt;
&lt;p&gt;投資対象となる複数の資産に対して，適当な投資比率をそれぞれ決定することを&lt;strong&gt;ポートフォリオ最適化&lt;/strong&gt;といいます．今回は，最も基本的なポートフォリオ最適化の問題設定として，Markowitzが提唱した&lt;strong&gt;平均分散モデル&lt;/strong&gt;(Mean-Variance Model)を採用します．&lt;/p&gt;
&lt;h3 id=&#34;31-markowitzの平均分散モデル&#34;&gt;3.1. Markowitzの平均分散モデル&lt;/h3&gt;
&lt;p&gt;Markowitzの平均分散モデルでは，「ポートフォリオの期待収益率(Expected return)が一定値以上となる」という制約条件の下で，「ポートフォリオの分散を最小化する」最適化問題を考えます．&lt;/p&gt;
&lt;p&gt;一般に，$n$コの資産で構成されるポートフォリオの場合，ポートフォリオの分散は$n$コの資産間の共分散行列の二次形式となるので，この最適化問題は二次計画問題(Quadratic Programming, QP)のクラスとなり，次のように定式化されます．&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\underset{\bf x}{\rm minimize} ~~~ &amp;amp;{\bf x}^T \Sigma {\bf x} \\&lt;br&gt;
{\rm subject~to} ~~~ &amp;amp;{\bf r}^T {\bf x} = \sum_{i=1}^{n} r_i x_i \geq r_e \\&lt;br&gt;
&amp;amp;{|| {\bf x} ||}_{1} = \sum_{i=1}^{n} x_i = 1 \\&lt;br&gt;
&amp;amp;x_i \geq 0 ~~ (i = 1, \cdots, n)
\end{align}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\Sigma \in \mathbb{R}^{n \times n}$ ー $n$コの資産の共分散行列&lt;/li&gt;
&lt;li&gt;${\bf x} \in \mathbb{R}^{n}$ ー $n$コの資産の投資比率ベクトル&lt;/li&gt;
&lt;li&gt;$\bar{\bf r} \in \mathbb{R}^{n}$ ー $n$コの資産の期待収益率ベクトル&lt;/li&gt;
&lt;li&gt;$x_i \in \mathbb{R}$ ー 資産$i$の投資比率&lt;/li&gt;
&lt;li&gt;$\bar{r}_i \in \mathbb{R}$ ー 資産$i$の期待収益率&lt;/li&gt;
&lt;li&gt;$r_e \in \mathbb{R}$ ー 投資家の要求期待収益率&lt;/li&gt;
&lt;li&gt;$\bar{r}_p \in \mathbb{R}$ ー ポートフォリオの収益率の期待値&lt;/li&gt;
&lt;li&gt;$\sigma_p \in \mathbb{R}$ ー ポートフォリオの収益率の標準偏差&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;1つ目の制約式は，ポートフォリオの期待収益率が一定値($=r_e$)以上となることを要請しています．2つ目，3つ目の制約式はポートフォリオの定義からくる自明なものです．資産の空売りを許す場合，3つ目の制約式を除くこともあります．&lt;/p&gt;
&lt;h3 id=&#34;32-cvxoptの使い方&#34;&gt;3.2. CVXOPTの使い方&lt;/h3&gt;
&lt;p&gt;Pythonの凸最適化向けパッケージ&lt;a href=&#34;https://cvxopt.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CVXOPT&lt;/a&gt;を使って，この二次計画問題(QP)を解きます．
CVXOPTで二次計画問題を扱う場合は，解きたい最適化問題を以下の一般化されたフォーマットに整理して，&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\underset{\bf x}{\rm minimize} ~~~ &amp;amp;\frac{1}{2} {\bf x}^{T} P {\bf x} + {\bf q}^{T} {\bf x} \\&lt;br&gt;
{\rm subject~to} ~~~ &amp;amp; G {\bf x} \leq {\bf h} \\&lt;br&gt;
&amp;amp;A {\bf x} = {\bf b}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;パラメータ&lt;code&gt;P&lt;/code&gt;,&lt;code&gt;q&lt;/code&gt;,&lt;code&gt;G&lt;/code&gt;,&lt;code&gt;h&lt;/code&gt;,&lt;code&gt;A&lt;/code&gt;を計算し，&lt;code&gt;cvxopt.solvers.qp()&lt;/code&gt;関数を実行することで最適解と最適値を求めます．Markowitzの平均・分散モデルの場合は，&lt;/p&gt;
&lt;p&gt;$$
P = 2 \cdot \Sigma, ~~~
q = {\bf 0}_n, ~~~
G = -1 \cdot
\begin{pmatrix}
\bar{r}_1 &amp;amp; \cdots &amp;amp; \bar{r}_n \\&lt;br&gt;
1 &amp;amp; \cdots &amp;amp; 0 \\&lt;br&gt;
\vdots &amp;amp; \ddots &amp;amp; \vdots \\&lt;br&gt;
0 &amp;amp; \cdots &amp;amp; 1
\end{pmatrix}, ~~~
h = -1 \cdot
\left(
\begin{array}{c}
r_e \\&lt;br&gt;
0 \\&lt;br&gt;
\vdots \\&lt;br&gt;
0
\end{array}
\right), ~~~
A = {\bf 1}_n^{\mathrm{T}}, ~~~
b = 1
$$&lt;/p&gt;
&lt;p&gt;となります．&lt;/p&gt;
&lt;p&gt;参考:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cvxopt.org/userguide/coneprog.html#quadratic-programming&#34;&gt;https://cvxopt.org/userguide/coneprog.html#quadratic-programming&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://qiita.com/ryoshi81/items/8b0c6add3e367f94c828&#34;&gt;https://qiita.com/ryoshi81/items/8b0c6add3e367f94c828&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;33-pythonで計算&#34;&gt;3.3. Pythonで計算&lt;/h3&gt;
&lt;p&gt;対象資産のパネルデータ&lt;code&gt;df&lt;/code&gt;から，必要な統計量を計算します．&lt;/p&gt;
&lt;p&gt;ポートフォリオ内の資産間の共分散行列 $\Sigma$：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.cov() # Covariance matrix
-----
        1301	    1762        1820	    1967	    2127
1301	0.024211	0.015340	0.018243	0.037772	0.081221
1762	0.015340	0.014867	0.015562	0.023735	0.038868
1820	0.018243	0.015562	0.025023	0.029918	0.040811
1967	0.037772	0.023735	0.029918	0.109754	0.312827
2127	0.081221	0.038868	0.040811	0.312827	1.703412
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ポートフォリオ内の各資産の期待収益率 ${\bf r}$：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.mean().values # Expected returns
-----
array([0.12547322, 0.10879767, 0.07469455, 0.44782516, 1.75209493])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;CVXOPTを使って最適化問題を解く．&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import cvxopt

def cvxopt_qp_solver(r, r_e, cov):
    # CVXOPT QP Solver for Markowitz&#39; Mean-Variance Model
    # See https://cvxopt.org/userguide/coneprog.html#quadratic-programming
    # See https://cdn.hackaday.io/files/277521187341568/art-mpt.pdf
    n = len(r)
    r = cvxopt.matrix(r)
    
    P = cvxopt.matrix(2.0 * np.array(cov))
    q = cvxopt.matrix(np.zeros((n, 1)))
    G = cvxopt.matrix(np.concatenate((-np.transpose(r), -np.identity(n)), 0))
    h = cvxopt.matrix(np.concatenate((-np.ones((1,1)) * r_e, np.zeros((n,1))), 0))
    A = cvxopt.matrix(1.0, (1, n))
    b = cvxopt.matrix(1.0)    
    sol = cvxopt.solvers.qp(P, q, G, h, A, b)
    return sol
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;r = df.mean().values # Expected returns
r_e = 0.005 * # Lower bound for portfolio&#39;s return
cov = df.cov() # Covariance matrix

# Solve QP and derive optimal portfolio
sol = cvxopt_qp_solver(r, r_e, cov)
x_opt = np.array(sol[&#39;x&#39;])
print(x_opt)
print(&amp;quot;Variance (x_opt) :&amp;quot;, sol[&amp;quot;primal objective&amp;quot;])

-----

 pcost       dcost       gap    pres   dres
 0:  4.3680e-03 -8.6883e-02  5e+00  2e+00  2e+00
 1:  9.1180e-02 -2.2275e-01  5e-01  1e-01  1e-01
 2:  2.1337e-02 -6.0274e-02  8e-02  2e-16  1e-16
 3:  1.0483e-02 -1.7810e-03  1e-02  1e-16  3e-17
 4:  4.9857e-03  1.5180e-03  3e-03  2e-16  8e-18
 5:  4.0217e-03  3.6059e-03  4e-04  3e-17  1e-17
 6:  3.7560e-03  3.7107e-03  5e-05  3e-17  1e-18
 7:  3.7187e-03  3.7168e-03  2e-06  1e-17  4e-18
 8:  3.7169e-03  3.7168e-03  2e-08  1e-16  6e-18
Optimal solution found.
[ 5.56e-05]
[ 1.00e+00]
[ 1.76e-05]
[ 3.84e-07]
[ 2.63e-07]

Variance (x_opt):  0.003716866155475511 # 最適ポートフォリオの分散
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;最適解（各資産への最適な投資比率）と，最適値（最適な投資比率を適用した場合のポートフォリオの分散）が求められました．なお，今回使った平均分散モデルによる最適解はポートフォリオのリスク(分散)に対する最適性を重視しているので，「最小分散ポートフォリオ」と呼ばれます．&lt;/p&gt;
&lt;p&gt;なお，収益率に対する評価指標には，無リスク資産の収益率(インフレ率)を加味したシャープレシオを用いるケースが多いです．backtestの方法についてはいくつか流儀があるので，専門書や論文を参照してください．&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;4-実装例&#34;&gt;4. 実装例&lt;/h2&gt;
&lt;br&gt;
&lt;p&gt;上のコードをまとめて，自作のバックテスト用Pythonクラス&lt;code&gt;MarkowitzMinVarianceModel()&lt;/code&gt;を作りました．
以下は参考例です．&lt;/p&gt;
&lt;h3 id=&#34;41-バックテスト用のpythonクラス&#34;&gt;4.1. バックテスト用のPythonクラス&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import cvxopt
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

class MarkowitzMinVarianceModel():
    &amp;quot;&amp;quot;&amp;quot;
    Args:
    =====
    - df: pandas.dataframe
        panel data for target assets for the portfolio. 
            its index must be `numpy.datetime64` type.
            its columns must be time-series data of target assets.
    - window_size: int
        the size of time-window which is used when deriving (or updating) the portfolio.
    - rebalance_freq: int
        rebalance frequency of the portfolio.
    - r_e: float
        min of the return ratio (= capital gain / investment).
    - r_f: float
        rate of returns of the risk-free asset.
    &amp;quot;&amp;quot;&amp;quot;
    def __init__(self, df, window_size, rebalance_freq, r_e=None, r_f=None):
        self.df = self._reset_index(df)
        self.df_chg = self.df.pct_change()
        self.df_chg[:1] = 0.0 # set 0.0 to the first record
        self.df_bt = None
        self.df_bt_r = None
        self.df_bt_x = None
        self.window_size = window_size
        self.rebalance_freq = rebalance_freq
        self.jgb_int = 0.0001 # 0.01% per year (Japanese Government Bond)
        self.r_f = r_f if r_f is not None else self.jgb_int * (1/12) # adjust monthly
        self.r_e = r_e if r_e is not None else r_f
        
    def _reset_index(self, df):
        df = df.copy()
        df[&#39;date&#39;] = pd.to_datetime(df.index)
        df = df.set_index(&#39;date&#39;)
        return df
    
    def get_dfbt_r(self):
        return self.df_bt_r
    
    def get_dfbt_x(self):
        return self.df_bt_x
        
    def backtest(self):
        date_init = self.df.index.values[self.window_size]
        df_bt = pd.DataFrame([[0.0, np.nan]], index=[date_init], columns=[&#39;ror&#39;, &#39;std&#39;])
        df_bt_r = pd.DataFrame(columns=list(self.df.columns.values))
        df_bt_x = pd.DataFrame(columns=list(self.df.columns.values))
        for idx, date in enumerate(self.df.index.values):
            if idx &amp;gt;= self.window_size + self.rebalance_freq:
                if (idx - self.window_size) % self.rebalance_freq == 0:
                    # df_chg_train
                    st = idx - self.rebalance_freq - self.window_size
                    ed = idx - self.rebalance_freq
                    df_chg_train = self.df_chg[st:ed]
                    
                    # expected returns per target term
                    if isinstance(self.r_e, pd.core.frame.DataFrame):
                        r_e = self.r_e.iloc[st:ed].values.mean()
                    else:
                        r_e = self.r_e
                    
                    # x_p: min variance portfolio
                    x_p = self.calc_portfolio(df_chg_train, r_e)
                    
                    # df_chg_test
                    st = idx - self.rebalance_freq
                    ed = idx
                    df_chg_test = self.df_chg[st:ed]
                    df_chgcum_test = (1.0 + df_chg_test).cumprod() - 1.0
                                                            
                    # ror_p: rate of return (portfolio)
                    ror_test = df_chgcum_test.iloc[-1].values
                    ror_p = float(np.dot(ror_test, x_p))
                    df_bt_r.loc[date] = ror_test
                    df_bt_x.loc[date] = x_p
                    
                    # std (portfolio)
                    if self.rebalance_freq == 1:
                        std_p = np.nan
                    else:
                        std_test = df_chg_test.std(ddof=True).values
                        std_p = float(np.dot(std_test, np.abs(x_p)))

                    # append
                    df_one = pd.DataFrame([[ror_p, std_p]], index=[date], columns=df_bt.columns)                    
                    df_bt = df_bt.append(df_one)
                    
        # reset index
        self.df_bt = self._reset_index(df_bt)
        self.df_bt_r = self._reset_index(df_bt_r)  
        self.df_bt_x = self._reset_index(df_bt_x)  
        return self.df_bt

    def calc_portfolio(self, df_retchg, r_e):
        r = df_retchg.mean().values
        cov = np.array(df_retchg.cov())
        x_opt = self.cvxopt_qp_solver(r, r_e, cov)
        return x_opt
        
    def cvxopt_qp_solver(self, r, r_e, cov):
        &amp;quot;&amp;quot;&amp;quot;
        CVXOPT QP Solver for Markowitz&#39; Mean-Variance Model
        - See also https://cvxopt.org/userguide/coneprog.html#quadratic-programming
        - See also https://cdn.hackaday.io/files/277521187341568/art-mpt.pdf
        
        r: mean returns of target assets. (vector)
        r_e: min of the return ratio (= capital gain / investment).
        cov: covariance matrix of target assets. (matrix)
        &amp;quot;&amp;quot;&amp;quot;
        n = len(r)
        r = cvxopt.matrix(r)

        # Create Objective matrices
        P = cvxopt.matrix(2.0 * np.array(cov))
        q = cvxopt.matrix(np.zeros((n, 1)))

        # Create constraint matrices
        G = cvxopt.matrix(np.concatenate((-np.transpose(r), -np.eye(n)), 0))
        h = cvxopt.matrix(np.concatenate((-np.ones((1,1))*r_e, np.zeros((n,1))), 0))
        A = cvxopt.matrix(1.0, (1, n))
        b = cvxopt.matrix(1.0)
        
        # Adjust params (stop log messages)
        cvxopt.solvers.options[&#39;show_progress&#39;] = False # default: True
        cvxopt.solvers.options[&#39;maxiters&#39;] = 1000 # default: 100
        
        sol = cvxopt.solvers.qp(P, q, G, h, A, b)
        x_opt = np.squeeze(np.array(sol[&#39;x&#39;]))
        return x_opt
    
    def get_yearly_performance(self):
        if self.df_bt is None:
            pass
        else:
            df_yearly = self.df_bt[[&amp;quot;ror&amp;quot;]].resample(&#39;y&#39;).sum()
            df_yearly[&amp;quot;std&amp;quot;] = self.df_bt[&amp;quot;ror&amp;quot;].resample(&#39;y&#39;).std().values
            df_yearly[&amp;quot;sharpe_ratio&amp;quot;] = df_yearly.apply(lambda d: (d[&amp;quot;ror&amp;quot;] - self.r_f) / d[&amp;quot;std&amp;quot;], axis=1)
            return df_yearly

    def evaluate_backtest(self, logging=False):   
        if self.df_bt is None:
            pass
        else:
            self.r_mean = self.df_bt[&amp;quot;ror&amp;quot;].mean()
            self.r_std = self.df_bt[&amp;quot;ror&amp;quot;].std(ddof=True)
            self.sharpe_ratio = (self.r_mean - self.r_f) / self.r_std
            self.net_capgain = (self.df_bt[&amp;quot;ror&amp;quot;] + 1.0).cumprod().iloc[-1] - 1.0
            
            self.r_mean_peryear = 12 * self.r_mean
            self.r_std_peryear = np.sqrt(12) * self.r_std
            self.sharpe_ratio_peryear = (self.r_mean_peryear - self.jgb_int) / self.r_std_peryear

            if logging:
                print(&amp;quot;Portfolio Performance&amp;quot;)
                print(&amp;quot;=======================&amp;quot;)
                print(&amp;quot;Returns per month&amp;quot;)
                print(&amp;quot;  sharpe ratio     : {:.8f}&amp;quot;.format(self.sharpe_ratio))
                print(&amp;quot;  mean of returns  : {:.8f}&amp;quot;.format(self.r_mean))
                print(&amp;quot;  std of returns   : {:.8f}&amp;quot;.format(self.r_std))
                print(&amp;quot;    risk-free rate : {:.8f}&amp;quot;.format(self.r_f))
                print(&amp;quot;    capgain ratio  : {:.8f}&amp;quot;.format(self.net_capgain))
                print(&amp;quot;Returns per year&amp;quot;)
                print(&amp;quot;  sharpe ratio     : {:.8f}&amp;quot;.format(self.sharpe_ratio_peryear))
                print(&amp;quot;  mean of returns  : {:.8f}&amp;quot;.format(self.r_mean_peryear))
                print(&amp;quot;  std of returns   : {:.8f}&amp;quot;.format(self.r_std_peryear))
                
            
    def plot_returns(self):
        if self.df_bt is None:
            pass
        else:
            xlabels = [d.strftime(&#39;%Y-%m&#39;) for idx, d in enumerate(self.df_bt.index) if idx % 12 == 0]
            
            fig, ax = plt.subplots(figsize=(12,6))
            ax.plot(self.df_bt.index.values, self.df_bt[&amp;quot;ror&amp;quot;].values, label=&amp;quot;rate of returns&amp;quot;)
            ax.plot(self.df_bt.index.values, self.df_bt[&amp;quot;ror&amp;quot;].cumsum().values, label=&amp;quot;total capital gain ratio&amp;quot;)
            ax.legend(loc=&amp;quot;upper left&amp;quot;)
            ax.set_xticks(xlabels)
            ax.set_xticklabels(xlabels, rotation=40)
            return fig            
        
    def plot_returns_histgram(self):
        if self.df_bt is None:
            pass
        else:
            x = self.df_bt[&amp;quot;ror&amp;quot;].values
            r_mean = &amp;quot;{:.4f}&amp;quot;.format(x.mean())
            r_std = &amp;quot;{:.4f}&amp;quot;.format(x.std())
            
            fig, ax = plt.subplots(figsize=(12,6))
            ax.hist(x, bins=30, alpha=0.75)
            ax.set_title(f&amp;quot;mean={r_mean}, std={r_std}&amp;quot;)
            return fig
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;42-使い方&#34;&gt;4.2. 使い方&lt;/h3&gt;
&lt;p&gt;対象資産としてTOPIX Core30に含まれる内国株30銘柄を選び，これらに(最適な)投資比率を与えてバックテストしてみましょう．&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/295228/f10c6efd-6301-ee1a-8a68-2e7e495f9bc5.png&#34; alt=&#34;topixcore30_chg_20041031-20201031.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/295228/c0361f2e-ff37-7ed8-b06c-05a4602ac4f0.png&#34; alt=&#34;topixcore30_cum_20041031-20201031.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;まず，&lt;code&gt;pandas_datareader.data.DataReader&lt;/code&gt;でTOPIX Core30構成銘柄のヒストリカルデータを読み込んで，すこし整形します．&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Get historical data
st = &#39;2004/10/31&#39; # start date
ed = &#39;2020/10/31&#39; # end date
stocks_topix30 = [2914, 3382, 4063, 4452, 4502, 
                  4503, 5401, 6301, 6501, 6502, 
                  6752, 6758, 6954, 7201, 7203, 
                  7267, 7751, 8031, 8058, 8306, 
                  8316, 8411, 8604, 8766, 8802, 
                  9021, 9432, 9433, 9437, 9984] # list of tickers in TOPIX Core30
symbols =  [str(s)+&#39;.T&#39; for s in stocks_topix30] 
dfs = []
for symbol in symbols:
    df = pandas_datareader.data.DataReader(symbol, &#39;yahoo&#39;, st, ed) # daily
    df = df.resample(&#39;M&#39;).mean() # daily -&amp;gt; monthly
    df = df.sort_values(by=&#39;Date&#39;, ascending=True)
    df = df.fillna(method=&#39;ffill&#39;) # 1つ前の行の値で埋める
    df = df[[&#39;Close&#39;]].rename(columns={&#39;Close&#39;: symbol})
    dfs.append(df)
df_tpx30 = pd.concat(dfs, axis=1)

# fill nan
for col in df_tpx30.columns:
    st_idx = df_tpx30[col].first_valid_index()
    ed_idx = df_tpx30[col].last_valid_index()
    # for any columns (stocks)
    if df_tpx30[col].isnull().any():
        # New listing (新規上場)
        if st_idx != df_tpx30.index[0]:
            df_tpx30[col] = df_tpx30[col].fillna(df_tpx30[col][st_idx])
        # Delisting (上場廃止)
        if df_tpx30.index[-1] != ed_idx:
            df_tpx30[col] = df_tpx30[col].fillna(df_tpx30[col][ed_idx])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;こんな感じのパネルデータができれば準備OK．&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;df_tpx30.tail()

Date	    2914.T	    3382.T	    4063.T	    4452.T	    4502.T	    4503.T	    5401.T	    6301.T	    6501.T	    6502.T	...	8316.T	    8411.T	    8604.T	    8766.T	8802.T	    9021.T	9432.T	    9433.T	    9437.T	    9984.T																				
2020-06-30	2147.159091	3710.272727	12471.136364	8774.045455	4024.818182	1824.386364	1063.240909	2220.500000	3561.590909	3275.681818	...	3172.181818	1363.545455	486.763636	4795.681818	1701.840909	6502.181818	2500.454545	3184.863636	2913.454545	5287.318182
2020-07-31	1933.785714	3427.333333	12802.619048	8465.428571	3763.000000	1731.785714	998.023810	2239.047619	3371.714286	3450.714286	...	3029.809524	1347.857143	491.138096	4699.238095	1576.000000	5405.428571	2523.428571	3289.142857	2944.547619	6311.333333
2020-08-31	1995.300000	3399.050000	12785.500000	8041.000000	3967.150000	1712.075000	1009.300000	2207.650000	3489.050000	3351.750000	...	3023.050000	1402.250000	531.764998	4779.850000	1644.575000	5106.050000	2570.875000	3285.300000	3066.400000	6453.700000
2020-09-30	1970.425000	3357.000000	13804.250000	8053.550000	3898.200000	1622.550000	1073.164999	2352.600000	3631.650000	2941.300000	...	3090.425000	1402.175000	522.770003	4871.900000	1638.575000	5578.100000	2313.800000	2851.150000	2879.875000	6278.600000
2020-10-31	1989.095238	3412.714286	14189.761905	7731.619048	3568.904762	1489.047619	1070.538095	2432.285714	3605.000000	2783.952381	...	2969.428571	1311.571429	487.642857	4804.000000	1611.214286	4938.571429	2237.142857	2742.738095	3882.095238	6991.047619
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;あとは，自作クラス&lt;code&gt;MarkowitzMinVarianceModel()&lt;/code&gt;のインスタンスオブジェクト&lt;code&gt;model&lt;/code&gt;にパラメータと価格データ&lt;code&gt;df_tpx30&lt;/code&gt;を食わせてバックテストを実行．&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from datetime import datetime

# Const.
ST_BACKTEST = datetime(2011,10,31) # Investment period (start date)
ED_BACKTEST = datetime(2020,10,31) # Investment period (end date)

# Params
params = {
    &amp;quot;window_size&amp;quot;: 36, # 収益率の特性量(平均，分散)の推定に使う期間 (例: 運用時から過去36カ月)
    &amp;quot;rebalance_freq&amp;quot;: 1, # リバランスの頻度 (1か月ごとにポートフォリオ内の投資比率を変更)
    &amp;quot;r_f&amp;quot;: 0.0001 * (1/12) # リスクフリーレート (日本国債10年物利回り:0.01%を単利計算で月次に変換)
}

# Data
st = (ST_BACKTEST - relativedelta(months=params[&amp;quot;window_size&amp;quot;])).strftime(&#39;%Y-%m-%d&#39;)
ed = ED_BACKTEST.strftime(&#39;%Y-%m-%d&#39;)
df = df_tpx30[st:ed]
params[&amp;quot;r_e&amp;quot;]=  df_tpx[st:ed] # 要求期待収益率(r_e)は同時期のTOPIX Indexの収益率とする (df_tpx作成コードは省略)

# Create model
model = MarkowitzMinVarianceModel(df, **params)

# Backtest by model
df_bt = model.backtest()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ここからは，自作クラス&lt;code&gt;MarkowitzMinVarianceModel()&lt;/code&gt;に用意したバックテスト評価用のメソッドを使う．(分析は無限大)&lt;/p&gt;
&lt;h5 id=&#34;ポートフォリオのパフォーマンス評価&#34;&gt;ポートフォリオのパフォーマンス評価&lt;/h5&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Evaluate
model.evaluate_backtest(logging=True)

Portfolio Performance
=======================
Returns per month
  sharpe ratio     : 0.18788996
  mean of returns  : 0.00735206
  std of returns   : 0.03908527
    risk-free rate : 0.00000833
    capgain ratio  : 1.04714952
Returns per year
  sharpe ratio     : 0.65086993
  mean of returns  : 0.08822476
  std of returns   : 0.13539535
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;ポートフォリオの収益率累積収益率プロット&#34;&gt;ポートフォリオの収益率・累積収益率プロット&lt;/h5&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig = model.plot_returns() # Plot returns
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/295228/360b0fc7-2d30-ad33-958e-44bc412026dd.png&#34; alt=&#34;mmvp_tpx30_w=36_plot.png&#34;&gt;&lt;/p&gt;
&lt;h5 id=&#34;ポートフォリオの月次収益率分布&#34;&gt;ポートフォリオの月次収益率分布&lt;/h5&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig = model.plot_returns_histgram()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/295228/608c7327-1312-35d7-0c13-5464a98ade5f.png&#34; alt=&#34;mmvp_tpx30_w=36_hist.png&#34;&gt;&lt;/p&gt;
&lt;h5 id=&#34;ポートフォリオの年次パフォーマンス&#34;&gt;ポートフォリオの年次パフォーマンス&lt;/h5&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df_yearly = model.get_yearly_performance()
df_yearly

date		ror	    std    	    sharpe_ratio
2011-12-31	-0.0001	3.3888e-05	-3.6736
2012-12-31	-0.0444	1.2435e-02	-3.5695
2013-12-31	0.5524	6.5010e-02	8.4973
2014-12-31	0.2448	5.2800e-02	4.6357
2015-12-31	0.0952	4.1543e-02	2.2923
2016-12-31	-0.0970	4.0639e-02	-2.3871
2017-12-31	0.2486	3.0262e-02	8.2144
2018-12-31	-0.0097	3.6705e-02	-0.2644
2019-12-31	0.0254	3.1904e-02	0.7947
2020-12-31	-0.1793	7.3461e-02	-2.4404
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;ポートフォリオ内の各銘柄の収益率&#34;&gt;ポートフォリオ内の各銘柄の収益率(%)&lt;/h5&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df_bt_r = model.get_dfbt_r() # rate_of_returns
df_bt_x = model.get_dfbt_x() # investment_ratio

df1 = df_bt_r * df_bt_x # (rate_of_returns) × (investment_ratio)

df1 = df1.resample(&amp;quot;y&amp;quot;).sum()
df1.columns = [c.replace(&amp;quot;.T&amp;quot;, &amp;quot;&amp;quot;) for c in df1.columns]
df1 = df1.T * 100 # transpose &amp;amp;&amp;amp; convert as pct.
df1.columns = [c.strftime(&#39;%Y&#39;) for c in df1.columns]

plt.figure(figsize=(12,12))
sns.heatmap(df1, cmap=&amp;quot;RdBu&amp;quot;, center=0, annot=True, fmt=&amp;quot;.2f&amp;quot;, cbar=True)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/295228/64fac1bb-3bcc-c673-fbf7-b8ef77482995.png&#34; alt=&#34;mmvp_tpx30_w=36_hm.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;最後まで読んでいただき，ありがとうございます！&lt;/p&gt;
&lt;div class=&#39;pixels-photo&#39;&gt;
&lt;a href=&#39;https://500px.com/photo/284676583/thanks-by-Esther-Moreno&#39; alt=&#39;thanks by Esther Moreno on 500px.com&#39;&gt;
  &lt;img src=&#39;https://drscdn.500px.org/photo/284676583/m%3D900/v2?sig=2c8aeb84d84531b9e9050dab1d209ed269be3747408c2f74e172ac60e7c89f52&#39; alt=&#39;thanks by Esther Moreno on 500px.com&#39; /&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;script type=&#39;text/javascript&#39; src=&#39;https://500px.com/embed.js&#39;&gt;&lt;/script&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;code&gt;stocks_topix30&lt;/code&gt;はTOPIX Core30構成銘柄の証券コードのリストです．構成銘柄は毎年10/31に更新されます．サンプルコードを再現したい場合&lt;code&gt;stocks_topix30 = [2914, 3382, 4063, 4452, 4502, 4503, 5401, 6301, 6501, 6502, 6752, 6758, 6954, 7201, 7203, 7267, 7751, 8031, 8058, 8306, 8316, 8411, 8604, 8766, 8802, 9021, 9432, 9433, 9437, 9984]&lt;/code&gt;としてください． &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Simon N Wood&#39;s &#34;lockdown reading list&#34;</title>
      <link>https://yumaloop.github.io/post/2020-06-30-sw-lockdown-reading-list/</link>
      <pubDate>Tue, 30 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/post/2020-06-30-sw-lockdown-reading-list/</guid>
      <description>&lt;div class=&#39;pixels-photo&#39;&gt;
&lt;a href=&#39;https://500px.com/photo/1023232933/Used-medical-mask-on-the-asphalted-road-Polution-concept--by-Arthur-Lomarainen&#39; alt=&#39;Used medical mask on the asphalted road. Polution concept.  by Arthur Lomarainen on 500px.com&#39;&gt;
  &lt;img src=&#39;https://drscdn.500px.org/photo/1023232933/m%3D900/v2?sig=6fa163cdf4de9e796f0c78bb8608f2cace0ba8849195c687d7b1dbb88177f50c&#39; alt=&#39;Used medical mask on the asphalted road. Polution concept.  by Arthur Lomarainen on 500px.com&#39; /&gt;
  &lt;/a&gt;
  &lt;/div&gt;
  &lt;script type=&#39;text/javascript&#39; src=&#39;https://500px.com/embed.js&#39;&gt;&lt;/script&gt;
&lt;p&gt;&lt;a href=&#34;https://scholar.google.co.uk/citations?user=EskiIyEAAAAJ&amp;amp;hl=en&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Simon Wood&lt;/a&gt;, a leading statistician in UK being famous for the text book of the GAMs introduced the lockdown reading list in his &lt;a href=&#34;https://people.maths.bris.ac.uk/~sw15190/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;homepage&lt;/a&gt;. It looks interesting, so I&amp;rsquo;ll share it here. (most of them are &lt;a href=&#34;https://blackwells.co.uk/bookshop/home&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Blackwell&amp;rsquo;s, books&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blackwells.co.uk/bookshop/product/Collapse-by-Jared-M-Diamond/9780241958681&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Collapse&lt;/a&gt; (Jared Diamond) on how societies are destroyed, not by external forces, but by their failure to adapt their cultural norms to those forces.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blackwells.co.uk/bookshop/product/Thinking-Fast-and-Slow-by-Daniel-Kahneman/9780141033570&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Thinking Fast and Slow&lt;/a&gt; (Daniel Kahneman) on the pitfalls of our intuitive reasoning, especially about risk and uncertainty.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blackwells.co.uk/bookshop/product/Mistakes-Were-Made-But-Not-by-Me-by-Carol-Tavris-Elliot-Aronson/9780544574786&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mistakes were made, but not by me&lt;/a&gt; (Carol Tarvis and Elliot Aronson) on the psychology of sticking with bad decisions.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://poets.org/poem/parable-old-man-and-young&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Parable of the Old Man and the Young&lt;/a&gt; by Wilfred Owen, on consequences of the above.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blackwells.co.uk/bookshop/product/Economics-by-Ha-Joon-Chang-author/9780718197032&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Economics The User&amp;rsquo;s Guide&lt;/a&gt; (Ha-Joon Chang) on what you really need to know about economics, and how it isn&amp;rsquo;t just a scaled up version of household accounting.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blackwells.co.uk/bookshop/product/The-Great-Crash-1929-by-John-Kenneth-Galbraith/9780141038254&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Great Crash 1929&lt;/a&gt; (Galbraith) a delightful disection of economic hubris (and the need for stabilizing controls that we long since did away with).&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blackwells.co.uk/bookshop/product/The-Rise-and-Fall-of-the-Third-Reich-by-William-L-Shirer-author/9781451651683&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Rise and Fall of the Third Reich&lt;/a&gt; (William Shirer) detailing exactly how things went wrong in Germany after the Great Depression.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blackwells.co.uk/bookshop/product/Witch-Hunting-in-Scotland-by-Brian-P-Levack/9780415399432&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Witch hunting in Scotland&lt;/a&gt; (Brian Levack) on the Scottish experience of the great European witchcraft panic (James I/VI wrote a treatise on Witchcraft).&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://people.maths.bris.ac.uk/~sw15190/WT99.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wood and Thomas paper&lt;/a&gt; on the problems of prediction with disease models in the absense of direct validation data (the least impressive item here).&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Recursion of the Capital</title>
      <link>https://yumaloop.github.io/post/2020-06-11-recurrent-structure-in-capita/</link>
      <pubDate>Thu, 11 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/post/2020-06-11-recurrent-structure-in-capita/</guid>
      <description>&lt;div class=&#39;pixels-photo&#39;&gt;
&lt;a href=&#39;https://500px.com/photo/1013781606/The-glare-of-empty-square-by-Sara-Biljana-Gaon&#39; alt=&#39;The glare of empty square by Sara Biljana Gaon on 500px.com&#39;&gt;
  &lt;img src=&#39;https://drscdn.500px.org/photo/1013781606/m%3D900/v2?sig=8fbfac0615a131ce9fe97ebac12eca86ca0e9b9eec82ba6b4fa68ce6da3cfc07&#39; alt=&#39;The glare of empty square by Sara Biljana Gaon on 500px.com&#39; style=&#34;width: 40vw; min-width: 330px;&#34; /&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;script type=&#39;text/javascript&#39; src=&#39;https://500px.com/embed.js&#39;&gt;&lt;/script&gt;
&lt;p&gt;&lt;strong&gt;Self-discriptive system within time change.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The simplest example of self-discriptive systems is the exponential increase. This is because the simplest &amp;ldquo;change&amp;rdquo; of a variable $x$ is a first derivative of its time $dx/dt$, and the simplest form of the function &amp;ldquo;$f(x)$&amp;rdquo; determined by a variable $x$ is a linear one $Cx$.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Case1: Growth is &lt;strong&gt;constant&lt;/strong&gt; with the current state (state is &lt;strong&gt;invariant&lt;/strong&gt; over time)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
\frac{dx}{dt} = C
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Case2: Growth is &lt;strong&gt;linear&lt;/strong&gt; with the current state (state changes &lt;strong&gt;exponentially&lt;/strong&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
\frac{dx}{dt} = Cx
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Case3: Growth is &lt;strong&gt;complex but relative&lt;/strong&gt; to the current state (generalization)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
\frac{dx}{dt} = f(x)
$$&lt;/p&gt;
&lt;h1 id=&#34;actual-situations&#34;&gt;Actual situations&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;1. Money/Capital creates new money/capital&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This is the principle of capital markets and investment. Or what is called Capital Gain. Source of motivation on the lender side.&lt;/p&gt;
&lt;p&gt;これは資本市場と投資の原理．いわゆるキャピタルゲイン．貸し手の動機の源泉．&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;strong&gt;2. Trust/Credit creates new trust/credit&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The most obvious example is banking. Actually, there is a word of credit creation. Lending is gradually increased based on credit. This is the principle of the borrower.&lt;/p&gt;
&lt;p&gt;わかりやすい例は銀行業． 実際，信用創造という言葉があるくらい．信用をもとに，少しずつ貸出を増やす．これは借り手の原理．&lt;/p&gt;
&lt;p&gt;The modern financial system is supported by the principle that capital and credit increase/decrease exponentially. This principle creates a dynamic phenomenon (spiral) that motivates lenders and borrowers and that &amp;ldquo;lending and borrowing exponentially increases/decreases.&amp;rdquo; This is inflation and deflation.&lt;/p&gt;
&lt;p&gt;現代金融システムは，「資本と信用が指数増加/減少する」という原理によって支えられる．この原理は，貸し手と借り手に動機を与え「指数増加/減少する貸金と借金」という現象（スパイラル）を生む．これがインフレとデフレ．&lt;/p&gt;
&lt;p&gt;A vested interest (a large corporation or a large political party) can be established as a vested interest by reproducing credit and achievement in the future by accumulating past credit and achievement.&lt;/p&gt;
&lt;p&gt;既得権益（大企業や大政党）は，過去の信用と実績の積み重ねにより，将来の信用と実績を再生産することで，既得権益として成立する．&lt;/p&gt;
&lt;p&gt;To make matters difficult, &amp;ldquo;trust&amp;rdquo; and &amp;ldquo;achievement&amp;rdquo; are complementary. &amp;ldquo;Trust&amp;rdquo; provides an opportunity to unlock new achievements. The new “achievement” repairs and strengthens trust. In other words, vested interests are invincible unless environmental changes occur.&lt;/p&gt;
&lt;p&gt;厄介なことに「信頼」と「実績」は相補関係にある．「信頼」は新たな実績解除への機会を提供する．新たな「実績」は信頼を補修・強化する．つまり，既得権益は環境変化が起きない限り無敵．&lt;/p&gt;
&lt;p&gt;The first step for new powers (ventures and youth) to scale up is to win trust or to make some achievements.
In addition, it is even better as it causes environmental changes and innovation.&lt;/p&gt;
&lt;p&gt;新興勢力（ベンチャーや若者）がスケールアップするための第一歩は「信頼」を勝ち取るか，「実績」で黙らせるか．
加えて，環境変化やイノベーションを起こすとなお良い．&lt;/p&gt;
&lt;p&gt;As a result,
The risk-loving youths first try to walk the cycle from the trust to the achievement, but
The risk-averse youths first try to walk the cycle from the achievement to the trust.&lt;/p&gt;
&lt;p&gt;結果として，
リスク選好的な若者は，信頼から実績へというサイクルを歩もうとし，
リスク回避的な若者は，実績から信頼へというサイクルを歩もうとする．&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;strong&gt;4. Follower/Fan creates new follower/fan&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In order for super popular corporate brands, entertainers, celebrities, and influencers to be born, their fans/followers need to create new fans/followers.&lt;/p&gt;
&lt;p&gt;超人気な企業ブランドや芸能人，セレブ，インフルエンサーが生まれるためには，彼らのファン/フォロワーが新たなファン/フォロワーを生む必要がある．&lt;/p&gt;
&lt;p&gt;Nowadays, this mechanism has been strengthened in the entertainment industry where globalization by the Internet has been achieved, and in platforms where search and recommendation algorithms that strongly fit past trends are dominant.&lt;/p&gt;
&lt;p&gt;近年，インターネットによるグローバル化が達成されたエンタメ産業や，過去の傾向に強くfitする検索や推薦のアルゴリズムが支配的なプラットホームにおいて，このメカニズムは強化されている．&lt;/p&gt;
&lt;p&gt;The more followers/fans there are, the more followers/fans there are.
The services with more registrants/subscribers tend to have more registrants/subscribers.&lt;/p&gt;
&lt;p&gt;フォロワー/ファンが多い人ほど，フォロワー/ファンが増えやすい．
登録者/購読者の多いサービスほど，登録者/購読者が増えやすい．&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;strong&gt;3. Popularity/Evaluation creates new popularity/evaluation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For products that sell well, the &amp;ldquo;selling&amp;rdquo; state itself becomes valuable.&lt;/p&gt;
&lt;p&gt;売れているものは，売れているということ自体が価値になる．&lt;/p&gt;
&lt;p&gt;This phenomenon is often explained by René Girard&amp;rsquo;s triangular desire from the perspective of consumer sentiment, and by the network externality from the perspective of industrial organization theory.&lt;/p&gt;
&lt;p&gt;この現象は，消費者心理の観点からはルネ・ジラールの欲望の三角形，産業組織論の観点からはネットワーク外部性でよく説明される．&lt;/p&gt;
&lt;p&gt;Additionally, this schema is often misused for stealth marketing, hype, information products, affiliates, etc.&lt;/p&gt;
&lt;p&gt;また，このスキーマは，しばしばステマ，偽客(サクラ)，誇大広告，情報商材，アフィリエイトなどで悪用される．&lt;/p&gt;
&lt;br&gt;
&lt;!--

### 自己組織化 

ファンがアイドルに理想像を提示し求める．
アイドルはファンの期待に応えるため，理想像に近づく．

--&gt;
</description>
    </item>
    
    <item>
      <title>Tencent&#39;s Strategy for the ACG and the Impact on Japan</title>
      <link>https://yumaloop.github.io/post/2020-06-10-tencent-acg/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/post/2020-06-10-tencent-acg/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iZYT.usmZYtc/v0/740x-1.jpg&#34; alt=&#34;img000&#34; title=&#34;img000&#34;&gt;&lt;/p&gt;
&lt;p&gt;中国のTencentが日本のACG(Anime, Comics, Game)産業へ大きな関心を寄せているらしい．
すなわち，コンソールゲームの制作とヒットシリーズのフランチャイズに関する日本の専門知識を吸収しながら，
いくつかのスタジオを買収し，潜在的な投資について交渉中とのこと．詳細は下記記事を参照．&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bloomberg.com/amp/news/articles/2020-06-09/tencent-targets-japan-anime-manga-to-jump-start-global-growth&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tencent Targets Japan Anime, Manga to Jump-Start Global Growth (Bloomberg, June 9, 2020, 5:00 PM EDT)&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>United States Macroeconomic History</title>
      <link>https://yumaloop.github.io/post/2020-05-29-history_of_us_macro_economy/</link>
      <pubDate>Fri, 29 May 2020 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/post/2020-05-29-history_of_us_macro_economy/</guid>
      <description>&lt;p&gt;2020年05月現在，コロナショックで，景気後退が予測されている．
S&amp;amp;P 500 YTDをみると，2018年・2019年と比較しても低調だ．&lt;/p&gt;
&lt;p&gt;アメリカ株は予想に反して高い水準を維持しているが，6月以降の統計結果によっては落ち込む可能性も高い．このポストでは，アメリカのマクロ経済史を振り返り,2021年以降のアメリカ経済について考えてみたい．&lt;/p&gt;
&lt;img src=&#34;{{ site.baseurl }}/assets/img/post/sp-500-ytd-performance-2020-06-12-macrotrends.png&#34;&gt;
&lt;p&gt;&lt;strong&gt;Fig: S&amp;amp;P 500 Index YTD Daily Performance&lt;/strong&gt; &lt;br&gt;
Source: &lt;a href=&#34;https://www.macrotrends.net/2490/sp-500-ytd-performance&#34;&gt;https://www.macrotrends.net/2490/sp-500-ytd-performance&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h1 id=&#34;gdp&#34;&gt;GDP&lt;/h1&gt;
&lt;p&gt;USの実質GDP年間推移(1947 - 2020)をみてみる．インフレ率を補正すると，ほぼ線形に増加していることがわかる．&lt;/p&gt;
&lt;img src=&#34;https://alfred.stlouisfed.org/graph/alfredgraph.png?g=rxJG&#34;&gt;
&lt;p&gt;&lt;strong&gt;Fig: Real GDP, Billions of Chained 2012 Dollars, Annual Rate (1947 - 2020)&lt;/strong&gt; &lt;br&gt;
Source: &lt;a href=&#34;https://alfred.stlouisfed.org/series?seid=GDPC1&#34;&gt;https://alfred.stlouisfed.org/series?seid=GDPC1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;次に，成長率(1次微分)．USの四半期ごとのGDP成長率(YOY)を，戦後(1947-2020)に限定してみてみる．基本的にランダムウォークにみえるが，興味深いのは&lt;strong&gt;1985年ごろを境に，分散が小さくなっていること&lt;/strong&gt;だ．&lt;/p&gt;
&lt;img src=&#34;{{site.baseurl}}/assets/img/post/USGDP1947-2020.png&#34;&gt;
&lt;p&gt;&lt;strong&gt;Fig: United States GDP Growth Rate, YOY (1947 - 2020)&lt;/strong&gt; &lt;br&gt;
Source: &lt;a href=&#34;https://tradingeconomics.com/united-states/gdp-growth&#34;&gt;https://tradingeconomics.com/united-states/gdp-growth&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;FREDのサイトにある，年間のGDP成長率(YOY)も載せておく．&lt;/p&gt;
&lt;img src=&#34;https://fred.stlouisfed.org/graph/fredgraph.png?g=qPxn&#34;&gt;
&lt;p&gt;&lt;strong&gt;Fig: Real GDP, Percent Change from Preceding Period (1930 - 2020)&lt;/strong&gt; &lt;br&gt;
Source: &lt;a href=&#34;https://fred.stlouisfed.org/graph/?g=oM2u&#34;&gt;https://fred.stlouisfed.org/graph/?g=oM2u&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h1 id=&#34;equity-market&#34;&gt;Equity Market&lt;/h1&gt;
&lt;p&gt;米国株式市場の歴史．まず事実として，USの株式市場は長期的に上昇トレンドである．また，S&amp;amp;P 500とDJIAは長期間でみると同じ挙動を示す．&lt;/p&gt;
&lt;img src=&#34;{{ site.baseurl }}/assets/img/post/sp-500-historical-chart-data-2020-06-12-macrotrends.png&#34;&gt;
&lt;p&gt;&lt;strong&gt;Fig: S&amp;amp;P 500 Index (1928.01 - 2020.06)&lt;/strong&gt; &lt;br&gt;
Source: &lt;a href=&#34;https://www.macrotrends.net/2324/sp-500-historical-chart-data&#34;&gt;https://www.macrotrends.net/2324/sp-500-historical-chart-data&lt;/a&gt;&lt;/p&gt;
&lt;img src=&#34;{{ site.baseurl }}/assets/img/post/dow-jones-100-year-historical-chart-2020-06-12-macrotrends.png&#34;&gt;
&lt;p&gt;&lt;strong&gt;Fig: Dow Jones Industrial Average (DJIA) (1915.02 - 2020.06)&lt;/strong&gt; &lt;br&gt;
Source: &lt;a href=&#34;https://www.macrotrends.net/2324/sp-500-historical-chart-data&#34;&gt;https://www.macrotrends.net/2324/sp-500-historical-chart-data&lt;/a&gt;&lt;/p&gt;
&lt;img src=&#34;{{ site.baseurl }}/assets/img/post/nasdaq-historical-chart-2020-06-13-macrotrends.png&#34;&gt;
&lt;p&gt;&lt;strong&gt;Fig: NASDAQ Composite (1971.02 - 2020.06)&lt;/strong&gt; &lt;br&gt;
Source: &lt;a href=&#34;https://www.macrotrends.net/1320/nasdaq-historical-chart&#34;&gt;https://www.macrotrends.net/1320/nasdaq-historical-chart&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;そして，狭い意味での効率的市場仮説を支持するならば，短期(年あるいは月単位)での景気循環は平滑化される．また事実として，あらゆる経済統計がせいぜい100年分しか存在しない以上，景気循環説や効率的市場仮説は正しく検証できない．&lt;/p&gt;
&lt;p&gt;S&amp;amp;P 500は，NYSEとNSDAQの上場銘柄から(流動性の高い大型株の)時価総額を指数化したものなので，DJIAより実体経済(企業部門の利益)を反映している(と言われている)．&lt;/p&gt;
&lt;p&gt;ここで，S&amp;amp;P 500の過去10年間(2010 - 2020)の推移をみてみる．&lt;/p&gt;
&lt;img src=&#34;https://fred.stlouisfed.org/graph/fredgraph.png?g=rtxI&#34;&gt;
&lt;p&gt;&lt;strong&gt;Fig: S&amp;amp;P 500 Index, Daily Close (2010.06.15 - 2020.06.12)&lt;/strong&gt; &lt;br&gt;
Source: &lt;a href=&#34;https://fred.stlouisfed.org/graph/fredgraph.png?g=rtxI,&#34;&gt;https://fred.stlouisfed.org/graph/fredgraph.png?g=rtxI,&lt;/a&gt;&lt;/p&gt;
&lt;br&gt;
&lt;img src=&#34;https://fred.stlouisfed.org/graph/fredgraph.png?g=rtyH&#34;&gt;
&lt;p&gt;&lt;strong&gt;Fig: S&amp;amp;P 500 Index Change from Year Ago (2011.06.13 - 2020.06.12)&lt;/strong&gt; &lt;br&gt;
Source: &lt;a href=&#34;https://fred.stlouisfed.org/graph/fredgraph.png?g=rtyH&#34;&gt;https://fred.stlouisfed.org/graph/fredgraph.png?g=rtyH&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;S&amp;amp;P 500の日別の変化量(YOY)．マイナスとなった期間は2015/08~2016/07，2018/11~2019/05，2020/03~05の3回である．&lt;/p&gt;
&lt;br&gt;
&lt;img src=&#34;https://fred.stlouisfed.org/graph/fredgraph.png?g=rtyj&#34;&gt;
&lt;p&gt;&lt;strong&gt;Fig: S&amp;amp;P 500 Index Change, Daily Close (2010.06.15 - 2020.06.12)&lt;/strong&gt; &lt;br&gt;
Source: &lt;a href=&#34;https://fred.stlouisfed.org/graph/fredgraph.png?g=rtyj&#34;&gt;https://fred.stlouisfed.org/graph/fredgraph.png?g=rtyj&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;S&amp;amp;P 500の日別の変化量(DOD)．&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h1 id=&#34;economic-policy&#34;&gt;Economic Policy&lt;/h1&gt;
&lt;p&gt;株価(cf. S&amp;amp;P 500)は，マクロ経済(GDP)に対する先行指標であると同時に，政府が経済対策を決定するための原因となる（結果ではない）．S&amp;amp;P 500の歴史と，その結果として時の米国政府がどのような経済政策を実施したか，その政策は具体的にどのようなマクロ経済理論によって裏付け(アドバイス)されたか，を考えてみる．&lt;/p&gt;
&lt;p&gt;S&amp;amp;P 500の前年比変動率（1929-2020/03）をみてみよう．&lt;/p&gt;
&lt;img src=&#34;{{ site.baseurl }}/assets/img/post/SP500HistoricalAnnualReturns1928-2020.png&#34;&gt;
&lt;p&gt;&lt;strong&gt;Fig: S&amp;amp;P 500 Historical Annual Returns (1928 - 2020)&lt;/strong&gt; &lt;br&gt;
Source: &lt;a href=&#34;https://www.macrotrends.net/2526/sp-500-historical-annual-returns&#34;&gt;https://www.macrotrends.net/2526/sp-500-historical-annual-returns&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;S&amp;amp;P 500の統計が開始されてから，1929-2019年のちょうど100年間で，年換算で前年比マイナスとなった年は22回しかない．そして，2020年は23番目の年になるかもしれない．全22回をリストアップしてみる．&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;統計上の留意点：S&amp;amp;P 500指数の発行元であるS&amp;amp;P Global社の沿革:&lt;/p&gt;
&lt;p&gt;1941年，スタンダード統計社(Standard Statistics Bureau)とプアー出版社(H.V. and H.W. Poor Co.)が合併してS&amp;amp;P社(Standard&amp;amp;Poor&amp;rsquo;s)が誕生．1957年，S&amp;amp;P 500が誕生．1966年，マグロウヒル社がS&amp;amp;P社を買収し，現在の運営体制 (S&amp;amp;P Global Inc.;  1995年までの旧名:The McGraw-Hill Companies)となった．&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;h4 id=&#34;great-depression-1929-1936-7-years&#34;&gt;Great Depression (1929-1936, 7 years)&lt;/h4&gt;
&lt;p&gt;ケインズ，ニューディール 政策 有効需要&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1929: (-11.91% YoY) 世界恐慌&lt;/li&gt;
&lt;li&gt;1930: (-28.48% YoY) 世界恐慌&lt;/li&gt;
&lt;li&gt;1931: (-47.07% YoY) 世界恐慌&lt;/li&gt;
&lt;li&gt;1932: (-15.15% YoY) 世界恐慌&lt;/li&gt;
&lt;li&gt;1934: (-05.94% YoY) 世界恐慌&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;world-war--1937-1945-8-years&#34;&gt;World War Ⅱ (1937-1945, 8 years)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;1937: (-38.59% YoY) 第二次世界大戦&lt;/li&gt;
&lt;li&gt;1939: (-05.45% YoY) 第二次世界大戦&lt;/li&gt;
&lt;li&gt;1940: (-15.29% YoY) 第二次世界大戦&lt;/li&gt;
&lt;li&gt;1941: (-17.86% YoY) 第二次世界大戦&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;post-war-prosperity-1945-1973-28-years&#34;&gt;Post-war Prosperity (1945-1973, 28 years)&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;60s後半-70s前半のスタグフレーションの結果として，1972,73: ニクソンショック(ブレトン・ウッズ協定崩壊)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;1946: (-11.87% YoY) 戦後&lt;/li&gt;
&lt;li&gt;1953: (-06.62% YoY)&lt;/li&gt;
&lt;li&gt;1957: (-14.31% YoY)&lt;/li&gt;
&lt;li&gt;1960: (-02.97% YoY)&lt;/li&gt;
&lt;li&gt;1962: (-11.81% YoY)&lt;/li&gt;
&lt;li&gt;1966: (-13.09% YoY)&lt;/li&gt;
&lt;li&gt;1969: (-11.36% YoY)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;reaganomics-1974-1990-16-years&#34;&gt;Reaganomics (1974-1990, 16 years)&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;新自由主義，エネルギー規制の緩和，レーガノミクス(所得減税)，プラザ合意，双子の赤字(財政赤字と貿易赤字の拡大)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;1973: (-17.37% YoY) 第一次オイルショック&lt;/li&gt;
&lt;li&gt;1974: (-29.72% YoY) 第一次オイルショック&lt;/li&gt;
&lt;li&gt;1977: (-11.50% YoY)&lt;/li&gt;
&lt;li&gt;1981: (-09.73% YoY) 第二次オイルショック&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;new-economy-1990-2000-10-years&#34;&gt;New Economy (1990-2000, 10 years)&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;情報通信業の牽引，ドットコムバブル，90sのUSGDPは69%増，S&amp;amp;P 500は3倍に上昇&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;1990: (-06.56%  YoY) 通貨危機&lt;/li&gt;
&lt;li&gt;2000: (-10.14% YoY) ドットコムバブル崩壊&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;financial-crisis-2001-2009-8-years&#34;&gt;Financial Crisis (2001-2009, 8 years)&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;2001年の同時多発テロ，2001-2007の住宅バブルとサブプライムローンによる金融危機，ミンスキーの金融不安定仮説，&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;2001: (-13.04% YoY) ドットコムバブル崩壊&lt;/li&gt;
&lt;li&gt;2002: (-23.37% YoY) ドットコムバブル崩壊&lt;/li&gt;
&lt;li&gt;2009: (-38.49% YoY) リーマンショック&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;tech-boom-2010-2019-10years&#34;&gt;Tech boom (2010-2019, 10years)&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;西海岸テック株の牽引，中国経済の台頭&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;2018: (-06.42% YoY) 上海危機&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;new-normal-2020-&#34;&gt;New Normal? (2020-????)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;2020: (-3.34% YTD) コロナショック&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h1 id=&#34;references--source&#34;&gt;References &amp;amp; Source&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.macrotrends.net/2526/sp-500-historical-annual-returns&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;www.macrotrends.net - S&amp;amp;P 500, historical annual returns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.macrotrends.net/1319/dow-jones-100-year-historical-chart&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;www.macrotrends.net - DJIA, 100 years historical chart&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://us.spindices.com/indices/equity/sp-500&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;us.spindices.com - S&amp;amp;P 500&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://us.spindices.com/indices/equity/dow-jones-industrial-average&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;us.spindices.com - Dow Jones Industrial Average&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tradingeconomics.com/united-states/gdp-growth&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tradingeconomics.com - United States GDP Growth Rate&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tradingeconomics.com/spx:ind&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tradingeconomics.com - S&amp;amp;P 500&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tradingeconomics.com/united-states/stock-market&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tradingeconomics.com - Dow Jones Industrial Average&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://fred.stlouisfed.org/graph/?g=oM2u&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;fred.stlouisfed.org - Real Gross Domestic Product&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://fred.stlouisfed.org/series/SP500&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;fred.stlouisfed.org - S&amp;amp;P 500 Index&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://fred.stlouisfed.org/series/DJIA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;fred.stlouisfed.org - Dow Jones Industrial Average&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Economic_history_of_the_United_States&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wikipedia - Economic history of the United States&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/List_of_recessions_in_the_United_States&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wikipedia - List of recessions in the United States&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/List_of_economic_expansions_in_the_United_States&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wikipedia - List of economic expansions in the United States&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Time-steady States on Systems</title>
      <link>https://yumaloop.github.io/post/2020-04-24-time-steady-state-on-system/</link>
      <pubDate>Fri, 24 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/post/2020-04-24-time-steady-state-on-system/</guid>
      <description>&lt;h3 id=&#34;システムと定常状態&#34;&gt;システムと定常状態&lt;/h3&gt;
&lt;p&gt;多くの動的モデル（Dynamic Model-System）は，定常状態（time-steady state）に至ることを目的として設計される．ここで，定常状態とは，「ある変数$X$に作用する，何らかの時変量（parameter $\theta_t$）や関数$L_t(x; \theta)$）が一定値に収束すること」と定義しておく．&lt;/p&gt;
&lt;p&gt;そして，着目している動的モデルが定常状態に至るプロセスは，システム同定（System identification）と呼ばれ，定常状態を示した概念として，均衡（equilibrium）や平衡（balance）と呼ばれる用語が使われる．&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e5%8c%96%e5%ad%a6%e5%8f%8d%e5%bf%9c&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;化学反応&lt;/a&gt;においては、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e5%8f%af%e9%80%86%e5%8f%8d%e5%bf%9c&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;可逆反応&lt;/a&gt;の生成物の変化量と出発物質の変化量が合致した状態を指す。&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e5%8c%96%e5%ad%a6%e5%b9%b3%e8%a1%a1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;化学平衡&lt;/a&gt;を参照。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e5%8a%9b%e5%ad%a6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;力学&lt;/a&gt;においては、物体に加わっている全ての&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e5%8a%9b_%28%e7%89%a9%e7%90%86%e5%ad%a6%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;力&lt;/a&gt;の合力と&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e5%8a%9b%e3%81%ae%e3%83%a2%e3%83%bc%e3%83%a1%e3%83%b3%e3%83%88&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;力のモーメント&lt;/a&gt;の和がともに 0 である状態を平衡と呼ぶ。&lt;a href=&#34;https://ja.wikipedia.org/w/index.php?title=%e5%8a%9b%e5%ad%a6%e7%9a%84%e5%b9%b3%e8%a1%a1&amp;amp;action=edit&amp;amp;redlink=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;力学的平衡&lt;/a&gt;（&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e8%8b%b1%e8%aa%9e&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;英語&lt;/a&gt;: &lt;a href=&#34;https://en.wikipedia.org/wiki/Mechanical_equilibrium&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mechanical equilibrium&lt;/a&gt;）を参照。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e7%86%b1%e5%8a%9b%e5%ad%a6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;熱力学&lt;/a&gt;においては通常、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e7%86%b1%e5%b9%b3%e8%a1%a1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;熱平衡&lt;/a&gt;、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e7%86%b1%e5%8a%9b%e5%ad%a6%e7%9a%84%e5%b9%b3%e8%a1%a1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;力学的平衡&lt;/a&gt;、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e5%8c%96%e5%ad%a6%e5%b9%b3%e8%a1%a1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;化学平衡&lt;/a&gt;の三つを合わせて、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e7%86%b1%e5%8a%9b%e5%ad%a6%e7%9a%84%e5%b9%b3%e8%a1%a1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;熱力学的平衡&lt;/a&gt;とよぶ。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e7%b5%b1%e8%a8%88%e5%8a%9b%e5%ad%a6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;統計力学&lt;/a&gt;においては、系のエネルギー分布が、ボルツマン分布に従うことである。&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e7%86%b1%e5%8a%9b%e5%ad%a6%e7%9a%84%e5%b9%b3%e8%a1%a1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;熱力学的平衡&lt;/a&gt;を参照。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e7%89%a9%e7%90%86%e5%8c%96%e5%ad%a6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;物理化学&lt;/a&gt;においては、複数の物質相から構成される系において、相間の物質の出入りが合い等しい状態を指す。&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e7%9b%b8%e5%b9%b3%e8%a1%a1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;相平衡&lt;/a&gt;を参照。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e9%9b%bb%e6%b0%97%e5%b7%a5%e5%ad%a6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;電気工学&lt;/a&gt;においては、信号源と負荷の間のインピーダンスが合致していることを指す。&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e3%82%a4%e3%83%b3%e3%83%94%e3%83%bc%e3%83%80%e3%83%b3%e3%82%b9%e5%b9%b3%e8%a1%a1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;インピーダンス平衡&lt;/a&gt;を参照。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e9%9b%bb%e6%b0%97%e5%9b%9e%e8%b7%af&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;電気回路&lt;/a&gt;においては、信号回路の双方が接地点に接続されていないことを指す。&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e5%b9%b3%e8%a1%a1%e6%8e%a5%e7%b6%9a&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;平衡接続&lt;/a&gt;を参照。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e6%83%85%e5%a0%b1%e5%b7%a5%e5%ad%a6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;情報工学&lt;/a&gt;においては、データ&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e6%9c%a8%e6%a7%8b%e9%80%a0_%28%e3%83%87%e3%83%bc%e3%82%bf%e6%a7%8b%e9%80%a0%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;木構造&lt;/a&gt;の任意の節においてその配下の節点の数が等しい状態を指す。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e7%94%9f%e6%85%8b%e5%ad%a6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;生態学&lt;/a&gt;においては、生物群集間の分布と個体数の変化が無い状態を指す。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e7%94%9f%e7%90%86%e5%ad%a6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;生理学&lt;/a&gt;においては、水平であることを認知することを指す。&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e5%b9%b3%e8%a1%a1%e6%84%9f%e8%a6%9a&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;平衡感覚&lt;/a&gt;を参照。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e7%b5%8c%e6%b8%88%e5%ad%a6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;経済学&lt;/a&gt;においては、&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e9%9c%80%e8%a6%81%e3%81%a8%e4%be%9b%e7%b5%a6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;需要と供給&lt;/a&gt;が釣り合って&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e4%be%a1%e6%a0%bc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;価格&lt;/a&gt;が不動になることなどを指す。&lt;a href=&#34;https://ja.wikipedia.org/wiki/%e5%9d%87%e8%a1%a1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;均衡&lt;/a&gt;を参照。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;連立(微分)方程式で記述できるため．&lt;/p&gt;
&lt;h3 id=&#34;なぜ線形モデルが有用なのか&#34;&gt;なぜ線形モデルが有用なのか？&lt;/h3&gt;
&lt;p&gt;答えはシンプルで，Taylor展開&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\frac{d x_1}{d t} &amp;amp;= f_1(x_1, \dots, x_n; \theta_1) \\&lt;br&gt;
\frac{d x_2}{d t} &amp;amp;= f_2(x_1, \dots, x_n; \theta_1) \\&lt;br&gt;
&amp;amp;\vdots \\&lt;br&gt;
\frac{d x_n}{d t} &amp;amp;= f_n(x_1, \dots, x_n; \theta_1)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;このモデルが，定常状態にいる場合，&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
f_1 = f_2 = \cdots = f_n = 0
\end{align}
$$&lt;/p&gt;
&lt;p&gt;が成り立つから，$n$個の変数${\bf x} = (x_1, x_2, \dots, x_n)$に対して，$n$個の方程式が得られる．この解がシステムの定常化となる．これを${\bf x}^* = (x_1^*, x_2^*, \dots, x_n^*)$とおくと，$f_1, f_2, \dots, f_n$に対して，点${\bf x}^*$の近傍でTaylor展開が可能になる．&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\frac{d x_1}{d t}
= f_1(x_1, \dots, x_n; \theta_1)
=&amp;amp; a_{11}(x_1 - x_1^*) + a_{12} {(x_2 - x_2^*)} + \cdots a_{1n} {(x_n - x_n^*)} + \\&lt;br&gt;
&amp;amp; a_{111}{(x_1 - x_1^*)}^2 + a_{112}(x_1 - x_1^*)(x_2 - x_2^*) + \cdots + a_{11n}{(x_1 - x_1^*)}^2 + \\&lt;br&gt;
&amp;amp; ~~ \vdots \\&lt;br&gt;
&amp;amp; a_{11\cdots1}{(x_1 - x_1^*)}^n + \cdots \\&lt;br&gt;
\frac{d x_2}{d t}
= f_2(x_1, \dots, x_n; \theta_1)
=&amp;amp; a_{21}(x_1 - x_1^*) + a_{22} {(x_2 - x_2^*)} + \cdots a_{2n} {(x_n - x_n^*)} + \\&lt;br&gt;
&amp;amp; a_{211}{(x_1 - x_1^*)}^2 + a_{212}(x_1 - x_1^*)(x_2 - x_2^*) + \cdots + a_{21n}{(x_1 - x_1^*)}^2 + \\&lt;br&gt;
&amp;amp; ~~ \vdots \\&lt;br&gt;
&amp;amp; a_{21\cdots1}{(x_1 - x_1^*)}^n + \cdots \\ \\&lt;br&gt;
&amp;amp; ~~ \vdots \\ \\&lt;br&gt;
\frac{d x_n}{d t}
= f_n(x_1, \dots, x_n; \theta_1)
=&amp;amp; a_{n1}(x_1 - x_1^*) + a_{n2} {(x_2 - x_2^*)} + \cdots a_{nn} {(x_n - x_n^*)} + \\&lt;br&gt;
&amp;amp; a_{n11}{(x_1 - x_1^*)}^2 + a_{n12}(x_1 - x_1^*)(x_2 - x_2^*) + \cdots + a_{n1n}{(x_1 - x_1^*)}^2 + \\&lt;br&gt;
&amp;amp; ~~ \vdots \\&lt;br&gt;
&amp;amp; a_{n1\cdots1}{(x_1 - x_1^*)}^n + \cdots \\&lt;br&gt;
\end{align}
$$&lt;/p&gt;
&lt;p&gt;つまり，任意の微分可能関数$f_1, f_2, \dots, f_n$によって表現されたダイナミクスをもつ動的モデルは，（定常解の近傍では）任意のn次多項式によって近似できる．これにより，線形システムの妥当性が保証される．一般解は，&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
x_1
=&amp;amp; ~ x_1^*  + C_{11}e^{\lambda_1 t} + C_{12}e^{\lambda_2 t} + \cdots C_{1n}e^{\lambda_n t} + \\&lt;br&gt;
&amp;amp; ~~~~~~~~~~ C_{111}e^{2\lambda_1 t} + C_{112}e^{2\lambda_2 t} + \cdots + C_{11n}e^{2\lambda_n t} + \\&lt;br&gt;
&amp;amp; ~~~~~~~~~~ ~~ \vdots \\&lt;br&gt;
&amp;amp; ~~~~~~~~~~ C_{11\cdots1}e^{n\lambda_1 t} + C_{11\cdots2}e^{n\lambda_2 t} + \cdots + C_{11\cdots n}e^{n\lambda_n t} \\&lt;br&gt;
x_2
=&amp;amp; ~ x_2^*  + C_{21}e^{\lambda_1 t} + C_{22}e^{\lambda_2 t} + \cdots C_{2n}e^{\lambda_n t} + \\&lt;br&gt;
&amp;amp; ~~~~~~~~~~ C_{211}e^{2\lambda_1 t} + C_{212}e^{2\lambda_2 t} + \cdots + C_{11n}e^{2\lambda_n t} + \\&lt;br&gt;
&amp;amp; ~~~~~~~~~~ ~~ \vdots \\&lt;br&gt;
&amp;amp; ~~~~~~~~~~ C_{21\cdots1}e^{n\lambda_1 t} + C_{21\cdots2}e^{n\lambda_2 t} + \cdots + C_{21\cdots n}e^{n\lambda_n t} \\ \\&lt;br&gt;
&amp;amp; ~~~~~~~~~~ ~~ \vdots
\ \&lt;br&gt;
x_n
=&amp;amp; ~ x_n^*  + C_{n1}e^{\lambda_1 t} + C_{n2}e^{\lambda_2 t} + \cdots C_{nn}e^{\lambda_n t} + \\&lt;br&gt;
&amp;amp; ~~~~~~~~~~ C_{n11}e^{2\lambda_1 t} + C_{n12}e^{2\lambda_2 t} + \cdots + C_{n1n}e^{2\lambda_n t} + \\&lt;br&gt;
&amp;amp; ~~~~~~~~~~ ~~ \vdots \\&lt;br&gt;
&amp;amp; ~~~~~~~~~~ C_{n1\cdots1}e^{n\lambda_1 t} + C_{n1\cdots2}e^{n\lambda_2 t} + \cdots + C_{n1\cdots n}e^{n\lambda_n t} \\&lt;br&gt;
\end{align}
$$&lt;/p&gt;
&lt;p&gt;となる．&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;モデルとは何か&#34;&gt;モデルとは何か？&lt;/h3&gt;
&lt;p&gt;つまり，多くの分野において数理モデルとか計量モデルとか呼ばれるものは，以下の手続きを必要とする．&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;定常状態に至ることを目的とする&lt;strong&gt;動的モデル&lt;/strong&gt;を定義する&lt;/li&gt;
&lt;li&gt;モデルの状態変化を&lt;strong&gt;最適化問題(過程&lt;/strong&gt;)として定式化する．&lt;/li&gt;
&lt;li&gt;定常状態への収束が保証された&lt;strong&gt;最適化アルゴリズム&lt;/strong&gt;を考える&lt;/li&gt;
&lt;/ol&gt;
&lt;br&gt;
&lt;h3 id=&#34;移動平均&#34;&gt;移動平均&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;カルマンフィルタ&lt;/li&gt;
&lt;li&gt;Adamに置けるモメンタム&lt;/li&gt;
&lt;li&gt;強化学習の報酬&lt;/li&gt;
&lt;li&gt;ゲーム理論におけるFicticious Play&lt;/li&gt;
&lt;li&gt;株価におけるテクニカル分析移動平均（ARMA）&lt;/li&gt;
&lt;li&gt;(金融工学)バリュエーションにおけるDCF法&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;移動平均とは何か？&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
m_t &amp;amp;= \gamma \cdot m_t − 1+η \cdot \frac{\partial L(w_t)}{\partial w} \\&lt;br&gt;
w_{t+1} &amp;amp;= w_t - m_t
\end{align}
$$&lt;/p&gt;
&lt;p&gt;$$
m_t = g_t + \gamma \cdot g_{t-1} + \gamma^2 \cdot g_{t-2} \cdots + \gamma^t \cdot g_{0}
$$&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>State Space Model &amp; Particle Filter</title>
      <link>https://yumaloop.github.io/post/2020-03-18-particle_filter/</link>
      <pubDate>Wed, 18 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/post/2020-03-18-particle_filter/</guid>
      <description>&lt;div class=&#39;pixels-photo&#39;&gt;
&lt;a href=&#39;https://500px.com/photo/80813059/Flow-of-Time-by-Jimin--Jacob&#39; alt=&#39;Flow of Time... by Jimin  Jacob on 500px.com&#39;&gt;
  &lt;img src=&#39;https://drscdn.500px.org/photo/80813059/m%3D900/v2?sig=9c99293070333accc348ef432437c6c0eeb6b87f5d14199485cae5d51d92e3db&#39; alt=&#39;Flow of Time... by Jimin  Jacob on 500px.com&#39; /&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;script type=&#39;text/javascript&#39; src=&#39;https://500px.com/embed.js&#39;&gt;&lt;/script&gt;
&lt;p&gt;&lt;strong&gt;State Space Model (SSM)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;State Space Model(SSM) is widely used in the field requiring the sequential estimation or online learning.
This model is effective if you consider a system having two different variables; one completely represents the actual state but cannot be observed and the other partially represents the actual state but can be observed. Here, I call the former $x$ (state variable) and the latter $y$ (observation variable).&lt;/p&gt;
&lt;p&gt;In SSM, we intruduce the following equations $F, H$ (or $f, h$) and identify them by observed data sample $[y_1, \dots, y_t]$.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Equation of each state $x_t$ :&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
x_{t+1} &amp;amp;= F(x_t) ~~ (\text{Deterministic process}) \\&lt;br&gt;
x_{t+1} &amp;amp;\sim f(\cdot\vert x_t) ~~ (\text{Stochastic process})
\end{aligned}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Equation of each observation $y_t$ :&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
y_t &amp;amp;= H(x_t) ~~ (\text{Deterministic process}) \\&lt;br&gt;
y_t &amp;amp;\sim h(\cdot \vert x_t) ~~ (\text{Stochastic process})
\end{aligned}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Perticle filter&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;For each $i$ in $[1 \dots M]$&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;(Prediction)&lt;/p&gt;
&lt;p&gt;Derive prediction distribution $f(x_t \vert \cdot)$ depends on particles $\hat{x}_{t-1}$.&lt;/p&gt;
&lt;p&gt;Sample $x^{i}_{t \vert t-1} ~~~ (i = 1, \dots, M)$ following $f(x_t \vert \cdot)$.&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
x^{i}_{t \vert t-1} \sim f(x_t \vert \hat{x}_{t-1})
\end{align}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Likelihood)&lt;/p&gt;
&lt;p&gt;Derive the likelihood of $x^i_{t \vert t-1}$ from given sample data $y_t$ based on $h(\cdot)$&lt;/p&gt;
&lt;p&gt;$$
w^i_t \sim h(y_t \vert x^i_{t \vert t-1})
$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(Resampling)&lt;/p&gt;
&lt;p&gt;Resampe $\hat{x}^i_{t \vert t-1}$ based on the likelihood $w^i_t ~~~ (i=1,\dots,M)$ .&lt;/p&gt;
&lt;p&gt;Derive the filter distribution $p(x_t \vert y_{1:t})$ for any $x_t$:
$$
\begin{aligned}
p(x_t \vert y_{1:t})
&amp;amp;\approx \frac{1}{M} \sum_{i=1}^{M} \delta(x_t - \hat{x}^i_{t \vert t-1}) \\&lt;br&gt;
&amp;amp;\approx \sum_{i=1}^{M} \frac{}{\sum_{i=1}^{M} } \delta(x_t - \hat{x}^i_{t \vert t-1})
\end{aligned}
$$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Free energy and Bayes inference</title>
      <link>https://yumaloop.github.io/post/2020-03-10-free_energy_on_bayes_inference/</link>
      <pubDate>Tue, 10 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/post/2020-03-10-free_energy_on_bayes_inference/</guid>
      <description>&lt;h3 id=&#34;平均場近似と自由エネルギー&#34;&gt;平均場近似と自由エネルギー&lt;/h3&gt;
&lt;p&gt;ある変数$X$のとりうるすべての状態(実現値)$x$に対して，何らかのエネルギー関数$\phi(x)$が与えられたとする．このとき，変数$X$のGibbs分布（Boltzmann分布）:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
p(x)
&amp;amp;= \frac{\exp (- \beta \phi(x))}{\int_X \exp (- \beta \phi(x))}
= \frac{\exp (- \beta \phi(x))}{Z^{\phi}(\beta)}
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;を考える．このとき，Gibbs分布$p(x)$と任意の近似分布$q(x)$とのKL-divergence:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
D_{KL}(q \vert\vert p) := \int_{X} q(x) \log \frac{q(x)}{p(x)}
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;は以下のように分解できる．&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
D_{KL}(q \vert\vert p)
&amp;amp;= \beta \int_X q(x)\phi(x) - \left\{ - \int_X q(x)\log q(x) \right\} + \log \int_X \exp(-\beta \phi(x)) \\&lt;br&gt;
&amp;amp;= \beta~ \mathbb{E}_{x \sim q}[\phi(x)] - H_q(X) + \log Z^{\phi}(\beta) \\&lt;br&gt;
&amp;amp;= \beta~ (\text{Internal energy}) - (\text{Entropy}) + (\text{Const.}) \\&lt;br&gt;
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;いま，近似分布$q(x)$に対する汎関数として，自由エネルギー:&lt;/p&gt;
&lt;p&gt;$$
F^{\phi}(q) := \mathbb{E}_{x \sim q}[\phi(x)] - \frac{1}{\beta}H_q(X) ~~~ (\text{Free energy})
$$&lt;/p&gt;
&lt;p&gt;を定義すれば，&lt;/p&gt;
&lt;p&gt;$$
D_{KL}(q \vert\vert p)  = \beta~ F^{\phi}(q) + \log Z^{\phi}(\beta)
$$&lt;/p&gt;
&lt;p&gt;となるから，$q(x)$による$p(x)$の近似問題は次式で表現できる．&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
\underset{q}{\rm min} ~ D_{KL}(p \vert\vert q) &amp;amp;=
\underset{q}{\rm min} ~ F^{\phi}(q)
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;また．自由エネルギー$F^{\phi}(q)$の最小値は，&lt;/p&gt;
&lt;p&gt;$$
{F^{\phi}}^{*}(q) = - \frac{1}{\beta} \log \int_X \exp (-\beta \phi(x)) = - \frac{1}{\beta} \log Z^{\phi}(\beta)
$$&lt;/p&gt;
&lt;p&gt;となる．すなわち，&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
{F^{\phi}}(q)
= - \frac{1}{\beta} \log Z^{\phi}(\beta)
~~ \Leftrightarrow ~~
D_{KL}(p \vert\vert q) = 0
~~ \Leftrightarrow ~~
p(\cdot) \equiv	 q(\cdot)
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;となる．&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;熱力学統計力学との関係&#34;&gt;熱力学(統計力学)との関係&lt;/h3&gt;
&lt;p&gt;温度$T$，内部エネルギー$U$，エントロピー$S$に対して，Helmholtzの自由エネルギー$F$は以下のように定義される．&lt;/p&gt;
&lt;p&gt;$$
F = U - TS
$$&lt;/p&gt;
&lt;p&gt;$F^{\phi}(q)$の定義式で，$F = F^{\phi}(q)$，$U = \mathbb{E}_{x \sim q}[\phi(x)]$，$S = H_q(X)$とおけば，&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
\beta F &amp;amp;= \beta U - S \\&lt;br&gt;
F &amp;amp;= U - \frac{1}{\beta} S
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;となるから，汎関数$F^{\phi}(q)$は，熱力学におけるHelmholtzの自由エネルギー$F$と類似した形式を持っていることがわかる．なお，Bayes理論において定数$\beta$は「逆温度」と呼ばれるが，これは温度$T$に由来する．&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;bayes脳やfepとの関係&#34;&gt;Bayes脳やFEPとの関係&lt;/h3&gt;
&lt;p&gt;神経科学の分野でK.Fristonによって提唱された自由エネルギー原理(Free energy principle, FEP)は，上にある汎関数$F^{\phi}(q)$を変分推論を組み合わせたものである（と解釈できる）．ここでは，ELBOとの関係にのみ触れておく．&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;ELBOの定義式:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
(\text{Evidence})
&amp;amp;= \log p(y) \\&lt;br&gt;
&amp;amp;\geq \mathbb{E}_{\theta \sim q}\left[ \log p(y, \theta) \right] - \mathbb{E}_{\theta \sim q} \left[ \log q(\theta) \right] \\&lt;br&gt;
&amp;amp;= \mathcal{L}_{ELBO}(q) \\&lt;br&gt;
&amp;amp;= (\text{Evidence Lower Bound})
\end{align}
$$&lt;/p&gt;
&lt;p&gt;と&lt;a href=&#34;[https://www.fil.ion.ucl.ac.uk/~karl/The%20free-energy%20principle%20-%20a%20rough%20guide%20to%20the%20brain.pdf](https://www.fil.ion.ucl.ac.uk/~karl/The free-energy principle - a rough guide to the brain.pdf)&#34;&gt;FristonのCell論文(2009)&lt;/a&gt;にある自由エネルギーの定義式&lt;/p&gt;
&lt;p&gt;$$
F(y) = - \mathbb{E}_{\theta \sim q}[\log p(y,\theta)] + \mathbb{E}_{\theta \sim q}[\log q(\theta)]
$$&lt;/p&gt;
&lt;p&gt;を比べると，以下の関係が得られる．&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
(\text{Surprise})
&amp;amp;= - \log p(y) \\&lt;br&gt;
&amp;amp;\leq - \mathbb{E}_{\theta \sim q}[\log p(y,\theta)] + \mathbb{E}_{\theta \sim q}[\log q(\theta)] \\&lt;br&gt;
&amp;amp;= -\mathcal{L}_{ELBO}(q) \\&lt;br&gt;
&amp;amp;= F(y) \\&lt;br&gt;
&amp;amp;= (\text{Free energy})
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;つまり，Fristonの自由エネルギー$F(y)$は「脳の外部環境$Y$に対する観測データ${\{y_t\}}_{t=1}^{n}$の対数尤度下限(ELBO)に$-1$をかけたもの」である．なお，Bayes推論では,対数尤度$\log p(y)$をエビデンス(Evidence)といい，情報理論では負の対数尤度$-\log p(y)$をサプライズ(Surprise)という．&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.fil.ion.ucl.ac.uk/~karl/The%20free-energy%20principle%20-%20a%20rough%20guide%20to%20the%20brain.pdf&#34;&gt;FristonのCell論文(2009)&lt;/a&gt;にあるエージェントの行動$\alpha$や脳の内部状態$\mu$の更新式:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\alpha^{*} &amp;amp;= \underset{\alpha}{\rm argmin} ~ F(y) \\&lt;br&gt;
\mu^{*} &amp;amp;= \underset{\mu}{\rm argmin} ~ F(y)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;における$F(y)$の最小化は，「脳の外部環境$Y$に対する観測データ${\{y_t\}}_{t=1}^{n}$の対数尤度(Evidence)」を最大化する過程を表している．ELBOとFEPの関係をまとめると以下の表のようになる．&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;原理&lt;/th&gt;
&lt;th&gt;Jensenの不等式&lt;/th&gt;
&lt;th&gt;Bayes推論&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ELBO&lt;/td&gt;
&lt;td&gt;Evidence: $ \log p(y)$ の最大化&lt;/td&gt;
&lt;td&gt;$\text{Evidence} \geq \mathcal{L}_{ELBO}$&lt;/td&gt;
&lt;td&gt;下限$\mathcal{L}_{ELBO}$を最大化&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;FEP&lt;/td&gt;
&lt;td&gt;Surprise: $- \log p(y)$ の最小化&lt;/td&gt;
&lt;td&gt;$\text{Surprise} \leq F$&lt;/td&gt;
&lt;td&gt;上限$F$を最小化&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;執筆時の個人的な理解としては，FEPにおける各変数$\theta, \mu, y, \alpha$の更新規則は，「観測データを用いた最尤推定」そのものだと思っている．論文で提唱されている自由エネルギー$F(y)$最小化は，Variational BayesにおけるELBO最大化と同じであるから，むしろ4つの変数間のループ構造（グラフ表現）の方が重要なのだろう．&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.fil.ion.ucl.ac.uk/~karl/The%20free-energy%20principle%20A%20unified%20brain%20theory.pdf&#34;&gt;FristonのNature論文(2010)&lt;/a&gt;では，自由エネルギー$F(y)$の定義がより複雑化しており，よく理解していない．&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bash script for git push</title>
      <link>https://yumaloop.github.io/post/2020-03-01-bash_script_for_git_push/</link>
      <pubDate>Sun, 01 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/post/2020-03-01-bash_script_for_git_push/</guid>
      <description>&lt;div class=&#39;pixels-photo&#39;&gt;
&lt;a href=&#39;https://500px.com/photo/1020520426/El-charco-de-La-Laja-Puesta-de-Sol-by-Fernando-Lopez&#39; alt=&#39;El charco de La Laja Puesta de Sol by Fernando Lopez on 500px.com&#39;&gt;
&lt;img src=&#39;https://drscdn.500px.org/photo/1020520426/m%3D900/v2?sig=030069c9c40fd7219d4f7b87f23b0e26f2eb84e701e8e867ee04f716d7b3bef6&#39; alt=&#39;El charco de La Laja Puesta de Sol by Fernando Lopez on 500px.com&#39; /&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;script type=&#39;text/javascript&#39; src=&#39;https://500px.com/embed.js&#39;&gt;&lt;/script&gt;
&lt;p&gt;In Git, commit messages are very imoportant to avoid confused commit log in your branch.
But in some small projects that you develope alone, thinking about every commit message might be dull.&lt;/p&gt;
&lt;p&gt;I usualy use the following script to send local data to the remote repository. Please try it.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash
echo -e &amp;quot;\033[0;32mDeploying updates to GitHub...\033[0m&amp;quot;

# Go To .git root directory
cd ~/workspace/{project_name}

# Add all changes to git.
git add .

# Commit changes.
msg=&amp;quot;update repo `date`&amp;quot;
if [ $# -eq 1 ]
  then msg=&amp;quot;$1&amp;quot;
fi
git commit -m &amp;quot;$msg&amp;quot;

# Push source and build repos.
git push origin master
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Deriving ELBO</title>
      <link>https://yumaloop.github.io/post/2020-02-24-deriving-elbo/</link>
      <pubDate>Mon, 24 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/post/2020-02-24-deriving-elbo/</guid>
      <description>&lt;div class=&#39;pixels-photo&#39;&gt;
&lt;a href=&#39;https://500px.com/photo/1020528836/Untitled-by-Vladimir-Maric&#39; alt=&#39;Untitled by Vladimir Maric on 500px.com&#39;&gt;
  &lt;img src=&#39;https://drscdn.500px.org/photo/1020528836/m%3D900/v2?sig=9c4001aaf8730c97353ae102428c6bc64818166778d359c4979d17eb42cf809d&#39; alt=&#39;Untitled by Vladimir Maric on 500px.com&#39; /&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;script type=&#39;text/javascript&#39; src=&#39;https://500px.com/embed.js&#39;&gt;&lt;/script&gt;
&lt;p&gt;Evidence Lower Bound (ELBO) is widely used in variational inference. Recently, according to the massive success of DeepLearning and related models, variational inference (and its technic) gains exposure in the filed of representation learning. For instance, stochastic generative models such as VAE and GAN are famous for their variational aspects.&lt;/p&gt;
&lt;h2 id=&#34;elbo&#34;&gt;ELBO&lt;/h2&gt;
&lt;p&gt;Evidence Lower Bound (ELBO) is a lower bound of Log likelihood of $X$ (Evidence) in the model. The below inequality holds based on Cauchy-Schwartz inequality because of the convexity of log function.&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
(\text{Evidence})
&amp;amp;= \log p(x) \\&lt;br&gt;
&amp;amp;= \log \int_{Z} p(x,z) \\&lt;br&gt;
&amp;amp;= \log \int_{Z} p(x,z) \frac{q(z)}{q(z)} \\&lt;br&gt;
&amp;amp;= \log \int_{Z} q(z) \frac{p(x,z)}{q(z)} \\&lt;br&gt;
&amp;amp;= \log \mathbb{E}_{z \sim q} \left[ \frac{p(x,z)}{q(z)} \right] \\&lt;br&gt;
&amp;amp;\geq \mathbb{E}_{z \sim q} \left[ \log \frac{p(x,z)}{q(z)} \right] \\&lt;br&gt;
&amp;amp;= \mathbb{E}_{z \sim q} \left[ \log p(x,z) \right] + H_q(Z) \\&lt;br&gt;
&amp;amp;= ELBO(q) ~~~ (\text{Evidence Lower Bound, ELBO})
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;So that, we can obtain the optimization formula below.&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
\underset{\theta}{\rm max} ~ \log p_{\theta}(x)
&amp;amp;= \underset{q}{\rm max} ~ ELBO(q)
\end{aligned}
$$&lt;/p&gt;
&lt;h2 id=&#34;kl-divergence-and-elbo&#34;&gt;KL-divergence and ELBO&lt;/h2&gt;
&lt;p&gt;$$
\begin{aligned}
D_{KL}( q(z) \vert\vert p(z \vert x) )
&amp;amp;= \int_{Z} q(z) \frac{q(z)}{p(z \vert x)} \\&lt;br&gt;
&amp;amp;= - H_q(Z) - \mathbb{E}_{z \sim q} \left[ \log p(z|x) \right]
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;ELBO is considered as the difference between Log likelihood  $\log p(x)$ and KL-divergence $D_{KL}( q(z) \vert\vert p(z \vert x) )$ as below.&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
ELBO
&amp;amp;= \mathbb{E}_{z \sim q} \left[ \log p(x,z) \right] + H_q(Z) \\&lt;br&gt;
&amp;amp;= \mathbb{E}_{z \sim q} \left[ \log p(x) + \log p(z|x) \right] + H_q(Z) \\&lt;br&gt;
&amp;amp;= \mathbb{E}_{z \sim q} \left[ \log p(x) \right] + \mathbb{E}_{z \sim q} \left[ \log p(z|x) \right] + H_q(Z) \\&lt;br&gt;
&amp;amp;= \log p(x) + H_q(Z) + \mathbb{E}_{z \sim q} \left[ \log p(z \vert x) \right] \\&lt;br&gt;
&amp;amp;= \log p(x) - D_{KL}( q(z) \vert\vert p(z \vert x) )
\end{align}
$$&lt;/p&gt;
&lt;p&gt;So that, we can obtain the below relation.&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\underset{\theta}{\rm max} ~ \log p_{\theta}(x)
&amp;amp;= \underset{q}{\rm max} ~ ELBO(q) \\&lt;br&gt;
&amp;amp;= \underset{q}{\rm min} ~ D_{KL}( q(z) \vert\vert p(z|x) )
\end{align}
$$
\&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Counterfactual Regret Minimization</title>
      <link>https://yumaloop.github.io/post/2020-02-10-counterfactual-regret-minimization/</link>
      <pubDate>Mon, 10 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/post/2020-02-10-counterfactual-regret-minimization/</guid>
      <description>&lt;p&gt;In this post, I introduce you the Counterfactual Regret Minimization (CFR Algorithm). It is mainly used for the algorithm to figure out the optimal strategy of a extensive-form game with incomplete information such as Poker and Mahjong.&lt;/p&gt;
&lt;h3 id=&#34;extensive-form-game&#34;&gt;Extensive-form Game&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Set, variables
&lt;ul&gt;
&lt;li&gt;$N: $ set of players
&lt;ul&gt;
&lt;li&gt;$i \in N$: player&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$A :$ set of actions
&lt;ul&gt;
&lt;li&gt;$a \in A: $ action&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$H: $set of sequences
&lt;ul&gt;
&lt;li&gt;$h \in H: $ sequences (= possible history of actions, $h = (a_1, \dots, a_t$)&lt;/li&gt;
&lt;li&gt;$Z \subseteq H: $ set of terminal histories. $Z = {z \in H \vert \forall h \in H, z \notin h }$&lt;/li&gt;
&lt;li&gt;$z \in Z$: sea&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Function, relations
&lt;ul&gt;
&lt;li&gt;$u_i: Z \to \mathbb{R}: $ utility function of player $i$&lt;/li&gt;
&lt;li&gt;$\sigma_i: A \to [0,1]$ a strategy of player $i$, probability distribution on action set $A$.&lt;/li&gt;
&lt;li&gt;$\sigma~: A^N \to [0,1]$ a strategy profile, $\sigma := (\sigma_1, \dots, \sigma_N)$&lt;/li&gt;
&lt;li&gt;$\pi^{\sigma}&lt;em&gt;i: H \to [0,1]: $ probability of history $h$ under a strategy $$\sigma&lt;/em&gt;$ of player $i$&lt;/li&gt;
&lt;li&gt;$\pi^{\sigma}: H^N \to [0,1]: $ probability of history $h$ under a strategy profile $\sigma$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then, you can also interplate $u_i$ as the function mapping a storategy profile $\sigma$ to its utility.&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
u_i(\sigma)
&amp;amp;= \sum_{h \in Z} u_i(h) \pi^{\sigma}(h) \\&lt;br&gt;
&amp;amp;= \sum_{h \in Z} u_i(h) \prod_{i \in N} \pi^{\sigma}_i(h)
\end{align}
$$
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h3 id=&#34;nash-equilibrium&#34;&gt;Nash equilibrium&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; $(\text{Nash equilibrium})$&lt;/p&gt;
&lt;p&gt;In $N$-player extensive game, a strategy profile $\acute{\sigma} := (\acute{\sigma_1}, \dots, \acute{\sigma_N})$ is the Nash equilibrium if and only if the followings holds.&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
u_1(\acute{\sigma_1}, \dots, \acute{\sigma_N})
&amp;amp;\geq \underset{\sigma_1}{\rm max} ~ u_1(\sigma_1, \acute{\sigma_{-1}}) \\&lt;br&gt;
u_2(\acute{\sigma_1}, \dots, \acute{\sigma_N})
&amp;amp;\geq \underset{\sigma_2}{\rm max} ~ u_2(\sigma_2, \acute{\sigma_{-2}}) \\&lt;br&gt;
&amp;amp;~ \vdots \\&lt;br&gt;
u_N(\acute{\sigma_1}, \dots, \acute{\sigma_N})
&amp;amp;\geq \underset{\sigma_N}{\rm max} ~ u_N(\sigma_N, \acute{\sigma_{-N}})
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Definition: $\text{(}\varepsilon\text{-Nash equilibrium)}$&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In $N$-player extensive game, a strategy profile $\acute{\sigma} := (\acute{\sigma_1}, \dots, \acute{\sigma_N})$ is the $\varepsilon$-Nash equilibrium if and only if the followings holds when $\forall \varepsilon \geq 0$ is given.&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
u_1(\acute{\sigma_1}, \dots, \acute{\sigma_N}) + \varepsilon
&amp;amp;\geq \underset{\sigma_1}{\rm max} ~ u_1(\sigma_1, \acute{\sigma_{-1}}) \\&lt;br&gt;
u_2(\acute{\sigma_1}, \dots, \acute{\sigma_N}) + \varepsilon
&amp;amp;\geq \underset{\sigma_2}{\rm max} ~ u_2(\sigma_2, \acute{\sigma_{-2}}) \\&lt;br&gt;
&amp;amp;~ \vdots \\&lt;br&gt;
u_N(\acute{\sigma_1}, \dots, \acute{\sigma_N}) + \varepsilon
&amp;amp;\geq \underset{\sigma_N}{\rm max} ~ u_N(\sigma_N, \acute{\sigma_{-N}})
\end{aligned}
$$&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;regret-matching&#34;&gt;Regret matching&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Average overall regret of player $i$ at time $T$：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
R_i^T
:= \underset{\sigma_i^*}{\rm max} ~
\frac{1}{T} \sum_{t=1}^{T} \left( u_i(\sigma_i^*, \sigma_{-i}^{t}) - u_i(\sigma_i^t, \sigma_{-i}^{t}) \right)
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Average strategy for player $i$ from time $1$ to $T$：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
\begin{align}
\overline{\sigma}_i^t(I)(a)
&amp;amp;:= \frac{\sum_{t=1}^{T} \pi_i^{\sigma^t}(I) \cdot \sigma^t(I)(a)}{\sum_{t=1}^{T} \pi_i^{\sigma^t}(I)} \\&lt;br&gt;
&amp;amp;= \frac{\sum_{t=1}^{T} \sum_{h \in I} \pi_i^{\sigma^t}(h) \cdot \sigma^t(h)(a)}{\sum_{t=1}^{T} \sum_{h \in I} \pi_i^{\sigma^t}(h)}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;If the average overall regret holds $R_i^T \leq \varepsilon$, the average strategy $\overline{\sigma}_i^t(I)(a) $ is $2 \varepsilon$-Nash equilibrium for player $i$ in time $t$. So that, in order to derive Nash equilibrium, we should minimize the average overall regret $R_i^T$ or its upper bound $\varepsilon$ according to $R_i^T \to 0 ~~ (\varepsilon \to 0)$.&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;cfr-algorithm&#34;&gt;CFR Algorithm&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Counterfactual utility：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
\begin{align}
u_i(\sigma, I) = \frac{\sum_{h \in H, h&#39; \in Z} \pi_{-i}^{\sigma}(h)\pi^{\sigma}(h,h&#39;)u_i(h) }{\pi_{-i}^{\sigma}(I)}
\end{align}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;immediate counteractual regret of action $a$ in Information set $I$:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
\begin{aligned}
R_{i,imm}^{T}(I, a)
:=
\frac{1}{T} \sum_{t=1}^{T}
\pi_{-i}^{\sigma^t}(I)
\left(
u_i(\sigma^t_{I \to a}, I) - u_i(\sigma^t, I)
\right)
\end{aligned}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Immediate counterfactual regret of Information set $I$：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
\begin{aligned}
R_{i,imm}^{T}(I)
&amp;amp;:= \underset{a \in A(I)}{\rm max} ~
\frac{1}{T} \sum_{t=1}^{T}
\pi_{-i}^{\sigma^t}(I)
\left(
u_i(\sigma^t_{I \to a}, I) - u_i(\sigma^t, I)
\right)
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;The following inequality holds for &lt;strong&gt;the average overall regret&lt;/strong&gt; $R_i^T $ and &lt;strong&gt;the immediate counterfactual regret&lt;/strong&gt;  $R_{i,imm}^{T}(I)$:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
R_i^T
\leq \sum_{I \in \mathcal{I}_i} &amp;amp;R_{i,imm}^{T,+}(I) \\&lt;br&gt;
where ~~~
&amp;amp;R_{i,imm}^{T, +}(I)
:= max(R_{i,imm}^{T}(I), 0)
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;So that, we obtain the sufficient condition of $R_{i,imm}^{T}(I)$  for the average strategy $\overline{\sigma}_i^t(I)(a)$ to become a Nash equilibrium strategy as below.&lt;/p&gt;
&lt;p&gt;$$
\sum_{I \in \mathcal{I}_i} R_{i,imm}^{T,+}(I) \to 0 ~~~ \Rightarrow ~~~ R_i^T \to 0 ~~~ \Rightarrow ~~~ \varepsilon \to 0.
$$&lt;/p&gt;
&lt;p&gt;Now all we need is to minimize the immediate counterfactual regret  $R_{i,imm}^{T}(I)$.&lt;/p&gt;
&lt;p&gt;In addition, as can be seen from the above formula, the computational complexity of the CFR algorithm depends on the number of information sets $I$. Also, to avoid the complete search of game tree (searching all information sets $I$), subsequent algorithms such as CFR + propose an abstraction of the game state.&lt;/p&gt;
&lt;h3 id=&#34;python-code-to-run-cfr-algorithm-for-kuhn-poker&#34;&gt;Python code to run CFR algorithm for Kuhn Poker&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np

# Number of actions a player can take at a decision node.
_N_ACTIONS = 2
_N_CARDS = 3

def main():
    &amp;quot;&amp;quot;&amp;quot;
    Run iterations of counterfactual regret minimization algorithm.
    &amp;quot;&amp;quot;&amp;quot;
    i_map = {}  # map of information sets
    n_iterations = 10000
    expected_game_value = 0

    for _ in range(n_iterations):
        expected_game_value += cfr(i_map)
        for _, v in i_map.items():
            v.next_strategy()

    expected_game_value /= n_iterations
    display_results(expected_game_value, i_map)


def cfr(i_map, history=&amp;quot;&amp;quot;, card_1=-1, card_2=-1, pr_1=1, pr_2=1, pr_c=1):
    &amp;quot;&amp;quot;&amp;quot;
    Counterfactual regret minimization algorithm.
    Parameters
    ----------
    i_map: dict
        Dictionary of all information sets.
    history : [{&#39;r&#39;, &#39;c&#39;, &#39;b&#39;}], str
        A string representation of the game tree path we have taken.
        Each character of the string represents a single action:
        &#39;r&#39;: random chance action
        &#39;c&#39;: check action
        &#39;b&#39;: bet action
    card_1 : (0, 2), int
        player A&#39;s card
    card_2 : (0, 2), int
        player B&#39;s card
    pr_1 : (0, 1.0), float
        The probability that player A reaches `history`.
    pr_2 : (0, 1.0), float
        The probability that player B reaches `history`.
    pr_c: (0, 1.0), float
        The probability contribution of chance events to reach `history`.
    &amp;quot;&amp;quot;&amp;quot;
    if is_chance_node(history):
        return chance_util(i_map)
    if is_terminal(history):
        return terminal_util(history, card_1, card_2)

    n = len(history)
    is_player_1 = n % 2 == 0
    info_set = get_info_set(i_map, card_1 if is_player_1 else card_2, history)

    strategy = info_set.strategy
    if is_player_1:
        info_set.reach_pr += pr_1
    else:
        info_set.reach_pr += pr_2

    # Counterfactual utility per action.
    action_utils = np.zeros(_N_ACTIONS)

    for i, action in enumerate([&amp;quot;c&amp;quot;, &amp;quot;b&amp;quot;]):
        next_history = history + action
        if is_player_1:
            action_utils[i] = -1 * cfr(i_map, next_history, card_1, card_2, pr_1 * strategy[i], pr_2, pr_c)
        else:
            action_utils[i] = -1 * cfr(i_map, next_history, card_1, card_2, pr_1, pr_2 * strategy[i], pr_c)

    # Utility of information set.
    util = sum(action_utils * strategy)
    regrets = action_utils - util
    if is_player_1:
        info_set.regret_sum += pr_2 * pr_c * regrets
    else:
        info_set.regret_sum += pr_1 * pr_c * regrets

    return util

def is_chance_node(history):
    &amp;quot;&amp;quot;&amp;quot;
    Determine if we are at a chance node based on tree history.
    &amp;quot;&amp;quot;&amp;quot;
    return history == &amp;quot;&amp;quot;

def chance_util(i_map):
    expected_value = 0
    n_possibilities = 6
    for i in range(_N_CARDS):
        for j in range(_N_CARDS):
            if i != j:
                expected_value += cfr(i_map, &amp;quot;rr&amp;quot;, i, j, 1, 1, 1/n_possibilities)
    return expected_value/n_possibilities


def is_terminal(history):
    possibilities = { &amp;quot;rrcc&amp;quot;: True, &amp;quot;rrcbc&amp;quot;: True,
                     &amp;quot;rrcbb&amp;quot;: True, &amp;quot;rrbc&amp;quot;: True, &amp;quot;rrbb&amp;quot;: True}
    return history in possibilities

def terminal_util(history, card_1, card_2):
    n = len(history)
    card_player = card_1 if n % 2 == 0 else card_2
    card_opponent = card_2 if n % 2 == 0 else card_1

    if history == &amp;quot;rrcbc&amp;quot; or history == &amp;quot;rrbc&amp;quot;:
        # Last player folded. The current player wins.
        return 1
    elif history == &amp;quot;rrcc&amp;quot;:
        # Showdown with no bets
        return 1 if card_player &amp;gt; card_opponent else -1

    # Showdown with 1 bet
    assert(history == &amp;quot;rrcbb&amp;quot; or history == &amp;quot;rrbb&amp;quot;)
    return 2 if card_player &amp;gt; card_opponent else -2

def card_str(card):
    if card == 0:
        return &amp;quot;J&amp;quot;
    elif card == 1:
        return &amp;quot;Q&amp;quot;
    elif card == 2:
        return &amp;quot;K&amp;quot;

def get_info_set(i_map, card, history):
    &amp;quot;&amp;quot;&amp;quot;
    Retrieve information set from dictionary.
    &amp;quot;&amp;quot;&amp;quot;
    key = card_str(card) + &amp;quot; &amp;quot; + history
    info_set = None

    if key not in i_map:
        info_set = InformationSet(key)
        i_map[key] = info_set
        return info_set

    return i_map[key]

class InformationSet():
    def __init__(self, key):
        self.key = key
        self.regret_sum = np.zeros(_N_ACTIONS)
        self.strategy_sum = np.zeros(_N_ACTIONS)
        self.strategy = np.repeat(1/_N_ACTIONS, _N_ACTIONS)
        self.reach_pr = 0
        self.reach_pr_sum = 0
        
    def next_strategy(self):
        self.strategy_sum += self.reach_pr * self.strategy
        self.strategy = self.calc_strategy()
        self.reach_pr_sum += self.reach_pr
        self.reach_pr = 0

    def calc_strategy(self):
        &amp;quot;&amp;quot;&amp;quot;
        Calculate current strategy from the sum of regret.
        &amp;quot;&amp;quot;&amp;quot;
        strategy = self.make_positive(self.regret_sum)
        total = sum(strategy)
        if total &amp;gt; 0:
            strategy = strategy / total
        else:
            n = _N_ACTIONS
            strategy = np.repeat(1/n, n)

        return strategy

    def get_average_strategy(self):
        &amp;quot;&amp;quot;&amp;quot;
        Calculate average strategy over all iterations. This is the
        Nash equilibrium strategy.
        &amp;quot;&amp;quot;&amp;quot;
        strategy = self.strategy_sum / self.reach_pr_sum

        # Purify to remove actions that are likely a mistake
        strategy = np.where(strategy &amp;lt; 0.001, 0, strategy)

        # Re-normalize
        total = sum(strategy)
        strategy /= total

        return strategy

    def make_positive(self, x):
        return np.where(x &amp;gt; 0, x, 0)

    def __str__(self):
        strategies = [&#39;{:03.2f}&#39;.format(x)
                      for x in self.get_average_strategy()]
        return &#39;{} {}&#39;.format(self.key.ljust(6), strategies)

def display_results(ev, i_map):
    print(&#39;player 1 expected value: {}&#39;.format(ev))
    print(&#39;player 2 expected value: {}&#39;.format(-1 * ev))

    print()
    print(&#39;player 1 strategies:&#39;)
    sorted_items = sorted(i_map.items(), key=lambda x: x[0])
    for _, v in filter(lambda x: len(x[0]) % 2 == 0, sorted_items):
        print(v)
    print()
    print(&#39;player 2 strategies:&#39;)
    for _, v in filter(lambda x: len(x[0]) % 2 == 1, sorted_items):
        print(v)

if __name__ == &amp;quot;__main__&amp;quot;:
    main()

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Setting up a GPU machine for Machine Learning</title>
      <link>https://yumaloop.github.io/post/2020-01-16-setup-gpu-machine-for-ml/</link>
      <pubDate>Thu, 16 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/post/2020-01-16-setup-gpu-machine-for-ml/</guid>
      <description>&lt;div class=&#39;pixels-photo&#39;&gt;
&lt;a href=&#39;https://500px.com/photo/1020504822/PicosDeEuropa-by-Kapan-Tay&#39; alt=&#39;Picos_De_Europa by Kapan Tay on 500px.com&#39;&gt;
  &lt;img src=&#39;https://drscdn.500px.org/photo/1020504822/m%3D900/v2?sig=e8cd1e4a2a70e4a800399c2bfba893fceb8d54699dcaf0ed8a62e1e9979c3f02&#39; alt=&#39;Picos_De_Europa by Kapan Tay on 500px.com&#39; /&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;script type=&#39;text/javascript&#39; src=&#39;https://500px.com/embed.js&#39;&gt;&lt;/script&gt;
&lt;p&gt;In this note, I describe how to install NVIDIA GPU and set up CUDA/cuDNN on Ubuntu 16.04LTS machine that has been clean booted. Also, I write down some linux commands used in debugging, since knowing your machine in detail would lead to resolving some errors related to the machine environment. This article could be updated from time to time.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Example: My Ubuntu GPU machine (2020/01/10)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OS :
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://releases.ubuntu.com/16.04/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ubuntu 16.04.6 LTS&lt;/a&gt; (GNU/Linux 4.4.0-145-generic x86_64)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RAM(16GB) :
&lt;ul&gt;
&lt;li&gt;Memory: &lt;a href=&#34;https://www.newegg.com/kingston-8gb-288-pin-ddr4-sdram/p/N82E16820242069&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kingston 8GB 288-Pin DDR4 SDRAM DDR4 2133 (PC4 17000)&lt;/a&gt; x2&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ROM(250GB):
&lt;ul&gt;
&lt;li&gt;SSD: &lt;a href=&#34;https://www.samsung.com/us/computing/memory-storage/solid-state-drives/mz-750250bw-mz-750250bw/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Samsung SSD 750 EVO 250GB&lt;/a&gt; (/dev/sda)&lt;/li&gt;
&lt;li&gt;HDD: &lt;a href=&#34;https://www.disctech.com/Seagate-Barracuda-2000GB-SATA-Hard-Drive-ST2000DM001&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Seagate Barracuda ST2000DM001 Desktop SATA&lt;/a&gt; (/dev/sdb)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CPU(x8) :
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://ark.intel.com/content/www/us/en/ark/products/88196/intel-core-i7-6700-processor-8m-cache-up-to-4-00-ghz.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Intel Core i7-6700 CPU @ 3.40GHz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;GPU(x1) :
&lt;ul&gt;
&lt;li&gt;NVIDIA &lt;a href=&#34;https://www.nvidia.com/en-us/geforce/products/10series/geforce-gtx-1080/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Geforce GTX 1080&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;NVIDIA CUDA : 10.0.130 (/usr/local/cuda-10.0/)&lt;/li&gt;
&lt;li&gt;NVIDIA cuDNN : 7.4.2.24 (/usr/lib/x86_64-linux-gnu/libcudnn.so.7.4.2)
&lt;ul&gt;
&lt;li&gt;Python3 : 3.6.9 (/usr/bin/python3.6)&lt;/li&gt;
&lt;li&gt;Python2 : 2.7.12 (/usr/bin/python)&lt;/li&gt;
&lt;li&gt;tensorflow 1.13.1 ($HOME/.local/lib/python3.6/site-packages)&lt;/li&gt;
&lt;li&gt;tensorflow-gpu 1.13.1 ($HOME/.local/lib/python3.6/site-packages)&lt;/li&gt;
&lt;li&gt;keras 2.2.4 ($HOME/.local/lib/python3.6/site-packages)&lt;/li&gt;
&lt;li&gt;pytorch 1.2.0 ($HOME/.local/lib/python3.6/site-packages)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;blockquote&gt;
&lt;p&gt;Table of contents&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#OS&#34;&gt;Operating System&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#linux_os&#34;&gt;Checking Linux OS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#linux_dist&#34;&gt;Checking Linux distribution&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#linux_kernel&#34;&gt;Checking Linux kernel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ROM&#34;&gt;Storage (ROM)&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#rom_devices&#34;&gt;Checking ROM devices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#rom_file&#34;&gt;Checking the number of files&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#rom_diskspace&#34;&gt;Checking disk space&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ram&#34;&gt;Memory (RAM)&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#ram_devices&#34;&gt;Checking RAM devices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ram_memspace&#34;&gt;Checking memory space&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cpu&#34;&gt;CPU&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#cpu_devices&#34;&gt;Checking CPU devices&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#gpu&#34;&gt;GPU&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#gpu_devices&#34;&gt;Checking GPU devices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#nvidia-cudacudnn&#34;&gt;NVIDIA driver &amp;amp; CUDA/cuDNN&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#nvidia_nvidiadriver&#34;&gt;Installing NVIDIA driver&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#nvidia_cuda&#34;&gt;Installing NVIDIA CUDA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#nvidia_cuDNN&#34;&gt;Installing NVIDIA cuDNN&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#------&#34;&gt;I/O&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#x11------------dm----&#34;&gt;Checking X11 display manager (DM)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h2 id=&#34;operating-system&#34;&gt;Operating System&lt;/h2&gt;
&lt;h5 id=&#34;checking-linux-os&#34;&gt;Checking Linux OS&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;uname&lt;/code&gt; command shows 1.OS Name, 2.Hostname, 3.Release, 4.Version, 5,Hardware Architecture, 6,CPU type, 7.Platform, 8.OS Name, respectively,&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ uname -a
Linux XXXX 4.4.0-145-generic #171-Ubuntu SMP Tue Mar 26 12:43:40 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux

&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;checking-linux-distribution&#34;&gt;Checking Linux distribution&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;/etc/issue&lt;/code&gt; contains information about Linux distribution.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cat /etc/issue
Ubuntu 16.04.6 LTS \n \l
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;/etc/lsb-release&lt;/code&gt; contains the same information.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cat /etc/lsb-release
DISTRIB_ID=Ubuntu
DISTRIB_RELEASE=16.04 DISTRIB_CODENAME=xenial 
DISTRIB_DESCRIPTION=&amp;quot;Ubuntu 16.04.6 LTS&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;/etc/os-release&lt;/code&gt; contains the same information.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cat /etc/os-release
NAME=“Ubuntu”
VERSION=“16.04.6 LTS (Xenial Xerus)” ID=ubuntu ID_LIKE=debian PRETTY_NAME=“Ubuntu 16.04.6 LTS” VERSION_ID=“16.04&amp;quot; HOME_URL=“http://www.ubuntu.com/” SUPPORT_URL=“http://help.ubuntu.com/” BUG_REPORT_URL=“http://bugs.launchpad.net/ubuntu/” VERSION_CODENAME=xenial UBUNTU_CODENAME=xenial
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;checking-linux-kernel&#34;&gt;Checking Linux kernel&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;/proc/version&lt;/code&gt; contains information about Linux kernel.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cat /proc/version
Linux version 4.4.0-159-generic (buildd@lgw01-amd64-042) (gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.10) ) #187-Ubuntu SMP Thu Aug 1 16:28:06 UTC 2019
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;storage-rom&#34;&gt;Storage (ROM)&lt;/h2&gt;
&lt;p&gt;Storage device (HDD, SSD) and file systems.&lt;/p&gt;
&lt;h5 id=&#34;checking-rom-devices&#34;&gt;Checking ROM devices&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;df&lt;/code&gt; commad shows information about ROM (HDD) devices&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ df -h
Filesystem      Size  Used Avail Use% Mounted on
udev            7.8G     0  7.8G   0% /dev
tmpfs           1.6G   46M  1.6G   3% /run
/dev/sda1       214G  165G   39G  81% /
tmpfs           7.9G  208K  7.9G   1% /dev/shm
tmpfs           5.0M  4.0K  5.0M   1% /run/lock
tmpfs           7.9G     0  7.9G   0% /sys/fs/cgroup
/dev/loop3      384K  384K     0 100% /snap/patchelf/93
/dev/loop1      384K  384K     0 100% /snap/patchelf/87
none            7.9G  2.5M  7.9G   1% /tmp/guest-qyuodw
tmpfs           1.6G   64K  1.6G   1% /run/user/998
/dev/loop4       90M   90M     0 100% /snap/core/8213
/dev/loop0       90M   90M     0 100% /snap/core/8268
tmpfs           1.6G     0  1.6G   0% /run/user/1001
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;checking-the-number-of-files&#34;&gt;Checking the number of files&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;wc&lt;/code&gt; command shows the number of files under the current dir.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ du -hsc *
689M	Research
4.0K	build
106M	dataset
4.0K	docker
9.3M	gym
50M	kaggle
2.6M	latent.gif
2.0G	opencv
122G	workspace
4.0K	ダウンロード
4.0K	テンプレート
4.0K	デスクトップ
4.0K	ドキュメント
4.0K	ビデオ
4.0K	ピクチャ
4.0K	ミュージック
4.0K	公開
125G	合計
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;ファイルのディスク使用量を確認したい&#34;&gt;ファイルのディスク使用量を確認したい&lt;/h5&gt;
&lt;p&gt;df -hコマンドを使う&lt;/p&gt;
&lt;p&gt;カレントディレクトリ直下にあるファイルおよびディレクトリのディスク使用量とその合計を表示する&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ du -hsc *
689M	Research
4.0K	build
106M	dataset
4.0K	docker
9.3M	gym
50M	kaggle
2.6M	latent.gif
2.0G	opencv
122G	workspace
4.0K	ダウンロード
4.0K	テンプレート
4.0K	デスクトップ
4.0K	ドキュメント
4.0K	ビデオ
4.0K	ピクチャ
4.0K	ミュージック
4.0K	公開
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;メモリram&#34;&gt;メモリ（RAM）&lt;/h2&gt;
&lt;h5 id=&#34;メモリデバイスを確認したい&#34;&gt;メモリデバイスを確認したい&lt;/h5&gt;
&lt;p&gt;/proc/meminfoをみる&lt;/p&gt;
&lt;p&gt;メモリの詳細情報が表示される&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ cat /proc/meminfo
MemTotal: 16377200 kB
MemFree: 3077848 kB
MemAvailable: 15767804 kB
Buffers: 363052 kB
Cached: 12274992 kB
SwapCached: 66936 kB
Active: 8048088 kB
Inactive: 4689560 kB
Active(anon): 25860 kB
Inactive(anon): 86584 kB
...
HugePages_Total: 0
HugePages_Free: 0
HugePages_Rsvd: 0
HugePages_Surp: 0
Hugepagesize: 2048 kB
DirectMap4k: 1907316 kB
DirectMap2M: 14815232 kB
DirectMap1G: 0 kB
&lt;/code&gt;&lt;/pre&gt;
&lt;h5 id=&#34;メモリの空き容量を確認したい&#34;&gt;メモリの空き容量を確認したい&lt;/h5&gt;
&lt;p&gt;freeコマンドを使う&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ free
              total        used        free      shared  buff/cache   available
Mem:       16377148     2470228      314496       17140    13592424    13460232
Swap:      16720892      431568    16289324
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;vmstatコマンドを使う&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ vmstat
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0 431584 267696 944212 12638044    0    2   389    15    0    0  6  2 91  0  0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;topコマンドを使う&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ top
top - 15:55:05 up 64 days, 23:12,  5 users,  load average: 1.00, 1.04, 1.07
Tasks: 232 total, 2 running, 230 sleeping, 0 stopped, 0 zombie
%Cpu(s): 9.1 us, 3.5 sy, 0.0 ni, 86.9 id, 0.5 wa, 0.0 hi, 0.0 si, 0.0 st
KiB Mem : 16377148 total,   271964 free,  2527528 used, 13577656 buff/cache
KiB Swap: 16720892 total, 16289228 free,   431664 used. 13403420 avail Mem 

...
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;cpu&#34;&gt;CPU&lt;/h2&gt;
&lt;h5 id=&#34;cpuデバイスを確認したい&#34;&gt;CPUデバイスを確認したい&lt;/h5&gt;
&lt;p&gt;/proc/cpuinfoをみる&lt;/p&gt;
&lt;p&gt;CPUのコアごとに詳細情報が表示される&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
$ cat /proc/cpuinfo
processor : 0
vendor_id : GenuineIntel
cpu family : 6
model : 94
model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz
stepping : 3
microcode : 0xc6
cpu MHz : 800.062
cache size : 8192 KB
physical id : 0
siblings : 8
...
processor : 1
vendor_id : GenuineIntel
cpu family : 6
model : 94
model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz
...
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;gpu&#34;&gt;GPU&lt;/h2&gt;
&lt;h5 id=&#34;gpuデバイスの確認&#34;&gt;GPUデバイスの確認&lt;/h5&gt;
&lt;p&gt;lswsコマンドを使う&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ sudo lshw -C display 
  *-display               
       詳細: VGA compatible controller
       製品: GP104 [GeForce GTX 1080]
       ベンダー: NVIDIA Corporation
       物理ID: 0
       バス情報: pci@0000:01:00.0
       バージョン: a1
       幅: 64 bits
       クロック: 33MHz
       性能: pm msi pciexpress vga_controller bus_master cap_list rom
       設定: driver=nvidia latency=0
       リソース: irq:317 メモリー:de000000-deffffff メモリー:c0000000-cfffffff メモリー:d0000000-d1ffffff IOポート:e000(サイズ=128) メモリー:df000000-df07ffff
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;lspciコマンドを使う&lt;/p&gt;
&lt;p&gt;Linuxに搭載されているPCIバスの情報を表示する．&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ lspci | grep -i nvidia
01:00.0 VGA compatible controller: NVIDIA Corporation GP104 [GeForce GTX 1080] (rev a1)
01:00.1 Audio device: NVIDIA Corporation GP104 High Definition Audio Controller (rev a1)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;nvidiaドライバとcudacudnnの導入&#34;&gt;NVIDIAドライバとCUDA/cuDNNの導入&lt;/h2&gt;
&lt;h5 id=&#34;nvidiaドライバのインストール&#34;&gt;NVIDIAドライバのインストール&lt;/h5&gt;
&lt;p&gt;1.下記リンクから，自分のGPUにあうドライバを検索してダウンロードする．&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.nvidia.co.jp/Download/index.aspx?lang=jp&#34;&gt;https://www.nvidia.co.jp/Download/index.aspx?lang=jp&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://lh4.googleusercontent.com/m4MAKmekqihk5pqTUHLojPX6uzAZoaGoj2d9EazHOSlVxNuradgm_lF-7piupC_j1dBf-PffJ2e1SaDxf215GddSYx_XdaUAyUkucebB5SSyN9ZrGUl7qeqFe0aUxnnBqQxYYeK7&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;たとえば，GPU「&lt;a href=&#34;http://d.hatena.ne.jp/keyword/NVIDIA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NVIDIA&lt;/a&gt; &lt;a href=&#34;http://d.hatena.ne.jp/keyword/GeForce&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GeForce&lt;/a&gt; 1080」に対応したドライバは以下のようになる．&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://lh3.googleusercontent.com/e951y4mwYumub525KR2Um_Cqbb6NxYIpnyThgMyIcClu7nvwHUzF5hGK5l3_4k0lPxf9T9uF33u-0t0cTJeovZFNsjXJkBBzCM1B61i4Kk8_xIBSsTWT0oUexsNDx5_QRFrIDIIj&#34; alt=&#34;img&#34;&gt;．&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;新しく&lt;a href=&#34;http://d.hatena.ne.jp/keyword/GPU&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GPU&lt;/a&gt;ドライバ（&lt;a href=&#34;http://d.hatena.ne.jp/keyword/NVIDIA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NVIDIA&lt;/a&gt;ドライバ）をインストールする前に，既にインストールされている&lt;a href=&#34;http://d.hatena.ne.jp/keyword/GPU&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GPU&lt;/a&gt;ドライバを確認する．&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;aptにNVIDIAドライバを提供しているxorg-edgersレポジトリを追加する．&lt;/p&gt;
&lt;p&gt;aptでNVIDIAドライバ「nvidia-396」をインストールして，マシンを再起動．&lt;/p&gt;
&lt;h2 id=&#34;cudaのインストール&#34;&gt;CUDAのインストール&lt;/h2&gt;
&lt;p&gt;（注意）CUDA・cuDNN・tensorFlow-gpuのバージョンを合わせる必要がある．&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;CUDAの公式ドキュメントをよく読む．&lt;/p&gt;
&lt;p&gt;CUDA Toolkit Documentation &lt;a href=&#34;https://docs.nvidia.com/cuda/index.html&#34;&gt;https://docs.nvidia.com/cuda/index.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;下記リンクから，NVIDIAドライバに対応するCUDAのバージョンを確認する&lt;/p&gt;
&lt;p&gt;CUDA Toolkit Documentation &amp;gt; Release Notes &amp;gt; 1. CUDA Toolkit Major Components &amp;gt; CUDA Driver &lt;a href=&#34;https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html&#34;&gt;https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://lh3.googleusercontent.com/s8gpeKo-VZlCtUROQc6YG1L3ZQ9aJlggnswp_mAAxRFua_Sh0ILtYsa-K4uUYWrjbfgz21EIVJwSrt-StpbGhvpPrxUytW-Xjy146HAo7pmo-SyPT6cP5-YPSFWRHHASmR9xyFon&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;
&lt;p&gt;下記リンクから，tensorflow-&lt;a href=&#34;http://d.hatena.ne.jp/keyword/gpu&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;gpu&lt;/a&gt;に対応するcuDNN/CUDAのバージョンを確認する&lt;/p&gt;
&lt;p&gt;TensorFlow (Linux) - テスト済みのビルド設定&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.tensorflow.org/install/source#linux&#34;&gt;https://www.tensorflow.org/install/source#linux&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://lh6.googleusercontent.com/LrKW-yUDWLZi5-iq1oz0BB_3dpt3hin3yLEyo8V1QtJzV958tWDaYr5RDwJsOniMxotiNqZsCcYa4-kqs3SdSLd7xzD9ABON4b2MT9kIHPbbnL3lP9GcgZpFRTWjVThXPuQMQNUP&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;CUDA・cuDNN・tensorFlow-gpuのバージョン確認を終えた．&lt;/p&gt;
&lt;p&gt;今回は，以下で環境構築をする．&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://d.hatena.ne.jp/keyword/Python&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Python&lt;/a&gt; 3.6.9&lt;/li&gt;
&lt;li&gt;tensorflow-&lt;a href=&#34;http://d.hatena.ne.jp/keyword/gpu&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;gpu&lt;/a&gt; 1.13.1&lt;/li&gt;
&lt;li&gt;CUDA 10.0&lt;/li&gt;
&lt;li&gt;cuDNN 7.4&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;
&lt;p&gt;下記リンクから，自分の環境にあった「CUDA Toolkitパッケージ」を確認し，マシンへダウンロードする．&lt;/p&gt;
&lt;p&gt;CUDA Toolkit Archive &lt;a href=&#34;https://developer.nvidia.com/cuda-toolkit-archive&#34;&gt;https://developer.nvidia.com/cuda-toolkit-archive&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://lh6.googleusercontent.com/6Wg51qcEzuCZ326X81F_48j0pU20MC4qKa0CU847Vw612vZQNUP302zFYWCJ9CA5uKABt6UU7UTLj8M6Kr9ndYKNzT-amTFv3hiWGDakR5gpjFlA3lppzcU-dORL0ojBI6qs-Pv5&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;今回は，CUDA10.0で，マシンの環境として，以下を選択．&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Operating System: Linux&lt;/li&gt;
&lt;li&gt;Architecture: x86_64&lt;/li&gt;
&lt;li&gt;Distribution: Ubuntu&lt;/li&gt;
&lt;li&gt;Version: 16.04&lt;/li&gt;
&lt;li&gt;Installer Type: deb [network]&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://lh6.googleusercontent.com/qkrUa2T8IaJ7IflSrZ6XCyDvHqmoP868EnpDlqOoSoYiMcse_8xteV7gEUsmAS_2GCr7GWUI_rClrw7E6i3RuKUKghWm-L5fT8vST6r9CnCHBtxwIS5LvB18ZfMY1Aet173jSWzC&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;（注意）https://developer.nvidia.com/cuda-downloadsは，最新バージョンのダウンロードリンクなので，ここから安易にCUDAをダウンロードしてはいけない．特に，tensorflow-&lt;a href=&#34;http://d.hatena.ne.jp/keyword/gpu&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;gpu&lt;/a&gt;は，最新のCUDA Toolkitに対応していないので注意する．CUDAとTensorflow-&lt;a href=&#34;http://d.hatena.ne.jp/keyword/gpu&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;gpu&lt;/a&gt;のバージョンがあっていないと，たとえばImportError: libcublas.so.10.0が発生する．&lt;/p&gt;
&lt;p&gt;対応するCUDA Toolkit（CUDA 10.0）の.&lt;a href=&#34;http://d.hatena.ne.jp/keyword/deb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;deb&lt;/a&gt;ファイル(network)は「cuda-repo-ubuntu1604_10.0.130-1_&lt;a href=&#34;http://d.hatena.ne.jp/keyword/amd64&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;amd64&lt;/a&gt;.&lt;a href=&#34;http://d.hatena.ne.jp/keyword/deb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;deb&lt;/a&gt;」となる． この.&lt;a href=&#34;http://d.hatena.ne.jp/keyword/deb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;deb&lt;/a&gt;ファイルをwgetコマンドを使って，マシンへダウンロードする．&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;ダウンロードしたCUDA Toolkitパッケージ(.deb)を，マシンへインストールする&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;dpkgコマンドでCUDA Toolkitパッケージ(.deb)をcudaパッケージとして保存します．さらに，aptコマンドでcudaパッケージをインストールします． 注意：公式に書かれているsudo apt-get install cudaを実行すると自動的に最新版のCUDAがインストールされる．&lt;/p&gt;
&lt;p&gt;これでCUDA Toolkit（CUDA 10.0）のインストールは完了．&lt;/p&gt;
&lt;p&gt;次に，&lt;a href=&#34;http://d.hatena.ne.jp/keyword/%B4%C4%B6%AD%CA%D1%BF%F4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;環境変数&lt;/a&gt;（PATH）を設定する．&lt;/p&gt;
&lt;h5 id=&#34;cudnnのインストール&#34;&gt;cuDNNのインストール&lt;/h5&gt;
&lt;h5 id=&#34;pathチェック&#34;&gt;PATHチェック&lt;/h5&gt;
&lt;h2 id=&#34;ディスプレイ&#34;&gt;ディスプレイ&lt;/h2&gt;
&lt;h5 id=&#34;x11ディスプレイマネージャdmを確認&#34;&gt;X11ディスプレイマネージャ(DM)を確認&lt;/h5&gt;
&lt;p&gt;/etc/X11/default-display-managerをみる&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://yumaloop.github.io/about/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/about/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Whiteside&#39;s Outline Method</title>
      <link>https://yumaloop.github.io/post/2019-11-25-whitesides_outline_method/</link>
      <pubDate>Mon, 25 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/post/2019-11-25-whitesides_outline_method/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://gmwgroup.harvard.edu/people/george-m-whitesides&#34;&gt;Prof. George M. Whitesides&lt;/a&gt; is a top-level researcher on chemistry and also known as one of the highest h-index researchers in the world. He explains his unique writing techniques called Outline Method in the article, &lt;a href=&#34;https://www.tulane.edu/~lamp/whiteside.pdf&#34;&gt;&amp;ldquo;Whitesides&#39; Group: Writing a Paper&amp;rdquo;&lt;/a&gt;. I&amp;rsquo;ve translated that into Japanese and publish it here.&lt;/p&gt;
&lt;h2 id=&#34;original-paper&#34;&gt;Original paper&lt;/h2&gt;
&lt;object data=&#34;https://www.tulane.edu/~lamp/whiteside.pdf&#34; type=&#34;application/pdf&#34; width=&#34;100%&#34; height=&#34;800px&#34;&gt;
    &lt;embed src=&#34;https://www.tulane.edu/~lamp/whiteside.pdf&#34;&gt;
        &lt;p&gt;This browser does not support PDFs. Please download the PDF to view it: &lt;a href=&#34;https://www.tulane.edu/~lamp/whiteside.pdf&#34;&gt;Download PDF&lt;/a&gt;.&lt;/p&gt;
    &lt;/embed&gt;
&lt;/object&gt;
&lt;br&gt;
&lt;h2 id=&#34;japanese--translation&#34;&gt;Japanese  translation&lt;/h2&gt;
&lt;object data=&#34;{{ site.baseurl }}/assets/pdf/whiteside_outline_method_jp.pdf&#34; type=&#34;application/pdf&#34; width=&#34;100%&#34; height=&#34;800px&#34;&gt;
    &lt;embed src=&#34;{{ site.baseurl }}/assets/pdf/whiteside_outline_method_jp.pdf&#34;&gt;
        &lt;p&gt;This browser does not support PDFs. Please download the PDF to view it: &lt;a href=&#34;{{ site.baseurl }}/assets/pdf/whiteside_outline_method_jp.pdf&#34;&gt;Download PDF&lt;/a&gt;.&lt;/p&gt;
    &lt;/embed&gt;
&lt;/object&gt;
</description>
    </item>
    
    <item>
      <title>EM Algorithm</title>
      <link>https://yumaloop.github.io/post/2019-09-25-em-algorithm/</link>
      <pubDate>Wed, 25 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/post/2019-09-25-em-algorithm/</guid>
      <description>&lt;div class=&#39;pixels-photo&#39;&gt;
&lt;a href=&#39;https://500px.com/photo/1002517180/The-algorithm-by-Luca-Rovatti&#39; alt=&#39;The algorithm... by Luca Rovatti on 500px.com&#39;&gt;
  &lt;img src=&#39;https://drscdn.500px.org/photo/1002517180/m%3D900/v2?sig=038077982809b60781286b9e0d94cd3b5dd1dba4a97d80d27302a7829d340618&#39; alt=&#39;The algorithm... by Luca Rovatti on 500px.com&#39; /&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;script type=&#39;text/javascript&#39; src=&#39;https://500px.com/embed.js&#39;&gt;&lt;/script&gt;
&lt;p&gt;​	EM algorithm is &lt;strong&gt;an algorithm for deriving the maximum likelihood estimator (MLE)&lt;/strong&gt;, which is generally applied to statistical methods for incomplete data. Originally, the concept of &lt;strong&gt;“incomplete data and complete data”&lt;/strong&gt; was established to handle missing data, but by extending the definition, it can be applied to cut data, censored data, mixed distribution models, Robust distribution models, and latent data. It can also be applied to variable models, and Bayesian modeling.&lt;/p&gt;
&lt;p&gt;​	Also, a number of statistical approach for clustering and unsupervised learning (eg, k-means, Gaussian mixture models) can be &lt;strong&gt;generalized&lt;/strong&gt; as EM algorithms when focusing on the computational process. In addition, researches on analyzing the EM algorithm from the viewpoint of &lt;strong&gt;information geometry&lt;/strong&gt; has been active, and applying EM algorithm to the stochastic model including an exponential family can be summarized in the form of &lt;strong&gt;e-projection / m-projection&lt;/strong&gt;.&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;1-statistical-inference&#34;&gt;1. Statistical inference&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Objectives: To find out the probability distribution $q(x)$ that a certain variable $x \in X$ follows.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Namely, when considering a stochastic model $p(x \vert \theta)$ determined by the parameter $\theta \in \Theta$ and detecting the optimal parameter $\theta^{*} \in \Theta$ from dataset $ \mathcal{D} := {\{x_i\}}_{i=1}^{n}$, the follwing Approximation holds.&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
x \sim q(x) \approx p(x|\theta)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;This is called a statistical inference (or statistical estimation).&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;2-maximum-likelihood-estimation&#34;&gt;2. Maximum likelihood estimation&lt;/h2&gt;
&lt;p&gt;The most basic algorithm for statistical inference is maximum likelihood estimation (MLE). A log likelihood function of the stochastic model $p(x \vert \theta)$ is defined as&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\ell(\theta | x) := \log p(x | \theta)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;and an empirical objective function of $\theta$:&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
J(\theta) := \frac{1}{n} \sum_{i=1}^{n} \ell(\theta | x_i)
\end{align}
$$&lt;/p&gt;
&lt;p&gt;that depends on dataset $ \mathcal{D} := {{x_i}}_{i=1}^{n}$ can be obtained, MLE of parameter $\theta$ is derived as follows.&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\hat{\theta}_{MLE} = \underset{\theta \in \Theta}{\rm argmax} ~ J(\theta)
\end{align}
$$&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;3-em-algorithm&#34;&gt;3. EM algorithm&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s define the following data categories.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Complete data $Y \in \mathcal{Y}$ : &lt;br&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;not observable&lt;/strong&gt; but completely follows the true distribution $p(y)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Imcomplete data $X \in \mathcal{X}$ : &lt;br&gt;
&lt;ul&gt;
&lt;li&gt;observable but &lt;strong&gt;not completely follows&lt;/strong&gt; the true distribution $p(x)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In general, the relationship complete data $y$ and incomplete data $x$ is a one-to-many relationship. but here, as a convenient assumption, I introduce a latent variable $z \in Z$ to express this constraint, that is assume $y = [x, z]$ holds. Considering the stochastic model for the complete data $x$,&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
p(y | \theta) = p(x,z | \theta)
\end{align}
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Complete data $\{X,Z\} \in \mathcal{X \times Z}$ : &lt;br&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;not observable&lt;/strong&gt; but completely follows the true distribution $p(x,z)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Imcomplete data $X \in \mathcal{X}$ : &lt;br&gt;
&lt;ul&gt;
&lt;li&gt;observable but &lt;strong&gt;not completely follows&lt;/strong&gt; the true distribution $p(x)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;data sample $x_i$ cannot be observed and its likelihood $p(x_i \vert \theta)$ cannot be calculated. However, for pair data sample $\{x_i, z_i\}$ can be observed and its likelihood $p(x_i, z_i \vert \theta)$ can be calculated.&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
p(x_i | \theta)
&amp;amp;= \int_{Z} p(x_i, z_i | \theta) ~ dz \&lt;br&gt;
\end{align}
$$&lt;/p&gt;
&lt;p&gt;By using this formula, the estimated value of $\hat{\theta}_{MLE}$ can be obtained by approximating $p(x,z \vert \theta)$, the likelihood function of complete data $\{x, z\}$. The procedure to derive the estimated value of $\hat{\theta}_{MLE}$ is called EM algorithm because it is an iterative method that repeats E-step and M-step alternately.&lt;/p&gt;
&lt;br&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;EM algorithm&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Initialize $\theta$ with $\theta^{0}$.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For each step $t$:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;E Step&lt;/strong&gt;: Update the expectation value $Q$.&lt;/p&gt;
&lt;p&gt;$$ \begin{aligned} Q(\theta | \theta^{(t)}) &amp;amp;= \mathbb{E}_{z \sim p(z \vert x, \theta^{(t)})} \left[ \log p(x, z \vert \theta)  \right] \\ &amp;amp;\simeq \sum_{i=1}^{n} p(z_i \vert x_i, \theta^{(t)}) \log p(x_i, z_i \vert \theta) \\ &amp;amp;= \sum_{i=1}^{n} p(z_i \vert x_i, \theta^{(t)}) \log p(z_i \vert x_i, \theta) + Const. \end{aligned}$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;M Step&lt;/strong&gt;: Derive the optimal parameter ${\theta}^{(t+1)}$ that maximize $Q$ value.&lt;/p&gt;
&lt;p&gt;$$\begin{aligned} {\theta}^{(t+1)} &amp;amp;= \underset{\theta \in \Theta}{\rm argmax} ~ Q(\theta \vert {\theta}^{(t)}) \end{aligned}$$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Consider the convergence value $\theta^{(\infty)}$ as the algorithm output $\hat{\theta}_{EM}$.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;p&gt;As a result, the estimated value of $\hat{\theta}_{MLE}$ is derived as $\hat{\theta}_{EM}$ and the following holds.&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
\hat{\theta}_{MLE} \approx \hat{\theta}_{EM}, ~~~
p(x|\hat{\theta}_{MLE} ) \approx p(x|\hat{\theta}_{EM} )
\end{align}
$$&lt;/p&gt;
&lt;p&gt;Also, the summarized formula of calculations in E step and M step is as follows.&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;
&lt;p&gt;For each step $t$:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;EM Step&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;$$\begin{align} \theta^{(t+1)} &amp;amp;= \underset{\theta \in \Theta}{\rm argmax} ~ \mathbb{E}_{z \sim p(z \vert x, \theta^{(t)})} \left[ \log p(x, z \vert \theta)  \right] \\ &amp;amp;= \underset{\theta \in \Theta}{\rm argmax} ~ \sum_{i=1}^{n} p(z_i \vert x_i, \theta^{(t)}) \log p(x_i, z_i \vert \theta) \end{align} $$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf&#34;&gt;PRML Chapter 9: Mixture models and EM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://ebsa.ism.ac.jp/ebooks/sites/default/files/ebook/1881/pdf/vol3_ch9.pdf&#34;&gt;9章 EMアルゴリズム - 「21 世紀の統計科学」第 III 巻 日本統計学会, 2008&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://staff.aist.go.jp/s.akaho/papers/josho-main.pdf&#34;&gt;解説 EMアルゴリズムの幾何学 - 赤穂昭太郎, 電子技術総合研究所&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ism.ac.jp/~shiro/papers/books/embook2000.pdf&#34;&gt;EMアルゴリズムと神経回路網, 2000, 統計数理研究所&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>A Capitalist&#39;s Game</title>
      <link>https://yumaloop.github.io/post/2020-04-05-adaptation-strategies-for-capitalism/</link>
      <pubDate>Fri, 21 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/post/2020-04-05-adaptation-strategies-for-capitalism/</guid>
      <description>&lt;div class=&#39;pixels-photo&#39;&gt;
&lt;a href=&#39;https://500px.com/photo/111743009/Frankfurt-Facades-by-Ingo-Juergens&#39; alt=&#39;Frankfurt Facades by Ingo Juergens on 500px.com&#39;&gt;
  &lt;img src=&#39;https://drscdn.500px.org/photo/111743009/m%3D900/v2?sig=01f0547db1460ab77c620ba8181bf7d5ac38c2816f1aa262a9f543309c896823&#39; alt=&#39;Frankfurt Facades by Ingo Juergens on 500px.com&#39; /&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;script type=&#39;text/javascript&#39; src=&#39;https://500px.com/embed.js&#39;&gt;&lt;/script&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h1 id=&#34;1-資本主義の原理&#34;&gt;1. 資本主義の原理&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;資本主義 - Capitalism&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;資本主義とは何か？を考える際には，資本主義ではないものは何か？を考え，その差分をまとめ直せば良い．資本主義の対義語は，共産主義（社会主義）になる．これらを排他的に比較すれば，その定義（政治的概念である&amp;quot;自由&amp;quot;や&amp;quot;民主主義&amp;quot;については除外する）は，次のようにまとめられると思う．&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資本主義：個人が資本を所有できる&lt;/li&gt;
&lt;li&gt;共産主義：個人が資本を所有できない&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;非常にシンプルな定義だが，僕は気に入っているし，この定義を使って文意解釈に苦難したことはない．要するに，何らかの文脈で「資本主義」というワードが使われた場合，そこでは私的財産の所有を認めるか・認めないかが言及されているのだ．&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;Note:&lt;/p&gt;
&lt;p&gt;原理としての「資本主義/共産主義」2元論は非常にシンプルだが，実際の人類史では，これらを現実社会へ制度・システムとして導入し，この原理を駆動させるために，様々な法的・政治的なしくみが提案されている．しかし，再現性がない現象(=史実)については黙るのが科学のルールなので，ここでは立ち入らないこととする．&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;strong&gt;資本 - Capital&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;資本とは，富を生産するための構成要素を指す抽象概念である．&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資本：生産要素&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;資本は，広義では生産要素を指す用語であり，以降で扱うヒト・モノ・カネは全て資本とみなすこともできる．しかし，実際には，その社会的役割や歴史的意味に注意して，これらを分けて扱うことが多い．これは経済学が，自然科学ではなく社会科学たる所以である．すなわち，経済学が扱う範疇である「人間社会」の制度・システムには，法や政治が設計理念として深く関わっており，実際的・実用的な分析を行う際には，これらは分離不可能であるということである．&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;Note:&lt;/p&gt;
&lt;p&gt;資本によって，我々が生産しているもの(=富)とは何か？という疑問が残る．結論から言うと，僕はまだ理解できていない（詳しい方に教えて欲しい）．以下に現時点での一応の解釈をまとめておく&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;アダム・スミスの時代に，当時の理論家は（抽象的な概念としての）「富」を理解するために思考を重ねた．その結果，国家における「富」を説明する際に，観測可能なもののうち，もっとも妥当な指標は，資本(=生産要素)だった．そのため「国家の富∝国家の生産力」と仮定し，その国の資本に注目した．&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;なお，「観測できない事実」については問題の範疇外とするか，あるいは妥当な仮定をおいて探求を進めるのが経験科学の作法なので，ここでは立ち入らないこととする．&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;strong&gt;取引と市場 - Trading &amp;amp; markets&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我々が，経済学的視点で社会をみるとき，それはすなわち，我々が「取引」に着目することを意味する．「取引」とは「資本(=生産要素)の所有権の交換」であり，取引の傾向を分析することで，経済のミクロな状態を推定することができる．さらに，取引の集合に対して「市場」という概念を与え，取引の統計的傾向を分析することで，経済のマクロな状態を推定することができる．&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;h1 id=&#34;2-資本主義社会に対する個人の適合戦略&#34;&gt;2. 資本主義社会に対する個人の適合戦略&lt;/h1&gt;
&lt;p&gt;ここからは，資本主義の原理を踏まえた上で，われわれ個人が取るべき戦略について考えてみようと思う．ここでいう「戦略」とは，「行動選択」と同義である．なお，実際の社会で考慮すべき個別具体的な条件は考えず，あくまで資本主義の&amp;quot;原理&amp;quot;を表現するためのモデルとして，ゲームを導入していることに注意してほしい．&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;資本主義ゲーム - The capitalist&amp;rsquo;s game&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;個人にとって重要な問題は，ミクロな社会状況に対して，科学的な視点をもち，合理的に意思決定・行動選択を行うことである．ここでは，資本主義の原理を踏まえた以下のようなゲームを考えて，個人の適合戦略を考えてみる．&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;社会：ゲーム世界&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;個人：プレイヤー&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;資本：プレイヤーの所有アイテム&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;資本主義経済：ゲームルール&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;取引：資本の所有権の交換&lt;/li&gt;
&lt;li&gt;市場：取引の集合&lt;/li&gt;
&lt;li&gt;価値：市場から統計的に推定される各資本の評価値&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;このゲームにおける各プレイヤーの目標は，&lt;strong&gt;「市場価値」が常に最大となるように所有する資本を選択し続けること&lt;/strong&gt;となる．ここで，「市場価値」とは，ゲーム参加者によって行われる取引（資本の所有権の交換）データ全体から，リアルタイムで統計的に推定された，各資本の評価値である．&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;Note:&lt;/p&gt;
&lt;p&gt;資本価値の定義に「評価値」という表現を使ったが，これは一体何なのか？各資本の評価値は，取引が行われる市場によって異なるが，その算定メカニズムは「需要」と「供給」という抽象概念で説明される．例として，株式市場では，企業の所有権（株式）に対して評価値（株価）を与えているが，これは需要（買い注文）と供給（売り注文）によって算定される．&lt;/p&gt;
&lt;br&gt;
&lt;br&gt;
&lt;p&gt;&lt;strong&gt;代表的な資本: ヒト・モノ・カネ&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;資本の分類については，法的分類や会計学的分類など種々である．ここでは，資本をヒト・モノ・カネに分けて，その具体例を考えてみる．&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;＊代表的な資本（=私的財産）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ヒト（個人）：法的制約を根拠とした価値を持つ．&lt;/p&gt;
&lt;p&gt;​	cf) 経済取引における行動主体　cf) 法人&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;モノ（消費財，生産財）：物理的制約を根拠とした価値をもつ．&lt;/p&gt;
&lt;p&gt;​	cf) サービスも含む　ex）金・石油・土地　&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;カネ（現金，有価証券）：モノ・ヒトとの交換可能性により価値を持つ．&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;p&gt;＊代表的な市場（=価値を測る評価関数）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ヒト：労働市場/雇用市場&lt;/li&gt;
&lt;li&gt;モノ：財市場　　　　 　&lt;/li&gt;
&lt;li&gt;カネ：資本市場/金融市場&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;p&gt;＊変換規則&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ヒト→カネ（労働）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;カネ→モノ（消費）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;モノ→ヒト（教育）：ここでいうモノ/サービスとは，知識やスキルを指す&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;モノ→カネ（売却）：ほとんどのモノは，評価されない（中古品市場）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;→適切な行動選択&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;＊市場に根ざした保有資本のポジショニング&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ヒト（就職，転職，副業）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;モノ（せどり，車や家，遺産相続）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;カネ（ポートフォリオ設計）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;→適切な現状分析&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;＊生産力(=価値)は，経過時間に対して成長/減衰する&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ヒトの価値：UP/DOWN（知識と技術，管理，人間関係の質/量）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;モノの価値：UP/DOWN（骨董品や古酒，経年劣化）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;カネの価値：UP/DOWN（物価と金利，経済成長と株価）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;→適切な未来予測&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;＊なぜ，金融市場に着目するべきか？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;カネは，法的・物理的制約の影響がもっとも小さい．
&lt;ul&gt;
&lt;li&gt;ヒトは法的制約を受ける：Ex.)労働時間の上限，勤務地の選択&lt;/li&gt;
&lt;li&gt;モノは物理的制約を受ける：Ex.)石油埋蔵量の上限，人口上限&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;→カネの市場価値は，定常状態に収束しないため，もっとも変化が激しい．&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Automatically Login to keio.jp using Selenium on Python</title>
      <link>https://yumaloop.github.io/post/2019-06-21-keiojp-auto-login/</link>
      <pubDate>Fri, 21 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/post/2019-06-21-keiojp-auto-login/</guid>
      <description>&lt;p&gt;Have you ever want to login to keio.jp automatically? Don&amp;rsquo;t you think it is cool? At least I think so and I write down the way to achieve that with Python.&lt;/p&gt;
&lt;br&gt;
&lt;div style=&#34;text-align:center&#34;&gt;
  &lt;video style=&#34;width: 100%;&#34; controls autoplay loop muted&gt;
    &lt;source src=&#34;{{ &#34;/assets/video/keio_login.mp4&#34; | relative_url }}&#34; type=&#34;video/mp4&#34;&gt;
    &lt;p&gt;Your browser does not support the video tag.&lt;/p&gt;
  &lt;/video&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;p&gt;In order to login to keio.jp (Keio Single Sign-On System), it is necessary to satisfy the page transition as below.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://auth.keio.jp&#34;&gt;https://auth.keio.jp&lt;/a&gt; (SSO login page)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://gslbs.adst.keio.ac.jp/student/index.html&#34;&gt;https://gslbs.adst.keio.ac.jp/student/index.html&lt;/a&gt; (Syllabus page)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.edu.keio.jp/ess2/login?&#34;&gt;https://www.edu.keio.jp/ess2/login?&lt;/a&gt; (Class support page)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So, this time, a static web-scraping library like BeautifulSoup is not enough, because it doesn&amp;rsquo;t support the dynamic site with Javascript or page redirection. Then I use &lt;a href=&#34;https://selenium.dev/documentation/en/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Selenium&lt;/a&gt; and &lt;a href=&#34;http://chromedriver.chromium.org/getting-started&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ChromeDriver&lt;/a&gt; in python.&lt;/p&gt;
&lt;br&gt;
&lt;h4 id=&#34;example-1--auto-login-to-keiojp&#34;&gt;Example 1 : Auto login to keio.jp&lt;/h4&gt;
&lt;p&gt;If you are the student in Keio University, you can login to keio.jp automatically. All you need is to assign your email address and password in the below script and run it in command line.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException

ID = &amp;quot;*****&amp;quot; # your email in keio.jp (ex. example@keio.jp)  #
PW = &amp;quot;*****&amp;quot; # your password in keio.jp #

# Optional settings of chrome driver
options = webdriver.ChromeOptions()
options.add_argument(&#39;--headless&#39;)

# Boot chrome driver
driver = webdriver.Chrome(&amp;quot;/usr/local/bin/chromedriver&amp;quot;, options=options)
driver.set_page_load_timeout(15) # Time out 15 sec

# GET (HTML Page)
driver.get(&amp;quot;https://auth.keio.jp&amp;quot;)

# Find elements and POST (send keys to the input tag)
id_element = driver.find_element_by_name(&amp;quot;j_username&amp;quot;)
id_element.send_keys(ID)
pw_element = driver.find_element_by_name(&amp;quot;j_password&amp;quot;)
pw_element.send_keys(PW)

# Click login button
login_button = driver.find_element_by_name(&amp;quot;_eventId_proceed&amp;quot;)
login_button.click()

# GET (HTML Page)
driver.get(&amp;quot;https://gslbs.adst.keio.ac.jp/student/index.html&amp;quot;)

# GET (HTML Page)
driver.get(&amp;quot;https://www.edu.keio.jp/ess2/login?&amp;quot;)

# Close chrome driver
driver.quit()
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;h4 id=&#34;example-2--auto-login-to-twittercom&#34;&gt;Example 2 : Auto login to twitter.com&lt;/h4&gt;
&lt;p&gt;If you have twitter account, you can also login to twitter.com automatically. All you need is to assign your username (@********) and password (********) in the below script and run it in command line.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException

USERNAME=&amp;quot;*****&amp;quot; # your username in twitter #
PASSWORD=&amp;quot;*****&amp;quot; # your password in twitter #

# Optional settings of chrome driver
options = webdriver.ChromeOptions()
options.add_argument(&#39;--headless&#39;)

# Boot chrome driver
driver = webdriver.Chrome(&amp;quot;/usr/local/bin/chromedriver&amp;quot;, options=options)
driver.set_page_load_timeout(15) # Time out 15 sec

# GET (HTML Page)
driver.get(&amp;quot;https://twitter.com/login&amp;quot;)

# Find elements and POST (send keys to the input tag)
username_element = driver.find_element_by_class_name(&#39;js-username-field&#39;)
username_element.send_keys(USERNAME)
password_element = driver.find_element_by_class_name(&#39;js-password-field&#39;)
password_element.send_keys(PASSWORD)

# Click login button
login_button = driver.find_element_by_css_selector(&#39;button.submit.EdgeButton.EdgeButton--primary.EdgeButtom--medium&#39;)
login_button.click()

# Close chrome driver
driver.quit()
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;h4 id=&#34;example-3--auto-search-in-googlecom&#34;&gt;Example 3 : Auto search in google.com&lt;/h4&gt;
&lt;p&gt;If you refer to Selenium Getting started guide, you can aquire the search result with the keyword &amp;ldquo;cheese&amp;rdquo; at google.com with Selenium on Python. (This requires Selenium WebDriver 3.13 or newer.)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support.expected_conditions import presence_of_element_located

# Open web driver (Google Chrome)
driver = webdriver.Firefox()

wait = WebDriverWait(driver, 10) 

# GET HTML page source of google.com
driver.get(&amp;quot;https://google.com/ncr&amp;quot;) # GET 
# POST the keyword &amp;quot;cheese&amp;quot; in &amp;quot;q&amp;quot; element in google.com
driver.find_element_by_name(&amp;quot;q&amp;quot;).send_keys(&amp;quot;cheese&amp;quot; + Keys.RETURN) # POST 

first_result = wait.until(presence_of_element_located((By.CSS_SELECTOR, &amp;quot;h3&amp;gt;div&amp;quot;)))

# Search result as text
print(first_result.get_attribute(&amp;quot;textContent&amp;quot;))

# Close web driver (Google Chrome)
driver.quit()
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The Selenium Browser Automation Project &amp;gt; Getting started &amp;gt; Quick tour&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://selenium.dev/documentation/en/getting_started/quick/#webdriver&#34;&gt;https://selenium.dev/documentation/en/getting_started/quick/#webdriver&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Display All Physical Fonts That Can Be Used As Strings in Java</title>
      <link>https://yumaloop.github.io/post/2018-07-24-java-get-all-fonts/</link>
      <pubDate>Tue, 24 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/post/2018-07-24-java-get-all-fonts/</guid>
      <description>&lt;h3 id=&#34;tldr&#34;&gt;TL;DR&lt;/h3&gt;
&lt;p&gt;Use &lt;code&gt;getLocalGraphicsEnvironment().getAllFonts();&lt;/code&gt; method defined in
&lt;code&gt;java.awt.GraphicsEnvironment&lt;/code&gt; class.&lt;/p&gt;
&lt;h3 id=&#34;cf&#34;&gt;Cf.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/javase/jp/8/docs/api/java/awt/GraphicsEnvironment.html&#34;&gt;https://docs.oracle.com/javase/jp/8/docs/api/java/awt/GraphicsEnvironment.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;p&gt;Code Sample (Java):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import java.awt.Font;
import java.awt.GraphicsEnvironment;

public class Main {
	public static void main(String[] args) throws Exception {
	    Font[] fonts  = GraphicsEnvironment.getLocalGraphicsEnvironment().getAllFonts();
	    for (int i = 0; i &amp;lt; fonts.length; i++) {
	      System.out.print(fonts[i].getFontName() + &amp;quot;, &amp;quot;);
	      System.out.print(fonts[i].getFamily() + &amp;quot;, &amp;quot;);
	      System.out.print(fonts[i].getName());
	      System.out.println();
	    }
	}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
&lt;p&gt;Output Result:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Serif, Serif, Serif,
SansSerif, SansSerif, SansSerif,
Monospaced, Monospaced, Monospaced,
Dialog, Dialog, Dialog,
DialogInput, DialogInput, DialogInput,
.SFNSText, .SF NS Text, .SFNSText,
.SFNSText-Bold, .SF NS Text, .SFNSText-Bold,
AlBayan, Al Bayan, AlBayan,
AlBayan-Bold, Al Bayan, AlBayan-Bold,
AlNile, Al Nile, AlNile,
AlNile-Bold, Al Nile, AlNile-Bold,
AlTarikh, Al Tarikh, AlTarikh,
AmericanTypewriter, American Typewriter, AmericanTypewriter,
AmericanTypewriter-Bold, American Typewriter, AmericanTypewriter-Bold,
AmericanTypewriter-Condensed, American Typewriter, AmericanTypewriter-Condensed,
AmericanTypewriter-CondensedBold, American Typewriter, AmericanTypewriter-CondensedBold,
AmericanTypewriter-CondensedLight, American Typewriter, AmericanTypewriter-CondensedLight,
AmericanTypewriter-Light, American Typewriter, AmericanTypewriter-Light,
AmericanTypewriter-Semibold, American Typewriter, AmericanTypewriter-Semibold,
AndaleMono, Andale Mono, AndaleMono,
Apple-Chancery, Apple Chancery, Apple-Chancery,
AppleBraille, Apple Braille, AppleBraille,
AppleBraille-Outline6Dot, Apple Braille, AppleBraille-Outline6Dot,
AppleBraille-Outline8Dot, Apple Braille, AppleBraille-Outline8Dot,
AppleBraille-Pinpoint6Dot, Apple Braille, AppleBraille-Pinpoint6Dot,
AppleBraille-Pinpoint8Dot, Apple Braille, AppleBraille-Pinpoint8Dot,
AppleColorEmoji, Apple Color Emoji, AppleColorEmoji,
AppleGothic, AppleGothic, AppleGothic,
AppleMyungjo, AppleMyungjo, AppleMyungjo,
AppleSDGothicNeo-Bold, Apple SD Gothic Neo, AppleSDGothicNeo-Bold,
AppleSDGothicNeo-ExtraBold, Apple SD Gothic Neo, AppleSDGothicNeo-ExtraBold,
AppleSDGothicNeo-Heavy, Apple SD Gothic Neo, AppleSDGothicNeo-Heavy,
AppleSDGothicNeo-Light, Apple SD Gothic Neo, AppleSDGothicNeo-Light,
AppleSDGothicNeo-Medium, Apple SD Gothic Neo, AppleSDGothicNeo-Medium,
AppleSDGothicNeo-Regular, Apple SD Gothic Neo, AppleSDGothicNeo-Regular,
AppleSDGothicNeo-SemiBold, Apple SD Gothic Neo, AppleSDGothicNeo-SemiBold,
AppleSDGothicNeo-Thin, Apple SD Gothic Neo, AppleSDGothicNeo-Thin,
AppleSDGothicNeo-UltraLight, Apple SD Gothic Neo, AppleSDGothicNeo-UltraLight,
AppleSymbols, Apple Symbols, AppleSymbols,
Arial-Black, Arial Black, Arial-Black,
Arial-BoldItalicMT, Arial, Arial-BoldItalicMT,
Arial-BoldMT, Arial, Arial-BoldMT,
Arial-ItalicMT, Arial, Arial-ItalicMT,
ArialHebrew, Arial Hebrew, ArialHebrew,
ArialHebrew-Bold, Arial Hebrew, ArialHebrew-Bold,
ArialHebrew-Light, Arial Hebrew, ArialHebrew-Light,
ArialHebrewScholar, Arial Hebrew Scholar, ArialHebrewScholar,
ArialHebrewScholar-Bold, Arial Hebrew Scholar, ArialHebrewScholar-Bold,
ArialHebrewScholar-Light, Arial Hebrew Scholar, ArialHebrewScholar-Light,
ArialMT, Arial, ArialMT,
ArialNarrow, Arial Narrow, ArialNarrow,
ArialNarrow-Bold, Arial Narrow, ArialNarrow-Bold,
ArialNarrow-BoldItalic, Arial Narrow, ArialNarrow-BoldItalic,
ArialNarrow-Italic, Arial Narrow, ArialNarrow-Italic,
ArialRoundedMTBold, Arial Rounded MT Bold, ArialRoundedMTBold,
ArialUnicodeMS, Arial Unicode MS, ArialUnicodeMS,
Athelas-Bold, Athelas, Athelas-Bold,
Athelas-BoldItalic, Athelas, Athelas-BoldItalic,
Athelas-Italic, Athelas, Athelas-Italic,
Athelas-Regular, Athelas, Athelas-Regular,
Avenir-Black, Avenir, Avenir-Black,
Avenir-BlackOblique, Avenir, Avenir-BlackOblique,
Avenir-Book, Avenir, Avenir-Book,
Avenir-BookOblique, Avenir, Avenir-BookOblique,
Avenir-Heavy, Avenir, Avenir-Heavy,
Avenir-HeavyOblique, Avenir, Avenir-HeavyOblique,
Avenir-Light, Avenir, Avenir-Light,
Avenir-LightOblique, Avenir, Avenir-LightOblique,
Avenir-Medium, Avenir, Avenir-Medium,
Avenir-MediumOblique, Avenir, Avenir-MediumOblique,
Avenir-Oblique, Avenir, Avenir-Oblique,
Avenir-Roman, Avenir, Avenir-Roman,
AvenirNext-Bold, Avenir Next, AvenirNext-Bold,
AvenirNext-BoldItalic, Avenir Next, AvenirNext-BoldItalic,
AvenirNext-DemiBold, Avenir Next, AvenirNext-DemiBold,
AvenirNext-DemiBoldItalic, Avenir Next, AvenirNext-DemiBoldItalic,
AvenirNext-Heavy, Avenir Next, AvenirNext-Heavy,
AvenirNext-HeavyItalic, Avenir Next, AvenirNext-HeavyItalic,
AvenirNext-Italic, Avenir Next, AvenirNext-Italic,
AvenirNext-Medium, Avenir Next, AvenirNext-Medium,
AvenirNext-MediumItalic, Avenir Next, AvenirNext-MediumItalic,
AvenirNext-Regular, Avenir Next, AvenirNext-Regular,
AvenirNext-UltraLight, Avenir Next, AvenirNext-UltraLight,
AvenirNext-UltraLightItalic, Avenir Next, AvenirNext-UltraLightItalic,
AvenirNextCondensed-Bold, Avenir Next Condensed, AvenirNextCondensed-Bold,
AvenirNextCondensed-BoldItalic, Avenir Next Condensed, AvenirNextCondensed-BoldItalic,
AvenirNextCondensed-DemiBold, Avenir Next Condensed, AvenirNextCondensed-DemiBold,
AvenirNextCondensed-DemiBoldItalic, Avenir Next Condensed, AvenirNextCondensed-DemiBoldItalic,
AvenirNextCondensed-Heavy, Avenir Next Condensed, AvenirNextCondensed-Heavy,
AvenirNextCondensed-HeavyItalic, Avenir Next Condensed, AvenirNextCondensed-HeavyItalic,
AvenirNextCondensed-Italic, Avenir Next Condensed, AvenirNextCondensed-Italic,
AvenirNextCondensed-Medium, Avenir Next Condensed, AvenirNextCondensed-Medium,
AvenirNextCondensed-MediumItalic, Avenir Next Condensed, AvenirNextCondensed-MediumItalic,
AvenirNextCondensed-Regular, Avenir Next Condensed, AvenirNextCondensed-Regular,
AvenirNextCondensed-UltraLight, Avenir Next Condensed, AvenirNextCondensed-UltraLight,
AvenirNextCondensed-UltraLightItalic, Avenir Next Condensed, AvenirNextCondensed-UltraLightItalic,
Ayuthaya, Ayuthaya, Ayuthaya,
Baghdad, Baghdad, Baghdad,
BanglaMN, Bangla MN, BanglaMN,
BanglaMN-Bold, Bangla MN, BanglaMN-Bold,
BanglaSangamMN, Bangla Sangam MN, BanglaSangamMN,
BanglaSangamMN-Bold, Bangla Sangam MN, BanglaSangamMN-Bold,
Baskerville, Baskerville, Baskerville,
Baskerville-Bold, Baskerville, Baskerville-Bold,
Baskerville-BoldItalic, Baskerville, Baskerville-BoldItalic,
Baskerville-Italic, Baskerville, Baskerville-Italic,
Baskerville-SemiBold, Baskerville, Baskerville-SemiBold,
Baskerville-SemiBoldItalic, Baskerville, Baskerville-SemiBoldItalic,
Beirut, Beirut, Beirut,
BigCaslon-Medium, Big Caslon, BigCaslon-Medium,
BodoniOrnamentsITCTT, Bodoni Ornaments, BodoniOrnamentsITCTT,
BodoniSvtyTwoITCTT-Bold, Bodoni 72, BodoniSvtyTwoITCTT-Bold,
BodoniSvtyTwoITCTT-Book, Bodoni 72, BodoniSvtyTwoITCTT-Book,
BodoniSvtyTwoITCTT-BookIta, Bodoni 72, BodoniSvtyTwoITCTT-BookIta,
BodoniSvtyTwoOSITCTT-Bold, Bodoni 72 Oldstyle, BodoniSvtyTwoOSITCTT-Bold,
BodoniSvtyTwoOSITCTT-Book, Bodoni 72 Oldstyle, BodoniSvtyTwoOSITCTT-Book,
BodoniSvtyTwoOSITCTT-BookIt, Bodoni 72 Oldstyle, BodoniSvtyTwoOSITCTT-BookIt,
BodoniSvtyTwoSCITCTT-Book, Bodoni 72 Smallcaps, BodoniSvtyTwoSCITCTT-Book,
BradleyHandITCTT-Bold, Bradley Hand, BradleyHandITCTT-Bold,
BrushScriptMT, Brush Script MT, BrushScriptMT,
Chalkboard, Chalkboard, Chalkboard,
Chalkboard-Bold, Chalkboard, Chalkboard-Bold,
ChalkboardSE-Bold, Chalkboard SE, ChalkboardSE-Bold,
ChalkboardSE-Light, Chalkboard SE, ChalkboardSE-Light,
ChalkboardSE-Regular, Chalkboard SE, ChalkboardSE-Regular,
Chalkduster, Chalkduster, Chalkduster,
Charter-Black, Charter, Charter-Black,
Charter-BlackItalic, Charter, Charter-BlackItalic,
Charter-Bold, Charter, Charter-Bold,
Charter-BoldItalic, Charter, Charter-BoldItalic,
Charter-Italic, Charter, Charter-Italic,
Charter-Roman, Charter, Charter-Roman,
Cochin, Cochin, Cochin,
Cochin-Bold, Cochin, Cochin-Bold,
Cochin-BoldItalic, Cochin, Cochin-BoldItalic,
Cochin-Italic, Cochin, Cochin-Italic,
ComicSansMS, Comic Sans MS, ComicSansMS,
ComicSansMS-Bold, Comic Sans MS, ComicSansMS-Bold,
Copperplate, Copperplate, Copperplate,
Copperplate-Bold, Copperplate, Copperplate-Bold,
Copperplate-Light, Copperplate, Copperplate-Light,
CorsivaHebrew, Corsiva Hebrew, CorsivaHebrew,
CorsivaHebrew-Bold, Corsiva Hebrew, CorsivaHebrew-Bold,
Courier, Courier, Courier,
Courier-Bold, Courier, Courier-Bold,
Courier-BoldOblique, Courier, Courier-BoldOblique,
Courier-Oblique, Courier, Courier-Oblique,
CourierNewPS-BoldItalicMT, Courier New, CourierNewPS-BoldItalicMT,
CourierNewPS-BoldMT, Courier New, CourierNewPS-BoldMT,
CourierNewPS-ItalicMT, Courier New, CourierNewPS-ItalicMT,
CourierNewPSMT, Courier New, CourierNewPSMT,
DFKaiShu-SB-Estd-BF, BiauKai, DFKaiShu-SB-Estd-BF,
DFWaWaSC-W5, Wawati SC, DFWaWaSC-W5,
DFWaWaTC-W5, Wawati TC, DFWaWaTC-W5,
DINAlternate-Bold, DIN Alternate, DINAlternate-Bold,
DINCondensed-Bold, DIN Condensed, DINCondensed-Bold,
Damascus, Damascus, Damascus,
DamascusBold, Damascus, DamascusBold,
DamascusLight, Damascus, DamascusLight,
DamascusMedium, Damascus, DamascusMedium,
DamascusSemiBold, Damascus, DamascusSemiBold,
DecoTypeNaskh, DecoType Naskh, DecoTypeNaskh,
DevanagariMT, Devanagari MT, DevanagariMT,
DevanagariMT-Bold, Devanagari MT, DevanagariMT-Bold,
DevanagariSangamMN, Devanagari Sangam MN, DevanagariSangamMN,
DevanagariSangamMN-Bold, Devanagari Sangam MN, DevanagariSangamMN-Bold,
Didot, Didot, Didot,
Didot-Bold, Didot, Didot-Bold,
Didot-Italic, Didot, Didot-Italic,
DiwanKufi, Diwan Kufi, DiwanKufi,
DiwanMishafi, Mishafi, DiwanMishafi,
DiwanMishafiGold, Mishafi Gold, DiwanMishafiGold,
DiwanThuluth, Diwan Thuluth, DiwanThuluth,
EuphemiaUCAS, Euphemia UCAS, EuphemiaUCAS,
EuphemiaUCAS-Bold, Euphemia UCAS, EuphemiaUCAS-Bold,
EuphemiaUCAS-Italic, Euphemia UCAS, EuphemiaUCAS-Italic,
FZLTTHB--B51-0, Lantinghei TC, FZLTTHB--B51-0,
FZLTTHK--GBK1-0, Lantinghei SC, FZLTTHK--GBK1-0,
FZLTXHB--B51-0, Lantinghei TC, FZLTXHB--B51-0,
FZLTXHK--GBK1-0, Lantinghei SC, FZLTXHK--GBK1-0,
FZLTZHB--B51-0, Lantinghei TC, FZLTZHB--B51-0,
FZLTZHK--GBK1-0, Lantinghei SC, FZLTZHK--GBK1-0,
Farah, Farah, Farah,
Farisi, Farisi, Farisi,
Futura-Bold, Futura, Futura-Bold,
Futura-CondensedExtraBold, Futura, Futura-CondensedExtraBold,
Futura-CondensedMedium, Futura, Futura-CondensedMedium,
Futura-Medium, Futura, Futura-Medium,
Futura-MediumItalic, Futura, Futura-MediumItalic,
GB18030Bitmap, GB18030 Bitmap, GB18030Bitmap,
GeezaPro, Geeza Pro, GeezaPro,
GeezaPro-Bold, Geeza Pro, GeezaPro-Bold,
Geneva, Geneva, Geneva,
Georgia, Georgia, Georgia,
Georgia-Bold, Georgia, Georgia-Bold,
Georgia-BoldItalic, Georgia, Georgia-BoldItalic,
Georgia-Italic, Georgia, Georgia-Italic,
GillSans, Gill Sans, GillSans,
GillSans-Bold, Gill Sans, GillSans-Bold,
GillSans-BoldItalic, Gill Sans, GillSans-BoldItalic,
GillSans-Italic, Gill Sans, GillSans-Italic,
GillSans-Light, Gill Sans, GillSans-Light,
GillSans-LightItalic, Gill Sans, GillSans-LightItalic,
GillSans-SemiBold, Gill Sans, GillSans-SemiBold,
GillSans-SemiBoldItalic, Gill Sans, GillSans-SemiBoldItalic,
GillSans-UltraBold, Gill Sans, GillSans-UltraBold,
GujaratiMT, Gujarati MT, GujaratiMT,
GujaratiMT-Bold, Gujarati MT, GujaratiMT-Bold,
GujaratiSangamMN, Gujarati Sangam MN, GujaratiSangamMN,
GujaratiSangamMN-Bold, Gujarati Sangam MN, GujaratiSangamMN-Bold,
GurmukhiMN, Gurmukhi MN, GurmukhiMN,
GurmukhiMN-Bold, Gurmukhi MN, GurmukhiMN-Bold,
GurmukhiSangamMN, Gurmukhi Sangam MN, GurmukhiSangamMN,
GurmukhiSangamMN-Bold, Gurmukhi Sangam MN, GurmukhiSangamMN-Bold,
HannotateSC-W5, Hannotate SC, HannotateSC-W5,
HannotateSC-W7, Hannotate SC, HannotateSC-W7,
HannotateTC-W5, Hannotate TC, HannotateTC-W5,
HannotateTC-W7, Hannotate TC, HannotateTC-W7,
HanziPenSC-W3, HanziPen SC, HanziPenSC-W3,
HanziPenSC-W5, HanziPen SC, HanziPenSC-W5,
HanziPenTC-W3, HanziPen TC, HanziPenTC-W3,
HanziPenTC-W5, HanziPen TC, HanziPenTC-W5,
Helvetica, Helvetica, Helvetica,
Helvetica-Bold, Helvetica, Helvetica-Bold,
Helvetica-BoldOblique, Helvetica, Helvetica-BoldOblique,
Helvetica-Light, Helvetica, Helvetica-Light,
Helvetica-LightOblique, Helvetica, Helvetica-LightOblique,
Helvetica-Oblique, Helvetica, Helvetica-Oblique,
HelveticaNeue, Helvetica Neue, HelveticaNeue,
HelveticaNeue-Bold, Helvetica Neue, HelveticaNeue-Bold,
HelveticaNeue-BoldItalic, Helvetica Neue, HelveticaNeue-BoldItalic,
HelveticaNeue-CondensedBlack, Helvetica Neue, HelveticaNeue-CondensedBlack,
HelveticaNeue-CondensedBold, Helvetica Neue, HelveticaNeue-CondensedBold,
HelveticaNeue-Italic, Helvetica Neue, HelveticaNeue-Italic,
HelveticaNeue-Light, Helvetica Neue, HelveticaNeue-Light,
HelveticaNeue-LightItalic, Helvetica Neue, HelveticaNeue-LightItalic,
HelveticaNeue-Medium, Helvetica Neue, HelveticaNeue-Medium,
HelveticaNeue-MediumItalic, Helvetica Neue, HelveticaNeue-MediumItalic,
HelveticaNeue-Thin, Helvetica Neue, HelveticaNeue-Thin,
HelveticaNeue-ThinItalic, Helvetica Neue, HelveticaNeue-ThinItalic,
HelveticaNeue-UltraLight, Helvetica Neue, HelveticaNeue-UltraLight,
HelveticaNeue-UltraLightItalic, Helvetica Neue, HelveticaNeue-UltraLightItalic,
Herculanum, Herculanum, Herculanum,
HiraKakuPro-W3, Hiragino Kaku Gothic Pro, HiraKakuPro-W3,
HiraKakuPro-W6, Hiragino Kaku Gothic Pro, HiraKakuPro-W6,
HiraKakuProN-W3, Hiragino Kaku Gothic ProN, HiraKakuProN-W3,
HiraKakuProN-W6, Hiragino Kaku Gothic ProN, HiraKakuProN-W6,
HiraKakuStd-W8, Hiragino Kaku Gothic Std, HiraKakuStd-W8,
HiraKakuStdN-W8, Hiragino Kaku Gothic StdN, HiraKakuStdN-W8,
HiraMaruPro-W4, Hiragino Maru Gothic Pro, HiraMaruPro-W4,
HiraMaruProN-W4, Hiragino Maru Gothic ProN, HiraMaruProN-W4,
HiraMinPro-W3, Hiragino Mincho Pro, HiraMinPro-W3,
HiraMinPro-W6, Hiragino Mincho Pro, HiraMinPro-W6,
HiraMinProN-W3, Hiragino Mincho ProN, HiraMinProN-W3,
HiraMinProN-W6, Hiragino Mincho ProN, HiraMinProN-W6,
HiraginoSans-W0, Hiragino Sans, HiraginoSans-W0,
HiraginoSans-W1, Hiragino Sans, HiraginoSans-W1,
HiraginoSans-W2, Hiragino Sans, HiraginoSans-W2,
HiraginoSans-W3, Hiragino Sans, HiraginoSans-W3,
HiraginoSans-W4, Hiragino Sans, HiraginoSans-W4,
HiraginoSans-W5, Hiragino Sans, HiraginoSans-W5,
HiraginoSans-W6, Hiragino Sans, HiraginoSans-W6,
HiraginoSans-W7, Hiragino Sans, HiraginoSans-W7,
HiraginoSans-W8, Hiragino Sans, HiraginoSans-W8,
HiraginoSans-W9, Hiragino Sans, HiraginoSans-W9,
HiraginoSansCNS-W3, Hiragino Sans CNS, HiraginoSansCNS-W3,
HiraginoSansCNS-W6, Hiragino Sans CNS, HiraginoSansCNS-W6,
HiraginoSansGB-W3, Hiragino Sans GB, HiraginoSansGB-W3,
HiraginoSansGB-W6, Hiragino Sans GB, HiraginoSansGB-W6,
HoeflerText-Black, Hoefler Text, HoeflerText-Black,
HoeflerText-BlackItalic, Hoefler Text, HoeflerText-BlackItalic,
HoeflerText-Italic, Hoefler Text, HoeflerText-Italic,
HoeflerText-Ornaments, Hoefler Text, HoeflerText-Ornaments,
HoeflerText-Regular, Hoefler Text, HoeflerText-Regular,
ITFDevanagari-Bold, ITF Devanagari, ITFDevanagari-Bold,
ITFDevanagari-Book, ITF Devanagari, ITFDevanagari-Book,
ITFDevanagari-Demi, ITF Devanagari, ITFDevanagari-Demi,
ITFDevanagari-Light, ITF Devanagari, ITFDevanagari-Light,
ITFDevanagari-Medium, ITF Devanagari, ITFDevanagari-Medium,
ITFDevanagariMarathi-Bold, ITF Devanagari Marathi, ITFDevanagariMarathi-Bold,
ITFDevanagariMarathi-Book, ITF Devanagari Marathi, ITFDevanagariMarathi-Book,
ITFDevanagariMarathi-Demi, ITF Devanagari Marathi, ITFDevanagariMarathi-Demi,
ITFDevanagariMarathi-Light, ITF Devanagari Marathi, ITFDevanagariMarathi-Light,
ITFDevanagariMarathi-Medium, ITF Devanagari Marathi, ITFDevanagariMarathi-Medium,
Impact, Impact, Impact,
InaiMathi, InaiMathi, InaiMathi,
InaiMathi-Bold, InaiMathi, InaiMathi-Bold,
IowanOldStyle-Black, Iowan Old Style, IowanOldStyle-Black,
IowanOldStyle-BlackItalic, Iowan Old Style, IowanOldStyle-BlackItalic,
IowanOldStyle-Bold, Iowan Old Style, IowanOldStyle-Bold,
IowanOldStyle-BoldItalic, Iowan Old Style, IowanOldStyle-BoldItalic,
IowanOldStyle-Italic, Iowan Old Style, IowanOldStyle-Italic,
IowanOldStyle-Roman, Iowan Old Style, IowanOldStyle-Roman,
IowanOldStyle-Titling, Iowan Old Style, IowanOldStyle-Titling,
JCHEadA, HeadLineA, JCHEadA,
JCfg, PilGi, JCfg,
JCkg, GungSeo, JCkg,
JCsmPC, PCMyungjo, JCsmPC,
Kailasa, Kailasa, Kailasa,
Kailasa-Bold, Kailasa, Kailasa-Bold,
KannadaMN, Kannada MN, KannadaMN,
KannadaMN-Bold, Kannada MN, KannadaMN-Bold,
KannadaSangamMN, Kannada Sangam MN, KannadaSangamMN,
KannadaSangamMN-Bold, Kannada Sangam MN, KannadaSangamMN-Bold,
Kefa-Bold, Kefa, Kefa-Bold,
Kefa-Regular, Kefa, Kefa-Regular,
KhmerMN, Khmer MN, KhmerMN,
KhmerMN-Bold, Khmer MN, KhmerMN-Bold,
KhmerSangamMN, Khmer Sangam MN, KhmerSangamMN,
Klee-Demibold, Klee, Klee-Demibold,
Klee-Medium, Klee, Klee-Medium,
KohinoorBangla-Bold, Kohinoor Bangla, KohinoorBangla-Bold,
KohinoorBangla-Light, Kohinoor Bangla, KohinoorBangla-Light,
KohinoorBangla-Medium, Kohinoor Bangla, KohinoorBangla-Medium,
KohinoorBangla-Regular, Kohinoor Bangla, KohinoorBangla-Regular,
KohinoorBangla-Semibold, Kohinoor Bangla, KohinoorBangla-Semibold,
KohinoorDevanagari-Bold, Kohinoor Devanagari, KohinoorDevanagari-Bold,
KohinoorDevanagari-Light, Kohinoor Devanagari, KohinoorDevanagari-Light,
KohinoorDevanagari-Medium, Kohinoor Devanagari, KohinoorDevanagari-Medium,
KohinoorDevanagari-Regular, Kohinoor Devanagari, KohinoorDevanagari-Regular,
KohinoorDevanagari-Semibold, Kohinoor Devanagari, KohinoorDevanagari-Semibold,
KohinoorTelugu-Bold, Kohinoor Telugu, KohinoorTelugu-Bold,
KohinoorTelugu-Light, Kohinoor Telugu, KohinoorTelugu-Light,
KohinoorTelugu-Medium, Kohinoor Telugu, KohinoorTelugu-Medium,
KohinoorTelugu-Regular, Kohinoor Telugu, KohinoorTelugu-Regular,
KohinoorTelugu-Semibold, Kohinoor Telugu, KohinoorTelugu-Semibold,
Kokonor, Kokonor, Kokonor,
Krungthep, Krungthep, Krungthep,
KufiStandardGK, KufiStandardGK, KufiStandardGK,
LaoMN, Lao MN, LaoMN,
LaoMN-Bold, Lao MN, LaoMN-Bold,
LaoSangamMN, Lao Sangam MN, LaoSangamMN,
LiGothicMed, Apple LiGothic, LiGothicMed,
LiHeiPro, LiHei Pro, LiHeiPro,
LiSongPro, LiSong Pro, LiSongPro,
LiSungLight, Apple LiSung, LiSungLight,
Lucida Bright Demibold, Lucida Bright, Lucida Bright Demibold,
Lucida Bright Demibold Italic, Lucida Bright, Lucida Bright Demibold Italic,
Lucida Bright Italic, Lucida Bright, Lucida Bright Italic,
Lucida Bright Regular, Lucida Bright, Lucida Bright Regular,
Lucida Sans Demibold, Lucida Sans, Lucida Sans Demibold,
Lucida Sans Regular, Lucida Sans, Lucida Sans Regular,
Lucida Sans Typewriter Bold, Lucida Sans Typewriter, Lucida Sans Typewriter Bold,
Lucida Sans Typewriter Regular, Lucida Sans Typewriter, Lucida Sans Typewriter Regular,
LucidaBright, Lucida Bright, LucidaBright,
LucidaBright-Demi, Lucida Bright, LucidaBright-Demi,
LucidaBright-DemiItalic, Lucida Bright, LucidaBright-DemiItalic,
LucidaBright-Italic, Lucida Bright, LucidaBright-Italic,
LucidaGrande, Lucida Grande, LucidaGrande,
LucidaGrande-Bold, Lucida Grande, LucidaGrande-Bold,
LucidaSans, Lucida Sans, LucidaSans,
LucidaSans-Demi, Lucida Sans, LucidaSans-Demi,
LucidaSans-Typewriter, Lucida Sans Typewriter, LucidaSans-Typewriter,
LucidaSans-TypewriterBold, Lucida Sans Typewriter, LucidaSans-TypewriterBold,
Luminari-Regular, Luminari, Luminari-Regular,
MLingWaiMedium-SC, LingWai SC, MLingWaiMedium-SC,
MLingWaiMedium-TC, LingWai TC, MLingWaiMedium-TC,
MalayalamMN, Malayalam MN, MalayalamMN,
MalayalamMN-Bold, Malayalam MN, MalayalamMN-Bold,
MalayalamSangamMN, Malayalam Sangam MN, MalayalamSangamMN,
MalayalamSangamMN-Bold, Malayalam Sangam MN, MalayalamSangamMN-Bold,
Marion-Bold, Marion, Marion-Bold,
Marion-Italic, Marion, Marion-Italic,
Marion-Regular, Marion, Marion-Regular,
MarkerFelt-Thin, Marker Felt, MarkerFelt-Thin,
MarkerFelt-Wide, Marker Felt, MarkerFelt-Wide,
Menlo-Bold, Menlo, Menlo-Bold,
Menlo-BoldItalic, Menlo, Menlo-BoldItalic,
Menlo-Italic, Menlo, Menlo-Italic,
Menlo-Regular, Menlo, Menlo-Regular,
MicrosoftSansSerif, Microsoft Sans Serif, MicrosoftSansSerif,
Monaco, Monaco, Monaco,
MonotypeGurmukhi, Gurmukhi MT, MonotypeGurmukhi,
Mshtakan, Mshtakan, Mshtakan,
MshtakanBold, Mshtakan, MshtakanBold,
MshtakanBoldOblique, Mshtakan, MshtakanBoldOblique,
MshtakanOblique, Mshtakan, MshtakanOblique,
Muna, Muna, Muna,
MunaBlack, Muna, MunaBlack,
MunaBold, Muna, MunaBold,
MyanmarMN, Myanmar MN, MyanmarMN,
MyanmarMN-Bold, Myanmar MN, MyanmarMN-Bold,
MyanmarSangamMN, Myanmar Sangam MN, MyanmarSangamMN,
MyanmarSangamMN-Bold, Myanmar Sangam MN, MyanmarSangamMN-Bold,
Nadeem, Nadeem, Nadeem,
NanumBrush, Nanum Brush Script, NanumBrush,
NanumGothic, Nanum Gothic, NanumGothic,
NanumGothicBold, Nanum Gothic, NanumGothicBold,
NanumGothicExtraBold, Nanum Gothic, NanumGothicExtraBold,
NanumMyeongjo, Nanum Myeongjo, NanumMyeongjo,
NanumMyeongjoBold, Nanum Myeongjo, NanumMyeongjoBold,
NanumMyeongjoExtraBold, Nanum Myeongjo, NanumMyeongjoExtraBold,
NanumPen, Nanum Pen Script, NanumPen,
NewPeninimMT, New Peninim MT, NewPeninimMT,
NewPeninimMT-Bold, New Peninim MT, NewPeninimMT-Bold,
NewPeninimMT-BoldInclined, New Peninim MT, NewPeninimMT-BoldInclined,
NewPeninimMT-Inclined, New Peninim MT, NewPeninimMT-Inclined,
Noteworthy-Bold, Noteworthy, Noteworthy-Bold,
Noteworthy-Light, Noteworthy, Noteworthy-Light,
NotoNastaliqUrdu, Noto Nastaliq Urdu, NotoNastaliqUrdu,
Optima-Bold, Optima, Optima-Bold,
Optima-BoldItalic, Optima, Optima-BoldItalic,
Optima-ExtraBlack, Optima, Optima-ExtraBlack,
Optima-Italic, Optima, Optima-Italic,
Optima-Regular, Optima, Optima-Regular,
OriyaMN, Oriya MN, OriyaMN,
OriyaMN-Bold, Oriya MN, OriyaMN-Bold,
OriyaSangamMN, Oriya Sangam MN, OriyaSangamMN,
OriyaSangamMN-Bold, Oriya Sangam MN, OriyaSangamMN-Bold,
Osaka, Osaka, Osaka,
Osaka-Mono, Osaka, Osaka-Mono,
PTMono-Bold, PT Mono, PTMono-Bold,
PTMono-Regular, PT Mono, PTMono-Regular,
PTSans-Bold, PT Sans, PTSans-Bold,
PTSans-BoldItalic, PT Sans, PTSans-BoldItalic,
PTSans-Caption, PT Sans Caption, PTSans-Caption,
PTSans-CaptionBold, PT Sans Caption, PTSans-CaptionBold,
PTSans-Italic, PT Sans, PTSans-Italic,
PTSans-Narrow, PT Sans Narrow, PTSans-Narrow,
PTSans-NarrowBold, PT Sans Narrow, PTSans-NarrowBold,
PTSans-Regular, PT Sans, PTSans-Regular,
PTSerif-Bold, PT Serif, PTSerif-Bold,
PTSerif-BoldItalic, PT Serif, PTSerif-BoldItalic,
PTSerif-Caption, PT Serif Caption, PTSerif-Caption,
PTSerif-CaptionItalic, PT Serif Caption, PTSerif-CaptionItalic,
PTSerif-Italic, PT Serif, PTSerif-Italic,
PTSerif-Regular, PT Serif, PTSerif-Regular,
Palatino-Bold, Palatino, Palatino-Bold,
Palatino-BoldItalic, Palatino, Palatino-BoldItalic,
Palatino-Italic, Palatino, Palatino-Italic,
Palatino-Roman, Palatino, Palatino-Roman,
Papyrus, Papyrus, Papyrus,
Papyrus-Condensed, Papyrus, Papyrus-Condensed,
Phosphate-Inline, Phosphate, Phosphate-Inline,
Phosphate-Solid, Phosphate, Phosphate-Solid,
PingFangHK-Light, PingFang HK, PingFangHK-Light,
PingFangHK-Medium, PingFang HK, PingFangHK-Medium,
PingFangHK-Regular, PingFang HK, PingFangHK-Regular,
PingFangHK-Semibold, PingFang HK, PingFangHK-Semibold,
PingFangHK-Thin, PingFang HK, PingFangHK-Thin,
PingFangHK-Ultralight, PingFang HK, PingFangHK-Ultralight,
PingFangSC-Light, PingFang SC, PingFangSC-Light,
PingFangSC-Medium, PingFang SC, PingFangSC-Medium,
PingFangSC-Regular, PingFang SC, PingFangSC-Regular,
PingFangSC-Semibold, PingFang SC, PingFangSC-Semibold,
PingFangSC-Thin, PingFang SC, PingFangSC-Thin,
PingFangSC-Ultralight, PingFang SC, PingFangSC-Ultralight,
PingFangTC-Light, PingFang TC, PingFangTC-Light,
PingFangTC-Medium, PingFang TC, PingFangTC-Medium,
PingFangTC-Regular, PingFang TC, PingFangTC-Regular,
PingFangTC-Semibold, PingFang TC, PingFangTC-Semibold,
PingFangTC-Thin, PingFang TC, PingFangTC-Thin,
PingFangTC-Ultralight, PingFang TC, PingFangTC-Ultralight,
PlantagenetCherokee, Plantagenet Cherokee, PlantagenetCherokee,
Raanana, Raanana, Raanana,
RaananaBold, Raanana, RaananaBold,
SIL-Hei-Med-Jian, Hei, SIL-Hei-Med-Jian,
SIL-Kai-Reg-Jian, Kai, SIL-Kai-Reg-Jian,
STBaoliSC-Regular, Baoli SC, STBaoliSC-Regular,
STBaoliTC-Regular, Baoli TC, STBaoliTC-Regular,
STFangsong, STFangsong, STFangsong,
STHeiti, STHeiti, STHeiti,
STHeitiSC-Light, Heiti SC, STHeitiSC-Light,
STHeitiSC-Medium, Heiti SC, STHeitiSC-Medium,
STHeitiTC-Light, Heiti TC, STHeitiTC-Light,
STHeitiTC-Medium, Heiti TC, STHeitiTC-Medium,
STIXGeneral-Bold, STIXGeneral, STIXGeneral-Bold,
STIXGeneral-BoldItalic, STIXGeneral, STIXGeneral-BoldItalic,
STIXGeneral-Italic, STIXGeneral, STIXGeneral-Italic,
STIXGeneral-Regular, STIXGeneral, STIXGeneral-Regular,
STIXIntegralsD-Bold, STIXIntegralsD, STIXIntegralsD-Bold,
STIXIntegralsD-Regular, STIXIntegralsD, STIXIntegralsD-Regular,
STIXIntegralsSm-Bold, STIXIntegralsSm, STIXIntegralsSm-Bold,
STIXIntegralsSm-Regular, STIXIntegralsSm, STIXIntegralsSm-Regular,
STIXIntegralsUp-Bold, STIXIntegralsUp, STIXIntegralsUp-Bold,
STIXIntegralsUp-Regular, STIXIntegralsUp, STIXIntegralsUp-Regular,
STIXIntegralsUpD-Bold, STIXIntegralsUpD, STIXIntegralsUpD-Bold,
STIXIntegralsUpD-Regular, STIXIntegralsUpD, STIXIntegralsUpD-Regular,
STIXIntegralsUpSm-Bold, STIXIntegralsUpSm, STIXIntegralsUpSm-Bold,
STIXIntegralsUpSm-Regular, STIXIntegralsUpSm, STIXIntegralsUpSm-Regular,
STIXNonUnicode-Bold, STIXNonUnicode, STIXNonUnicode-Bold,
STIXNonUnicode-BoldItalic, STIXNonUnicode, STIXNonUnicode-BoldItalic,
STIXNonUnicode-Italic, STIXNonUnicode, STIXNonUnicode-Italic,
STIXNonUnicode-Regular, STIXNonUnicode, STIXNonUnicode-Regular,
STIXSizeFiveSym-Regular, STIXSizeFiveSym, STIXSizeFiveSym-Regular,
STIXSizeFourSym-Bold, STIXSizeFourSym, STIXSizeFourSym-Bold,
STIXSizeFourSym-Regular, STIXSizeFourSym, STIXSizeFourSym-Regular,
STIXSizeOneSym-Bold, STIXSizeOneSym, STIXSizeOneSym-Bold,
STIXSizeOneSym-Regular, STIXSizeOneSym, STIXSizeOneSym-Regular,
STIXSizeThreeSym-Bold, STIXSizeThreeSym, STIXSizeThreeSym-Bold,
STIXSizeThreeSym-Regular, STIXSizeThreeSym, STIXSizeThreeSym-Regular,
STIXSizeTwoSym-Bold, STIXSizeTwoSym, STIXSizeTwoSym-Bold,
STIXSizeTwoSym-Regular, STIXSizeTwoSym, STIXSizeTwoSym-Regular,
STIXVariants-Bold, STIXVariants, STIXVariants-Bold,
STIXVariants-Regular, STIXVariants, STIXVariants-Regular,
STKaiti, STKaiti, STKaiti,
STKaitiSC-Black, Kaiti SC, STKaitiSC-Black,
STKaitiSC-Bold, Kaiti SC, STKaitiSC-Bold,
STKaitiSC-Regular, Kaiti SC, STKaitiSC-Regular,
STKaitiTC-Black, Kaiti TC, STKaitiTC-Black,
STKaitiTC-Bold, Kaiti TC, STKaitiTC-Bold,
STKaitiTC-Regular, Kaiti TC, STKaitiTC-Regular,
STLibianSC-Regular, Libian SC, STLibianSC-Regular,
STLibianTC-Regular, Libian TC, STLibianTC-Regular,
STSong, STSong, STSong,
STSongti-SC-Black, Songti SC, STSongti-SC-Black,
STSongti-SC-Bold, Songti SC, STSongti-SC-Bold,
STSongti-SC-Light, Songti SC, STSongti-SC-Light,
STSongti-SC-Regular, Songti SC, STSongti-SC-Regular,
STSongti-TC-Bold, Songti TC, STSongti-TC-Bold,
STSongti-TC-Light, Songti TC, STSongti-TC-Light,
STSongti-TC-Regular, Songti TC, STSongti-TC-Regular,
STXihei, STHeiti, STXihei,
STXingkaiSC-Bold, Xingkai SC, STXingkaiSC-Bold,
STXingkaiSC-Light, Xingkai SC, STXingkaiSC-Light,
STXingkaiTC-Bold, Xingkai TC, STXingkaiTC-Bold,
STXingkaiTC-Light, Xingkai TC, STXingkaiTC-Light,
STYuanti-SC-Bold, Yuanti SC, STYuanti-SC-Bold,
STYuanti-SC-Light, Yuanti SC, STYuanti-SC-Light,
STYuanti-SC-Regular, Yuanti SC, STYuanti-SC-Regular,
STYuanti-TC-Bold, Yuanti TC, STYuanti-TC-Bold,
STYuanti-TC-Light, Yuanti TC, STYuanti-TC-Light,
STYuanti-TC-Regular, Yuanti TC, STYuanti-TC-Regular,
Sana, Sana, Sana,
Sathu, Sathu, Sathu,
SavoyeLetPlain, Savoye LET, SavoyeLetPlain,
Seravek, Seravek, Seravek,
Seravek-Bold, Seravek, Seravek-Bold,
Seravek-BoldItalic, Seravek, Seravek-BoldItalic,
Seravek-ExtraLight, Seravek, Seravek-ExtraLight,
Seravek-ExtraLightItalic, Seravek, Seravek-ExtraLightItalic,
Seravek-Italic, Seravek, Seravek-Italic,
Seravek-Light, Seravek, Seravek-Light,
Seravek-LightItalic, Seravek, Seravek-LightItalic,
Seravek-Medium, Seravek, Seravek-Medium,
Seravek-MediumItalic, Seravek, Seravek-MediumItalic,
ShreeDev0714, Shree Devanagari 714, ShreeDev0714,
ShreeDev0714-Bold, Shree Devanagari 714, ShreeDev0714-Bold,
ShreeDev0714-BoldItalic, Shree Devanagari 714, ShreeDev0714-BoldItalic,
ShreeDev0714-Italic, Shree Devanagari 714, ShreeDev0714-Italic,
SignPainter-HouseScript, SignPainter, SignPainter-HouseScript,
SignPainter-HouseScriptSemibold, SignPainter, SignPainter-HouseScriptSemibold,
Silom, Silom, Silom,
SinhalaMN, Sinhala MN, SinhalaMN,
SinhalaMN-Bold, Sinhala MN, SinhalaMN-Bold,
SinhalaSangamMN, Sinhala Sangam MN, SinhalaSangamMN,
SinhalaSangamMN-Bold, Sinhala Sangam MN, SinhalaSangamMN-Bold,
Skia-Regular, Skia, Skia-Regular,
Skia-Regular_Black, Skia, Skia-Regular_Black,
Skia-Regular_Black-Condensed, Skia, Skia-Regular_Black-Condensed,
Skia-Regular_Black-Extended, Skia, Skia-Regular_Black-Extended,
Skia-Regular_Bold, Skia, Skia-Regular_Bold,
Skia-Regular_Condensed, Skia, Skia-Regular_Condensed,
Skia-Regular_Extended, Skia, Skia-Regular_Extended,
Skia-Regular_Light, Skia, Skia-Regular_Light,
Skia-Regular_Light-Condensed, Skia, Skia-Regular_Light-Condensed,
Skia-Regular_Light-Extended, Skia, Skia-Regular_Light-Extended,
SnellRoundhand, Snell Roundhand, SnellRoundhand,
SnellRoundhand-Black, Snell Roundhand, SnellRoundhand-Black,
SnellRoundhand-Bold, Snell Roundhand, SnellRoundhand-Bold,
SukhumvitSet-Bold, Sukhumvit Set, SukhumvitSet-Bold,
SukhumvitSet-Light, Sukhumvit Set, SukhumvitSet-Light,
SukhumvitSet-Medium, Sukhumvit Set, SukhumvitSet-Medium,
SukhumvitSet-SemiBold, Sukhumvit Set, SukhumvitSet-SemiBold,
SukhumvitSet-Text, Sukhumvit Set, SukhumvitSet-Text,
SukhumvitSet-Thin, Sukhumvit Set, SukhumvitSet-Thin,
Superclarendon-Black, Superclarendon, Superclarendon-Black,
Superclarendon-BlackItalic, Superclarendon, Superclarendon-BlackItalic,
Superclarendon-Bold, Superclarendon, Superclarendon-Bold,
Superclarendon-BoldItalic, Superclarendon, Superclarendon-BoldItalic,
Superclarendon-Italic, Superclarendon, Superclarendon-Italic,
Superclarendon-Light, Superclarendon, Superclarendon-Light,
Superclarendon-LightItalic, Superclarendon, Superclarendon-LightItalic,
Superclarendon-Regular, Superclarendon, Superclarendon-Regular,
Symbol, Symbol, Symbol,
Tahoma, Tahoma, Tahoma,
Tahoma-Bold, Tahoma, Tahoma-Bold,
TamilMN, Tamil MN, TamilMN,
TamilMN-Bold, Tamil MN, TamilMN-Bold,
TamilSangamMN, Tamil Sangam MN, TamilSangamMN,
TamilSangamMN-Bold, Tamil Sangam MN, TamilSangamMN-Bold,
TeluguMN, Telugu MN, TeluguMN,
TeluguMN-Bold, Telugu MN, TeluguMN-Bold,
TeluguSangamMN, Telugu Sangam MN, TeluguSangamMN,
TeluguSangamMN-Bold, Telugu Sangam MN, TeluguSangamMN-Bold,
Thonburi, Thonburi, Thonburi,
Thonburi-Bold, Thonburi, Thonburi-Bold,
Thonburi-Light, Thonburi, Thonburi-Light,
Times-Bold, Times, Times-Bold,
Times-BoldItalic, Times, Times-BoldItalic,
Times-Italic, Times, Times-Italic,
Times-Roman, Times, Times-Roman,
TimesNewRomanPS-BoldItalicMT, Times New Roman, TimesNewRomanPS-BoldItalicMT,
TimesNewRomanPS-BoldMT, Times New Roman, TimesNewRomanPS-BoldMT,
TimesNewRomanPS-ItalicMT, Times New Roman, TimesNewRomanPS-ItalicMT,
TimesNewRomanPSMT, Times New Roman, TimesNewRomanPSMT,
ToppanBunkyuGothicPr6N-DB, Toppan Bunkyu Gothic, ToppanBunkyuGothicPr6N-DB,
ToppanBunkyuGothicPr6N-Regular, Toppan Bunkyu Gothic, ToppanBunkyuGothicPr6N-Regular,
ToppanBunkyuMidashiGothicStdN-ExtraBold, Toppan Bunkyu Midashi Gothic, ToppanBunkyuMidashiGothicStdN-ExtraBold,
ToppanBunkyuMidashiMinchoStdN-ExtraBold, Toppan Bunkyu Midashi Mincho, ToppanBunkyuMidashiMinchoStdN-ExtraBold,
ToppanBunkyuMinchoPr6N-Regular, Toppan Bunkyu Mincho, ToppanBunkyuMinchoPr6N-Regular,
Trattatello, Trattatello, Trattatello,
Trebuchet-BoldItalic, Trebuchet MS, Trebuchet-BoldItalic,
TrebuchetMS, Trebuchet MS, TrebuchetMS,
TrebuchetMS-Bold, Trebuchet MS, TrebuchetMS-Bold,
TrebuchetMS-Italic, Trebuchet MS, TrebuchetMS-Italic,
TsukuARdGothic-Bold, Tsukushi A Round Gothic, TsukuARdGothic-Bold,
TsukuARdGothic-Regular, Tsukushi A Round Gothic, TsukuARdGothic-Regular,
TsukuBRdGothic-Bold, Tsukushi B Round Gothic, TsukuBRdGothic-Bold,
TsukuBRdGothic-Regular, Tsukushi B Round Gothic, TsukuBRdGothic-Regular,
Verdana, Verdana, Verdana,
Verdana-Bold, Verdana, Verdana-Bold,
Verdana-BoldItalic, Verdana, Verdana-BoldItalic,
Verdana-Italic, Verdana, Verdana-Italic,
Waseem, Waseem, Waseem,
WaseemLight, Waseem, WaseemLight,
Webdings, Webdings, Webdings,
WeibeiSC-Bold, Weibei SC, WeibeiSC-Bold,
WeibeiTC-Bold, Weibei TC, WeibeiTC-Bold,
Wingdings-Regular, Wingdings, Wingdings-Regular,
Wingdings2, Wingdings 2, Wingdings2,
Wingdings3, Wingdings 3, Wingdings3,
YuGo-Bold, YuGothic, YuGo-Bold,
YuGo-Medium, YuGothic, YuGo-Medium,
YuKyo-Bold, YuKyokasho, YuKyo-Bold,
YuKyo-Medium, YuKyokasho, YuKyo-Medium,
YuKyo_Yoko-Bold, YuKyokasho Yoko, YuKyo_Yoko-Bold,
YuKyo_Yoko-Medium, YuKyokasho Yoko, YuKyo_Yoko-Medium,
YuMin-Demibold, YuMincho, YuMin-Demibold,
YuMin-Extrabold, YuMincho, YuMin-Extrabold,
YuMin-Medium, YuMincho, YuMin-Medium,
YuMin_36pKn-Demibold, YuMincho +36p Kana, YuMin_36pKn-Demibold,
YuMin_36pKn-Extrabold, YuMincho +36p Kana, YuMin_36pKn-Extrabold,
YuMin_36pKn-Medium, YuMincho +36p Kana, YuMin_36pKn-Medium,
YuppySC-Regular, Yuppy SC, YuppySC-Regular,
YuppyTC-Regular, Yuppy TC, YuppyTC-Regular,
ZapfDingbatsITC, Zapf Dingbats, ZapfDingbatsITC,
Zapfino, Zapfino, Zapfino,
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Kullback-Leibler Divergence</title>
      <link>https://yumaloop.github.io/post/2018-04-19-kl-divergence/</link>
      <pubDate>Thu, 19 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/post/2018-04-19-kl-divergence/</guid>
      <description>&lt;p&gt;KL-divergence frequently appears in many fields such as statistics and information theory. It is defined as the &lt;strong&gt;expected value&lt;/strong&gt; of &lt;strong&gt;logarithmic&lt;/strong&gt; transformation of &lt;strong&gt;likelihood ratio&lt;/strong&gt;. Note that:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;expected value: weighted integration with probability density.&lt;/li&gt;
&lt;li&gt;logarithmic transformation: conversion multiplication to linear combination that is suitable for convex optimization and function analysis.&lt;/li&gt;
&lt;li&gt;likelihood ratio: a measure of likelihood comparison&lt;/li&gt;
&lt;/ol&gt;
&lt;br&gt;
&lt;h2 id=&#34;1-what-is-kl-divergence&#34;&gt;1. What is KL-divergence?&lt;/h2&gt;
&lt;h4 id=&#34;11-definition&#34;&gt;1.1 Definition&lt;/h4&gt;
&lt;p&gt;　For any probability distributions $P$ and $Q$, &lt;strong&gt;KL-divergence&lt;/strong&gt; (Kullback-Leibler divergence)&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; is defined as follows, using their probability density function $p(x)$ and $q(x)$.&lt;/p&gt;
&lt;p&gt;\begin{align}
D_{KL}( Q \mid\mid P )
&amp;amp;:= \int q(x) \log \frac{q(x)}{p(x)} ~dx
\end{align}&lt;/p&gt;
&lt;br&gt;
&lt;h4 id=&#34;12-basic-properties&#34;&gt;1.2 Basic properties&lt;/h4&gt;
&lt;p&gt;　KL-divergence has the following properties.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;（&lt;strong&gt;non-negative&lt;/strong&gt;）It has a non-negative range.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;\begin{align}
0 \leq D_{KL}( Q \mid\mid P ) &amp;amp;\leq \infty
\end{align}&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;（&lt;em&gt;&lt;strong&gt;completeness&lt;/strong&gt;&lt;/em&gt;）When it equals to $0$, $P$ and $Q$ are equivalent.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;\begin{align}
D_{KL}( Q \mid\mid P )
&amp;amp;= 0 ~~ \Leftrightarrow ~~ P = Q
\end{align}&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;（&lt;strong&gt;assymmetry&lt;/strong&gt;）It is not symmetric about $P$ and $Q$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;\begin{align}
D_{KL}( Q \mid\mid P )
&amp;amp;\neq D_{KL}( P \mid\mid Q )
\end{align}&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;（&lt;strong&gt;absolute continuity&lt;/strong&gt;）Unless it diverges, $Q$ is absolutely continuous with respect to $P$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;\begin{align}
D_{KL}( Q \mid\mid P )
&amp;amp;\lt \infty ~~ \Rightarrow ~~ P \gg Q
\end{align}&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;​	For example, calculating KL-divergence&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; between two Gaussian distributions gives the following results: It can be seen that the more the shapes between two distributions do not match, the more  KL-divergence increases.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;%7B%7Bsite.baseurl%7D%7D/assets/img/post/dkl_norm.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;br&gt;
&lt;h4 id=&#34;13-is-kl-divergence-a-metrics&#34;&gt;1.3 Is KL-divergence a metrics?&lt;/h4&gt;
&lt;p&gt;​	KL-divergence is so important measurement when considering probability and information that it is called by various names depending on the field and context.&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;KL-divergence&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;KL-metrics&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;KL-information&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Information divergence&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Information gain&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Relative entropy&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;Since KL-divergence is always non-negative, it might be interpreted as the metrics in the space where the probability distributions $P$ and $Q$ exist. However, KL-divergence is &lt;strong&gt;not&lt;/strong&gt; strictly a metric because it only satisfies &amp;ldquo;non-negativity&amp;rdquo; and &amp;ldquo;completeness&amp;rdquo; among the following &lt;strong&gt;axioms of metrics&lt;/strong&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Axioms of metrics $d(~)$:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;non-negativity                     $d(x, ~ y) \geq 0$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;completeness                      $d(x, ~ y) = 0 ~~ \Leftrightarrow ~~ x = y$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;symmetry                             $d(x, ~ y) = d(y, ~ x)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The triangle inequality       $d(x, ~ y) + d(y, ~ z) \geq d(x, ~ z)$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;Note that $d()$ is called the &lt;em&gt;distance function&lt;/em&gt; or simply &lt;em&gt;distance&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For example, Euclidean distance, squared distance, Mahalanobis distance, and Hamming distance satisfy these conditions, and can be clearly considered as metrics. On the other hand, KL-divergence is a divergence, not metrics. In mathematics, &lt;strong&gt;&amp;ldquo;divergence&amp;rdquo;&lt;/strong&gt; is an extended concept of &amp;ldquo;metrics&amp;rdquo; that satisfies only &lt;strong&gt;non-negativity&lt;/strong&gt; and &lt;strong&gt;completeness&lt;/strong&gt; among axioms of metrics. By introducing &amp;ldquo;divergence&amp;rdquo;, you can reduce the constraints of axioms of metrics and  have a high level of abstraction.&lt;/p&gt;
&lt;p&gt;The word &amp;ldquo;divergence&amp;rdquo; is generally interpreted as the process or state of diverging; for example, in physics it appears as a vector operator &lt;strong&gt;div&lt;/strong&gt;. There is no Japanese words that corresponds to the meaning of divergence, but it seems that &amp;ldquo;相違度&amp;rdquo;, &amp;ldquo;分離度&amp;rdquo;, &amp;ldquo;逸脱度&amp;rdquo;, &amp;ldquo;乖離度&amp;rdquo; etc. might be used.&lt;/p&gt;
&lt;p&gt;As an example, let&amp;rsquo;s measure the KL-divergence between two Gaussian distributions $ N (0, 1) $ (blue) and $ N (1, 2) $ (red). In the figure, the left shows &lt;strong&gt;KL-divergence from red one as seen from blue one&lt;/strong&gt;, and the right shows &lt;strong&gt;KL-divergence from blue one as seen from red one&lt;/strong&gt;. Their value are surely different.&lt;/p&gt;
&lt;p&gt;Note that given two Gaussian distribution $p_1,p_2$ as&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
p_1(x) &amp;amp;= \mathcal{N}(\mu_1, \sigma_1^2) = \frac{1}{\sqrt{2 \pi \sigma_1^2}} \exp \left\{ - \frac{ {(x - \mu_1)}^2}{2 \sigma_1^2} \right\} \\&lt;br&gt;
p_2(x) &amp;amp;= \mathcal{N}(\mu_2, \sigma_2^2) = \frac{1}{\sqrt{2 \pi \sigma_2^2}} \exp \left\{ - \frac{ {(x - \mu_2)}^2}{2 \sigma_2^2} \right\}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;the following holds.&lt;/p&gt;
&lt;p&gt;$$
\begin{align}
{D}_{KL}(p_1 \mid\mid p_2)
&amp;amp;= \int_{-\infty}^{\infty} p_1(x) \log \frac{p_1(x)}{p_2(x)} dx \\&lt;br&gt;
&amp;amp;= \log \frac{\sigma_2}{\sigma_1} + \frac{\sigma_1^2 + {( \mu_1 - \mu_2 )}^2}{2 \sigma_2^2} - \frac{1}{2}
\end{align}
$$&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;%7B%7Bsite.baseurl%7D%7D/assets/img/post/comparison_of_dkl_norm.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Incidentally, in addition to the KL-divergence, the following is known as a measure of the proximity (or closeness) between two probability distributions.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;The metrics to measure closeness between $q(x)$ and $p(x)$&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$ {\chi}^2(q ; p) := \sum_{i=1}^{k} \frac{ { { p_i - q_i } }^{2} }{p_i}$        ($\chi^2$-statistics)&lt;/li&gt;
&lt;li&gt;$ L_1(q ; p) := \int \vert q(x) - p(x) \vert ~ dx$        ($L_1$-norm)&lt;/li&gt;
&lt;li&gt;$ L_2(q ; p) := \int { { q(x) - p(x) } }^{2} ~ dx$        ($L_2$-norm)&lt;/li&gt;
&lt;li&gt;$ I_K(q ; p) := \int { \{ \sqrt{ q(x) } - \sqrt{ p(x) } \} }^{2} ~ dx $        (Herringer distance)&lt;/li&gt;
&lt;li&gt;$ \mathbb{D}(q ; p) := \int f \left( {\large \frac{q(x)}{p(x)} } \right) q(x) ~ dx$        ($f$-divergence)&lt;/li&gt;
&lt;li&gt;$ I_{\lambda}(q ; p) := \int \left\{ { \left( {\large \frac{q(x)}{p(x)} } \right) }^{\lambda} - 1 \right\} q(x) ~ dx$        (Generalized information)&lt;/li&gt;
&lt;li&gt;$ {D}_{KL}(q ; p) := \int \log \left( {\large \frac{q(x)}{p(x)} } \right) q(x) ~ dx$        (KL-divergence)&lt;/li&gt;
&lt;li&gt;$ JSD(q \mid\mid p) := \frac{1}{2} {D}_{KL}(q \mid\mid \frac{q+p}{2}) + \frac{1}{2} {D}_{KL}(p \mid\mid \frac{q+p}{2})$        (JS-divergence)&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;br&gt;
&lt;h2 id=&#34;2-relatinoship-to-other-measurements&#34;&gt;2. Relatinoship to other measurements&lt;/h2&gt;
&lt;h4 id=&#34;21-kl-divergence-vs-mutual-information&#34;&gt;2.1 KL-divergence vs Mutual information&lt;/h4&gt;
&lt;p&gt;　In information theory, entropy $H(X)$, join entropy $H(X,Y)$, conditional entropy $H(X \vert Y)$, mutual information $MI(X,Y)$ are defined as follows by using probability density $Pr()$&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;\begin{align}
H(X)    &amp;amp;:= - \int Pr(x) \log Pr(x) ~dx \\&lt;br&gt;
H(X,Y)  &amp;amp;:= - \int Pr(x,y) \log Pr(x,y) ~dy~dx \\&lt;br&gt;
H(X|Y)  &amp;amp;:= - \int Pr(x,y) \log Pr(x|y) ~dx~dy \\&lt;br&gt;
MI(X,Y) &amp;amp;:= \int \int Pr(x,y) \log \frac{Pr(x,y)}{Pr(x)Pr(y)} ~dxdy
\end{align}&lt;/p&gt;
&lt;p&gt;For any two random variable $X$ and $Y$, mutual information $MI(X, Y)$ specifies the mutual (symmetric) dependence between them.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;%7B%7Bsite.baseurl%7D%7D/assets/img/post/dkl_and_mutual_information.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;\begin{align}
MI(X,Y) &amp;amp;= H(X) - H(X|Y)  \\&lt;br&gt;
&amp;amp;= H(Y) - H(Y|X) \\&lt;br&gt;
&amp;amp;= H(X) + H(Y) - H(X,Y)
\end{align}&lt;/p&gt;
&lt;p&gt;Here, the following relationship holds between KL-divergence and mutual information.&lt;/p&gt;
&lt;p&gt;\begin{align}
MI(X, Y)
&amp;amp;= D_{KL} \bigl( Pr(x, y) \mid\mid Pr(x)Pr(y) \bigr) \\&lt;br&gt;
&amp;amp;= \mathbb{E}_{Y} \bigl[ D_{KL} \bigl( Pr(x|y) \mid\mid Pr(x) \bigr) \bigr] \\&lt;br&gt;
&amp;amp;= \mathbb{E}_{X} \bigl[ D_{KL} \bigl( Pr(y|x) \mid\mid Pr(y) \bigr) \bigr]
\end{align}&lt;/p&gt;
&lt;p&gt;So that, mutual information $MI (X, Y)$ is interpreted as the degree of difference (average degree of deviation) between the joint distribution $Pr (x, y)$ when the $X$ and $Y$ are &lt;strong&gt;not independent&lt;/strong&gt; and the joint distribution $Pr (x) Pr (y)$ when $X$ and $Y$ are &lt;strong&gt;independent&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;（cf.）Formula transformation of mutual information:&lt;/p&gt;
&lt;p&gt;\begin{align}
MI(X,Y)
&amp;amp;= \int \int Pr(x,y) \log \frac{Pr(x,y)}{Pr(x)Pr(y)} ~dxdy \\&lt;br&gt;
&amp;amp;= \int \int Pr(x|y)Pr(y) \log \frac{Pr(x|y)Pr(y)}{Pr(x)Pr(y)} ~dxdy \\&lt;br&gt;
&amp;amp;= \int Pr(y) \int Pr(x|y) \log \frac{Pr(x|y)}{Pr(x)} ~dx~dy \\&lt;br&gt;
&amp;amp;= \int Pr(y) \cdot D_{KL} \bigl( Pr(x|y) \mid\mid Pr(x) \bigr) ~dy \\&lt;br&gt;
&amp;amp;= \mathbb{E}_{Y} \bigl[ D_{KL} \bigl( Pr(x|y) \mid\mid Pr(x) \bigr) \bigr]
\end{align}&lt;/p&gt;
&lt;br&gt;
&lt;h3 id=&#34;22-kl-divergence-vs-log-likelihood-ratio&#34;&gt;2.2 KL-divergence vs Log likelihood ratio&lt;/h3&gt;
&lt;p&gt;In the field of Bayes inference and statistical modeling, you often face the problem of estimating the &lt;strong&gt;true distribution&lt;/strong&gt; $q(x)$ by $p_{\hat{\theta}}(x)$ (that is the combination of stochastic model $p_{\theta}(x)$ and estimated parameter $\hat{\theta}$ ) . Therefore, KL-divergence is used when you want to measure the difference between two distributions, or when you want to incorporate the estimation error into the loss function or risk function in order to solve  the optimization problem for the parameter $\theta$.&lt;/p&gt;
&lt;p&gt;Also, KL-divergence is related to the log likelihood ratio so much that it has a deep connection to the model selection method &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; such as likelihood ratio test, Bayes factor, and AIC (Akaike&amp;rsquo;s information criterion).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;KL-divergence of estimated distribution $p_{\theta}(x)$ for the true distribution $q(x)$ : $D_{KL}(q \mid\mid p_{\theta})$ is considerd as the expected value of the log likelihood ratio $q(x)/p_{\theta}(x)$ for tue true distribution $q(x)$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;\begin{align}
\left( \text{Log likelihood ratio} \right)
&amp;amp;= \log \frac{q(x)}{p_{\theta}(x)} \\&lt;br&gt;
D_{KL}( q \mid\mid p_{\theta} )
&amp;amp;:= \int q(x) \log \frac{q(x)}{p_{\theta}(x)} ~dx \\&lt;br&gt;
&amp;amp;= \mathbb{E}_{X} \left[ \log \frac{q(x)}{p_{\theta}(x)} \right] \left(\text{Expected log likelihood ratio} \right)
\end{align}&lt;/p&gt;
&lt;p&gt;When using KL-divergence as the evaluation/loss value in model selection/comparison, it is equivalent that minimizing KL-divergence: $D_{KL}( q \mid\mid p )$ and maximizing the log likelihood: $\log p(x)$ as follows.&lt;/p&gt;
&lt;p&gt;\begin{align}
D_{KL}( q \mid\mid p_{\theta} )
&amp;amp;= \mathbb{E}_{X} \bigl[ \log q(x) \bigr] - \mathbb{E}_{X} \bigl[ \log p_{\theta}(x) \bigr] \\&lt;br&gt;
&amp;amp;\propto - \mathbb{E}_{X} \bigl[ \log p_{\theta}(x) \bigr] \left(-1 \cdot \text{ Expected log likelihood} \right)
\end{align}&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;For any parametric stochastic model $f(x \vert \theta)$ (such as a linear regression model) which represents the estimated distribution as&lt;/p&gt;
&lt;p&gt;\begin{align}
p_{\theta}(x) = f(x|\theta)
\end{align}&lt;/p&gt;
&lt;p&gt;, if a certain loss function $L(\theta)$ is given, the optimal parameter $\theta^*$ exists as it satisfy the following.&lt;/p&gt;
&lt;p&gt;\begin{align}
q(x) &amp;amp;= f(x|\theta^*)
\end{align}&lt;/p&gt;
&lt;p&gt;Then, for any estimated parameter $\hat{\theta}$ ,the estimated loss of the model $f(x \vert \hat{\theta})$ is represented by KL-divergence. (Note that $\ell( \cdot \vert x)$ means the log likelihood function.)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;\begin{align}
\left( \text{Log likelihood ratio} \right)
&amp;amp;=  \log \frac{f(x|\theta^{*})}{f(x|\hat{\theta})}
\end{align}&lt;/p&gt;
&lt;p&gt;\begin{align}
\hat{\theta}
&amp;amp;:= \underset{\theta \in \Theta}{\rm argmin} ~ L(\theta) \tag{7}
\\&lt;br&gt;
D_{KL}( q \mid\mid p_{\hat{\theta}} )
&amp;amp;= D_{KL}( p_{\theta^{*}} \mid\mid p_{\hat{\theta}} ) \\&lt;br&gt;
&amp;amp;= D_{KL}( f_{\theta^{*}} \mid\mid f_{\hat{\theta}} ) \\&lt;br&gt;
&amp;amp;= \int f(x|\theta^{*}) \log \frac{f(x|\theta^{*})}{ f(x|\hat{\theta})} dx \\&lt;br&gt;
&amp;amp;= \mathbb{E}_{X} \left[ \log \frac{ f(x|\theta^{*}) }{ f(x|\hat{\theta}) } \right] \\&lt;br&gt;
&amp;amp;= \mathbb{E}_{X} \bigl[ \ell( \theta_{0}|x ) \bigr] - \mathbb{E}_{X} \bigl[ \ell( \hat{\theta} | x ) \bigr]
\end{align}&lt;/p&gt;
&lt;br&gt;
&lt;h4 id=&#34;23-kl-divergence-vs-fisher-information&#34;&gt;2.3 KL-divergence vs Fisher information&lt;/h4&gt;
&lt;p&gt;Given a certain stochastic model $f(\cdot \vert \theta)$, &lt;strong&gt;Fisher information&lt;/strong&gt; $I(\theta)$ for the parameter $\theta$ is defined as follows.  (Note that $ \ell( \cdot \vert x) $ means the log likelihood function.)&lt;/p&gt;
&lt;p&gt;\begin{align}
I(\theta)
&amp;amp;:= \mathbb{E}_{X} \left[ { \left\{ \frac{d}{dx} \ell(\theta \vert x) \right\} }^{3} \right] \\&lt;br&gt;
&amp;amp;= \mathbb{E}_{X} \left[ { \left\{ \frac{d}{dx} \log f(x|\theta) \right\} }^{2} \right]
\end{align}&lt;/p&gt;
&lt;p&gt;Also, between KL-divergence and Fisher information, the following holds.&lt;/p&gt;
&lt;p&gt;\begin{align}
\lim_{h \to 0} \frac{1}{h^{2}} D_{KL} \bigl( f(x|\theta) \mid\mid f(x|\theta+h) \bigr)
&amp;amp;= \frac{1}{2} I(\theta)&lt;br&gt;
\end{align}&lt;/p&gt;
&lt;p&gt;(cf.) The following equation holds by using Taylor expansion of $\ell( \cdot \vert x)$.&lt;br&gt;&lt;/p&gt;
&lt;p&gt;\begin{align}
\ell(\theta + h) - \ell(\theta)
&amp;amp;= {\ell}^{&#39;}(\theta)h + \frac{1}{2} {\ell}^{&#39;&#39;}(\theta) h^{2} + O(h^{3})
\end{align}&lt;/p&gt;
&lt;p&gt;This formula indicates that in parameter space $\Theta$, for all point $ \theta \in \Theta $ ant its neighborring point $ \theta + h $, their KL-divergence：$ D_{KL} ( f(x \vert \theta) \mid\mid f(x \vert \theta+h) )$ is **directly proportional to** Fisher information $I(\theta)$. After all, Fisher information $ I(\theta)$ measures **the local information** that the stochastic model $f(\cdot \vert \theta)$ has at the point $\theta$.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;%7B%7Bsite.baseurl%7D%7D/assets/img/post/dkl_and_fisher_information.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;br&gt;
&lt;h2 id=&#34;3-references&#34;&gt;3. References&lt;/h2&gt;
&lt;iframe style=&#34;width:120px;height:240px;&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; scrolling=&#34;no&#34; frameborder=&#34;0&#34; src=&#34;https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&amp;t=yumaloop0f-22&amp;m=amazon&amp;o=9&amp;p=8&amp;l=as1&amp;IS1=1&amp;detail=1&amp;asins=4254127820&amp;linkId=1456f8ade37cd01c91d31448ce7b50f2&amp;bc1=ffffff&amp;lt1=_top&amp;fc1=333333&amp;lc1=0066c0&amp;bg1=ffffff&amp;f=ifr&#34;&gt;
&lt;/iframe&gt;
&lt;iframe style=&#34;width:120px;height:240px;&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; scrolling=&#34;no&#34; frameborder=&#34;0&#34; src=&#34;https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&amp;t=yumaloop0f-22&amp;m=amazon&amp;o=9&amp;p=8&amp;l=as1&amp;IS1=1&amp;detail=1&amp;asins=4785314117&amp;linkId=a437161b2bfff7107300d73243499d9d&amp;bc1=FFFFFF&amp;lt1=_top&amp;fc1=333333&amp;lc1=0066C0&amp;bg1=FFFFFF&amp;f=ifr&#34;&gt;
&lt;/iframe&gt;
&lt;iframe style=&#34;width:120px;height:240px;&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; scrolling=&#34;no&#34; frameborder=&#34;0&#34; src=&#34;https://rcm-fe.amazon-adsystem.com/e/cm?ref=tf_til&amp;t=yumaloop0f-22&amp;m=amazon&amp;o=9&amp;p=8&amp;l=as1&amp;IS1=1&amp;detail=1&amp;asins=0471241954&amp;linkId=477c693b4215ab3b8aa2cdee1450fef7&amp;bc1=ffffff&amp;lt1=_top&amp;fc1=333333&amp;lc1=0066c0&amp;bg1=ffffff&amp;f=ifr&#34;&gt;
&lt;/iframe&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Also, f-divergence is defined as its generalized class. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;I used scipy.stats.entropy(). &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Although thermodynamic entropy is originated in Boltzmann, the historical background of Shannon information is mentioned below link. There seems to be a reference flow: Hartley → Nyquist → Shannon. &lt;a href=&#34;http://www.ieice.org/jpn/books/kaishikiji/200112/200112-9.html&#34;&gt;http://www.ieice.org/jpn/books/kaishikiji/200112/200112-9.html&lt;/a&gt; &lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Article on gneralized information criterion(GIC): &lt;a href=&#34;https://www.ism.ac.jp/editsec/toukei/pdf/47-2-375.pdf&#34;&gt;https://www.ism.ac.jp/editsec/toukei/pdf/47-2-375.pdf&lt;/a&gt; &lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Example Project</title>
      <link>https://yumaloop.github.io/project/example/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://yumaloop.github.io/project/example/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
